op0: SchedulerNode(ComputedBuffer)
op0.writes = [MemoryDep('buf0', c0, {c0: 100}, None)]
op0.unmet_dependencies = []
op0.met_dependencies = 
    [   MemoryDep('full_default', c0, {c0: 100}, None),
        MemoryDep('tangents_1', 96, {}, None),
        MemoryDep('tangents_1', 97, {}, None),
        MemoryDep('tangents_1', 98, {}, None),
        MemoryDep('tangents_1', 99, {}, None)]
op0.outputs = [
    buf0: ComputedBuffer
    buf0.layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
    buf0.users = [NodeUser(node=SchedulerNode(name='op1'), can_inplace=True, is_weak=False)]
]
op0.group.device = cuda:0
op0.group.iteration = (100, 1)
op0.sizes = ([100], [])
tangents_1_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
full_default_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
tangents_1_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
tangents_1_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
tangents_1_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf0_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
class op0_loop_body:
    var_ranges = {z0: 100}
    index0 = z0
    index1 = 99
    index2 = 98
    index3 = 97
    index4 = 96
    def body(self, ops):
        get_index = self.get_index('index0')
        index_expr = ops.index_expr(get_index, torch.int32)
        constant = ops.constant(99, torch.int32)
        eq = ops.eq(index_expr, constant)
        get_index_1 = self.get_index('index1')
        load = ops.load('tangents_1', get_index_1)
        constant_1 = ops.constant(2.0, torch.float32)
        mul = ops.mul(load, constant_1)
        get_index_2 = self.get_index('index0')
        load_1 = ops.load('full_default', get_index_2)
        where = ops.where(eq, mul, load_1)
        get_index_3 = self.get_index('index0')
        index_expr_1 = ops.index_expr(get_index_3, torch.int32)
        constant_2 = ops.constant(98, torch.int32)
        eq_1 = ops.eq(index_expr_1, constant_2)
        constant_3 = ops.constant(98, torch.int32)
        constant_4 = ops.constant(99, torch.int32)
        eq_2 = ops.eq(constant_3, constant_4)
        get_index_4 = self.get_index('index2')
        load_2 = ops.load('tangents_1', get_index_4)
        constant_5 = ops.constant(0.0, torch.float32)
        where_1 = ops.where(eq_2, constant_5, load_2)
        constant_6 = ops.constant(2.0, torch.float32)
        mul_1 = ops.mul(where_1, constant_6)
        get_index_5 = self.get_index('index0')
        load_3 = ops.load('full_default', get_index_5)
        where_2 = ops.where(eq_1, mul_1, load_3)
        add = ops.add(where, where_2)
        get_index_6 = self.get_index('index0')
        index_expr_2 = ops.index_expr(get_index_6, torch.int32)
        constant_7 = ops.constant(97, torch.int32)
        eq_3 = ops.eq(index_expr_2, constant_7)
        constant_8 = ops.constant(97, torch.int32)
        constant_9 = ops.constant(98, torch.int32)
        eq_4 = ops.eq(constant_8, constant_9)
        constant_10 = ops.constant(97, torch.int32)
        constant_11 = ops.constant(99, torch.int32)
        eq_5 = ops.eq(constant_10, constant_11)
        get_index_7 = self.get_index('index3')
        load_4 = ops.load('tangents_1', get_index_7)
        constant_12 = ops.constant(0.0, torch.float32)
        where_3 = ops.where(eq_5, constant_12, load_4)
        constant_13 = ops.constant(0.0, torch.float32)
        where_4 = ops.where(eq_4, constant_13, where_3)
        constant_14 = ops.constant(2.0, torch.float32)
        mul_2 = ops.mul(where_4, constant_14)
        get_index_8 = self.get_index('index0')
        load_5 = ops.load('full_default', get_index_8)
        where_5 = ops.where(eq_3, mul_2, load_5)
        add_1 = ops.add(add, where_5)
        get_index_9 = self.get_index('index0')
        index_expr_3 = ops.index_expr(get_index_9, torch.int32)
        constant_15 = ops.constant(96, torch.int32)
        eq_6 = ops.eq(index_expr_3, constant_15)
        constant_16 = ops.constant(96, torch.int32)
        constant_17 = ops.constant(97, torch.int32)
        eq_7 = ops.eq(constant_16, constant_17)
        constant_18 = ops.constant(96, torch.int32)
        constant_19 = ops.constant(98, torch.int32)
        eq_8 = ops.eq(constant_18, constant_19)
        constant_20 = ops.constant(96, torch.int32)
        constant_21 = ops.constant(99, torch.int32)
        eq_9 = ops.eq(constant_20, constant_21)
        get_index_10 = self.get_index('index4')
        load_6 = ops.load('tangents_1', get_index_10)
        constant_22 = ops.constant(0.0, torch.float32)
        where_6 = ops.where(eq_9, constant_22, load_6)
        constant_23 = ops.constant(0.0, torch.float32)
        where_7 = ops.where(eq_8, constant_23, where_6)
        constant_24 = ops.constant(0.0, torch.float32)
        where_8 = ops.where(eq_7, constant_24, where_7)
        constant_25 = ops.constant(2.0, torch.float32)
        mul_3 = ops.mul(where_8, constant_25)
        get_index_11 = self.get_index('index0')
        load_7 = ops.load('full_default', get_index_11)
        where_9 = ops.where(eq_6, mul_3, load_7)
        add_2 = ops.add(add_1, where_9)
        get_index_12 = self.get_index('index0')
        store = ops.store('buf0', get_index_12, add_2, None)
        return store
op0 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[128], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, multi_processor_count=20), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 5, 'num_reduction': 0, 'backend_hash': '712B1D69F892A891D8FFA5075DCAB47CFF4E132D88BFC66744701CEAE226F127', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 100
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp3 = tl.load(in_ptr0 + (99))
        tmp4 = tl.broadcast_to(tmp3, [XBLOCK])
        tmp7 = tl.load(in_ptr1 + (x0), xmask)
        tmp12 = tl.load(in_ptr0 + (98))
        tmp13 = tl.broadcast_to(tmp12, [XBLOCK])
        tmp23 = tl.load(in_ptr0 + (97))
        tmp24 = tl.broadcast_to(tmp23, [XBLOCK])
        tmp35 = tl.load(in_ptr0 + (96))
        tmp36 = tl.broadcast_to(tmp35, [XBLOCK])
        tmp0 = x0
        tmp1 = tl.full([1], 99, tl.int32)
        tmp2 = tmp0 == tmp1
        tmp5 = 2.0
        tmp6 = tmp4 * tmp5
        tmp8 = tl.where(tmp2, tmp6, tmp7)
        tmp9 = tl.full([1], 98, tl.int32)
        tmp10 = tmp0 == tmp9
        tmp11 = tmp9 == tmp1
        tmp14 = 0.0
        tmp15 = tl.where(tmp11, tmp14, tmp13)
        tmp16 = tmp15 * tmp5
        tmp17 = tl.where(tmp10, tmp16, tmp7)
        tmp18 = tmp8 + tmp17
        tmp19 = tl.full([1], 97, tl.int32)
        tmp20 = tmp0 == tmp19
        tmp21 = tmp19 == tmp9
        tmp22 = tmp19 == tmp1
        tmp25 = tl.where(tmp22, tmp14, tmp24)
        tmp26 = tl.where(tmp21, tmp14, tmp25)
        tmp27 = tmp26 * tmp5
        tmp28 = tl.where(tmp20, tmp27, tmp7)
        tmp29 = tmp18 + tmp28
        tmp30 = tl.full([1], 96, tl.int32)
        tmp31 = tmp0 == tmp30
        tmp32 = tmp30 == tmp19
        tmp33 = tmp30 == tmp9
        tmp34 = tmp30 == tmp1
        tmp37 = tl.where(tmp34, tmp14, tmp36)
        tmp38 = tl.where(tmp33, tmp14, tmp37)
        tmp39 = tl.where(tmp32, tmp14, tmp38)
        tmp40 = tmp39 * tmp5
        tmp41 = tl.where(tmp31, tmp40, tmp7)
        tmp42 = tmp29 + tmp41
        tl.store(out_ptr0 + (x0), tmp42, xmask)


op1: SchedulerNode(ComputedBuffer)
op1.writes = [MemoryDep('buf1', c0, {c0: 100}, None)]
op1.unmet_dependencies = [MemoryDep('buf0', c0, {c0: 100}, None)]
op1.met_dependencies = 
    [   MemoryDep('full_default', c0, {c0: 100}, None),
        MemoryDep('tangents_1', 94, {}, None),
        MemoryDep('tangents_1', 95, {}, None)]
op1.outputs = [
    buf1: ComputedBuffer
    buf1.layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
    buf1.users = [NodeUser(node=SchedulerNode(name='op2'), can_inplace=True, is_weak=False)]
]
op1.group.device = cuda:0
op1.group.iteration = (100, 1)
op1.sizes = ([100], [])
buf0_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
tangents_1_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
full_default_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
tangents_1_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf1_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
class op1_loop_body:
    var_ranges = {z0: 100}
    index0 = z0
    index1 = 95
    index2 = 94
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf0', get_index)
        get_index_1 = self.get_index('index0')
        index_expr = ops.index_expr(get_index_1, torch.int32)
        constant = ops.constant(95, torch.int32)
        eq = ops.eq(index_expr, constant)
        constant_1 = ops.constant(95, torch.int32)
        constant_2 = ops.constant(96, torch.int32)
        eq_1 = ops.eq(constant_1, constant_2)
        constant_3 = ops.constant(95, torch.int32)
        constant_4 = ops.constant(97, torch.int32)
        eq_2 = ops.eq(constant_3, constant_4)
        constant_5 = ops.constant(95, torch.int32)
        constant_6 = ops.constant(98, torch.int32)
        eq_3 = ops.eq(constant_5, constant_6)
        constant_7 = ops.constant(95, torch.int32)
        constant_8 = ops.constant(99, torch.int32)
        eq_4 = ops.eq(constant_7, constant_8)
        get_index_2 = self.get_index('index1')
        load_1 = ops.load('tangents_1', get_index_2)
        constant_9 = ops.constant(0.0, torch.float32)
        where = ops.where(eq_4, constant_9, load_1)
        constant_10 = ops.constant(0.0, torch.float32)
        where_1 = ops.where(eq_3, constant_10, where)
        constant_11 = ops.constant(0.0, torch.float32)
        where_2 = ops.where(eq_2, constant_11, where_1)
        constant_12 = ops.constant(0.0, torch.float32)
        where_3 = ops.where(eq_1, constant_12, where_2)
        constant_13 = ops.constant(2.0, torch.float32)
        mul = ops.mul(where_3, constant_13)
        get_index_3 = self.get_index('index0')
        load_2 = ops.load('full_default', get_index_3)
        where_4 = ops.where(eq, mul, load_2)
        add = ops.add(load, where_4)
        get_index_4 = self.get_index('index0')
        index_expr_1 = ops.index_expr(get_index_4, torch.int32)
        constant_14 = ops.constant(94, torch.int32)
        eq_5 = ops.eq(index_expr_1, constant_14)
        constant_15 = ops.constant(94, torch.int32)
        constant_16 = ops.constant(95, torch.int32)
        eq_6 = ops.eq(constant_15, constant_16)
        constant_17 = ops.constant(94, torch.int32)
        constant_18 = ops.constant(96, torch.int32)
        eq_7 = ops.eq(constant_17, constant_18)
        constant_19 = ops.constant(94, torch.int32)
        constant_20 = ops.constant(97, torch.int32)
        eq_8 = ops.eq(constant_19, constant_20)
        constant_21 = ops.constant(94, torch.int32)
        constant_22 = ops.constant(98, torch.int32)
        eq_9 = ops.eq(constant_21, constant_22)
        constant_23 = ops.constant(94, torch.int32)
        constant_24 = ops.constant(99, torch.int32)
        eq_10 = ops.eq(constant_23, constant_24)
        get_index_5 = self.get_index('index2')
        load_3 = ops.load('tangents_1', get_index_5)
        constant_25 = ops.constant(0.0, torch.float32)
        where_5 = ops.where(eq_10, constant_25, load_3)
        constant_26 = ops.constant(0.0, torch.float32)
        where_6 = ops.where(eq_9, constant_26, where_5)
        constant_27 = ops.constant(0.0, torch.float32)
        where_7 = ops.where(eq_8, constant_27, where_6)
        constant_28 = ops.constant(0.0, torch.float32)
        where_8 = ops.where(eq_7, constant_28, where_7)
        constant_29 = ops.constant(0.0, torch.float32)
        where_9 = ops.where(eq_6, constant_29, where_8)
        constant_30 = ops.constant(2.0, torch.float32)
        mul_1 = ops.mul(where_9, constant_30)
        get_index_6 = self.get_index('index0')
        load_4 = ops.load('full_default', get_index_6)
        where_10 = ops.where(eq_5, mul_1, load_4)
        add_1 = ops.add(add, where_10)
        get_index_7 = self.get_index('index0')
        store = ops.store('buf1', get_index_7, add_1, None)
        return store
op1 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[128], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, multi_processor_count=20), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_out_ptr0'], 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': '712B1D69F892A891D8FFA5075DCAB47CFF4E132D88BFC66744701CEAE226F127', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_out_ptr0, in_ptr0, in_ptr1, xnumel, XBLOCK : tl.constexpr):
        xnumel = 100
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp0 = tl.load(in_out_ptr0 + (x0), xmask)
        tmp12 = tl.load(in_ptr0 + (95))
        tmp13 = tl.broadcast_to(tmp12, [XBLOCK])
        tmp21 = tl.load(in_ptr1 + (x0), xmask)
        tmp31 = tl.load(in_ptr0 + (94))
        tmp32 = tl.broadcast_to(tmp31, [XBLOCK])
        tmp1 = x0
        tmp2 = tl.full([1], 95, tl.int32)
        tmp3 = tmp1 == tmp2
        tmp4 = tl.full([1], 96, tl.int32)
        tmp5 = tmp2 == tmp4
        tmp6 = tl.full([1], 97, tl.int32)
        tmp7 = tmp2 == tmp6
        tmp8 = tl.full([1], 98, tl.int32)
        tmp9 = tmp2 == tmp8
        tmp10 = tl.full([1], 99, tl.int32)
        tmp11 = tmp2 == tmp10
        tmp14 = 0.0
        tmp15 = tl.where(tmp11, tmp14, tmp13)
        tmp16 = tl.where(tmp9, tmp14, tmp15)
        tmp17 = tl.where(tmp7, tmp14, tmp16)
        tmp18 = tl.where(tmp5, tmp14, tmp17)
        tmp19 = 2.0
        tmp20 = tmp18 * tmp19
        tmp22 = tl.where(tmp3, tmp20, tmp21)
        tmp23 = tmp0 + tmp22
        tmp24 = tl.full([1], 94, tl.int32)
        tmp25 = tmp1 == tmp24
        tmp26 = tmp24 == tmp2
        tmp27 = tmp24 == tmp4
        tmp28 = tmp24 == tmp6
        tmp29 = tmp24 == tmp8
        tmp30 = tmp24 == tmp10
        tmp33 = tl.where(tmp30, tmp14, tmp32)
        tmp34 = tl.where(tmp29, tmp14, tmp33)
        tmp35 = tl.where(tmp28, tmp14, tmp34)
        tmp36 = tl.where(tmp27, tmp14, tmp35)
        tmp37 = tl.where(tmp26, tmp14, tmp36)
        tmp38 = tmp37 * tmp19
        tmp39 = tl.where(tmp25, tmp38, tmp21)
        tmp40 = tmp23 + tmp39
        tl.store(in_out_ptr0 + (x0), tmp40, xmask)


op2: SchedulerNode(ComputedBuffer)
op2.writes = [MemoryDep('buf2', c0, {c0: 100}, None)]
op2.unmet_dependencies = [MemoryDep('buf1', c0, {c0: 100}, None)]
op2.met_dependencies = 
    [   MemoryDep('full_default', c0, {c0: 100}, None),
        MemoryDep('tangents_1', 92, {}, None),
        MemoryDep('tangents_1', 93, {}, None)]
op2.outputs = [
    buf2: ComputedBuffer
    buf2.layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
    buf2.users = [NodeUser(node=SchedulerNode(name='op6'), can_inplace=True, is_weak=False)]
]
op2.group.device = cuda:0
op2.group.iteration = (100, 1)
op2.sizes = ([100], [])
buf1_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
tangents_1_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
full_default_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
tangents_1_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf2_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
class op2_loop_body:
    var_ranges = {z0: 100}
    index0 = z0
    index1 = 93
    index2 = 92
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf1', get_index)
        get_index_1 = self.get_index('index0')
        index_expr = ops.index_expr(get_index_1, torch.int32)
        constant = ops.constant(93, torch.int32)
        eq = ops.eq(index_expr, constant)
        constant_1 = ops.constant(93, torch.int32)
        constant_2 = ops.constant(94, torch.int32)
        eq_1 = ops.eq(constant_1, constant_2)
        constant_3 = ops.constant(93, torch.int32)
        constant_4 = ops.constant(95, torch.int32)
        eq_2 = ops.eq(constant_3, constant_4)
        constant_5 = ops.constant(93, torch.int32)
        constant_6 = ops.constant(96, torch.int32)
        eq_3 = ops.eq(constant_5, constant_6)
        constant_7 = ops.constant(93, torch.int32)
        constant_8 = ops.constant(97, torch.int32)
        eq_4 = ops.eq(constant_7, constant_8)
        constant_9 = ops.constant(93, torch.int32)
        constant_10 = ops.constant(98, torch.int32)
        eq_5 = ops.eq(constant_9, constant_10)
        constant_11 = ops.constant(93, torch.int32)
        constant_12 = ops.constant(99, torch.int32)
        eq_6 = ops.eq(constant_11, constant_12)
        get_index_2 = self.get_index('index1')
        load_1 = ops.load('tangents_1', get_index_2)
        constant_13 = ops.constant(0.0, torch.float32)
        where = ops.where(eq_6, constant_13, load_1)
        constant_14 = ops.constant(0.0, torch.float32)
        where_1 = ops.where(eq_5, constant_14, where)
        constant_15 = ops.constant(0.0, torch.float32)
        where_2 = ops.where(eq_4, constant_15, where_1)
        constant_16 = ops.constant(0.0, torch.float32)
        where_3 = ops.where(eq_3, constant_16, where_2)
        constant_17 = ops.constant(0.0, torch.float32)
        where_4 = ops.where(eq_2, constant_17, where_3)
        constant_18 = ops.constant(0.0, torch.float32)
        where_5 = ops.where(eq_1, constant_18, where_4)
        constant_19 = ops.constant(2.0, torch.float32)
        mul = ops.mul(where_5, constant_19)
        get_index_3 = self.get_index('index0')
        load_2 = ops.load('full_default', get_index_3)
        where_6 = ops.where(eq, mul, load_2)
        add = ops.add(load, where_6)
        get_index_4 = self.get_index('index0')
        index_expr_1 = ops.index_expr(get_index_4, torch.int32)
        constant_20 = ops.constant(92, torch.int32)
        eq_7 = ops.eq(index_expr_1, constant_20)
        constant_21 = ops.constant(92, torch.int32)
        constant_22 = ops.constant(93, torch.int32)
        eq_8 = ops.eq(constant_21, constant_22)
        constant_23 = ops.constant(92, torch.int32)
        constant_24 = ops.constant(94, torch.int32)
        eq_9 = ops.eq(constant_23, constant_24)
        constant_25 = ops.constant(92, torch.int32)
        constant_26 = ops.constant(95, torch.int32)
        eq_10 = ops.eq(constant_25, constant_26)
        constant_27 = ops.constant(92, torch.int32)
        constant_28 = ops.constant(96, torch.int32)
        eq_11 = ops.eq(constant_27, constant_28)
        constant_29 = ops.constant(92, torch.int32)
        constant_30 = ops.constant(97, torch.int32)
        eq_12 = ops.eq(constant_29, constant_30)
        constant_31 = ops.constant(92, torch.int32)
        constant_32 = ops.constant(98, torch.int32)
        eq_13 = ops.eq(constant_31, constant_32)
        constant_33 = ops.constant(92, torch.int32)
        constant_34 = ops.constant(99, torch.int32)
        eq_14 = ops.eq(constant_33, constant_34)
        get_index_5 = self.get_index('index2')
        load_3 = ops.load('tangents_1', get_index_5)
        constant_35 = ops.constant(0.0, torch.float32)
        where_7 = ops.where(eq_14, constant_35, load_3)
        constant_36 = ops.constant(0.0, torch.float32)
        where_8 = ops.where(eq_13, constant_36, where_7)
        constant_37 = ops.constant(0.0, torch.float32)
        where_9 = ops.where(eq_12, constant_37, where_8)
        constant_38 = ops.constant(0.0, torch.float32)
        where_10 = ops.where(eq_11, constant_38, where_9)
        constant_39 = ops.constant(0.0, torch.float32)
        where_11 = ops.where(eq_10, constant_39, where_10)
        constant_40 = ops.constant(0.0, torch.float32)
        where_12 = ops.where(eq_9, constant_40, where_11)
        constant_41 = ops.constant(0.0, torch.float32)
        where_13 = ops.where(eq_8, constant_41, where_12)
        constant_42 = ops.constant(2.0, torch.float32)
        mul_1 = ops.mul(where_13, constant_42)
        get_index_6 = self.get_index('index0')
        load_4 = ops.load('full_default', get_index_6)
        where_14 = ops.where(eq_7, mul_1, load_4)
        add_1 = ops.add(add, where_14)
        get_index_7 = self.get_index('index0')
        store = ops.store('buf2', get_index_7, add_1, None)
        return store
op2 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[128], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, multi_processor_count=20), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_out_ptr0'], 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': '712B1D69F892A891D8FFA5075DCAB47CFF4E132D88BFC66744701CEAE226F127', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_out_ptr0, in_ptr0, in_ptr1, xnumel, XBLOCK : tl.constexpr):
        xnumel = 100
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp0 = tl.load(in_out_ptr0 + (x0), xmask)
        tmp16 = tl.load(in_ptr0 + (93))
        tmp17 = tl.broadcast_to(tmp16, [XBLOCK])
        tmp27 = tl.load(in_ptr1 + (x0), xmask)
        tmp39 = tl.load(in_ptr0 + (92))
        tmp40 = tl.broadcast_to(tmp39, [XBLOCK])
        tmp1 = x0
        tmp2 = tl.full([1], 93, tl.int32)
        tmp3 = tmp1 == tmp2
        tmp4 = tl.full([1], 94, tl.int32)
        tmp5 = tmp2 == tmp4
        tmp6 = tl.full([1], 95, tl.int32)
        tmp7 = tmp2 == tmp6
        tmp8 = tl.full([1], 96, tl.int32)
        tmp9 = tmp2 == tmp8
        tmp10 = tl.full([1], 97, tl.int32)
        tmp11 = tmp2 == tmp10
        tmp12 = tl.full([1], 98, tl.int32)
        tmp13 = tmp2 == tmp12
        tmp14 = tl.full([1], 99, tl.int32)
        tmp15 = tmp2 == tmp14
        tmp18 = 0.0
        tmp19 = tl.where(tmp15, tmp18, tmp17)
        tmp20 = tl.where(tmp13, tmp18, tmp19)
        tmp21 = tl.where(tmp11, tmp18, tmp20)
        tmp22 = tl.where(tmp9, tmp18, tmp21)
        tmp23 = tl.where(tmp7, tmp18, tmp22)
        tmp24 = tl.where(tmp5, tmp18, tmp23)
        tmp25 = 2.0
        tmp26 = tmp24 * tmp25
        tmp28 = tl.where(tmp3, tmp26, tmp27)
        tmp29 = tmp0 + tmp28
        tmp30 = tl.full([1], 92, tl.int32)
        tmp31 = tmp1 == tmp30
        tmp32 = tmp30 == tmp2
        tmp33 = tmp30 == tmp4
        tmp34 = tmp30 == tmp6
        tmp35 = tmp30 == tmp8
        tmp36 = tmp30 == tmp10
        tmp37 = tmp30 == tmp12
        tmp38 = tmp30 == tmp14
        tmp41 = tl.where(tmp38, tmp18, tmp40)
        tmp42 = tl.where(tmp37, tmp18, tmp41)
        tmp43 = tl.where(tmp36, tmp18, tmp42)
        tmp44 = tl.where(tmp35, tmp18, tmp43)
        tmp45 = tl.where(tmp34, tmp18, tmp44)
        tmp46 = tl.where(tmp33, tmp18, tmp45)
        tmp47 = tl.where(tmp32, tmp18, tmp46)
        tmp48 = tmp47 * tmp25
        tmp49 = tl.where(tmp31, tmp48, tmp27)
        tmp50 = tmp29 + tmp49
        tl.store(in_out_ptr0 + (x0), tmp50, xmask)


op3: SchedulerNode(ComputedBuffer)
op3.writes = [MemoryDep('buf3', c0, {c0: 100}, None)]
op3.unmet_dependencies = []
op3.met_dependencies = 
    [   MemoryDep('full_default', c0, {c0: 100}, None),
        MemoryDep('tangents_1', 91, {}, None)]
op3.outputs = [
    buf3: ComputedBuffer
    buf3.layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
    buf3.users = [NodeUser(node=SchedulerNode(name='op6'), can_inplace=True, is_weak=False)]
]
op3.group.device = cuda:0
op3.group.iteration = (100, 1)
op3.sizes = ([100], [])
tangents_1_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
full_default_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf3_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
class op3_loop_body:
    var_ranges = {z0: 100}
    index0 = z0
    index1 = 91
    def body(self, ops):
        get_index = self.get_index('index0')
        index_expr = ops.index_expr(get_index, torch.int32)
        constant = ops.constant(91, torch.int32)
        eq = ops.eq(index_expr, constant)
        constant_1 = ops.constant(91, torch.int32)
        constant_2 = ops.constant(92, torch.int32)
        eq_1 = ops.eq(constant_1, constant_2)
        constant_3 = ops.constant(91, torch.int32)
        constant_4 = ops.constant(93, torch.int32)
        eq_2 = ops.eq(constant_3, constant_4)
        constant_5 = ops.constant(91, torch.int32)
        constant_6 = ops.constant(94, torch.int32)
        eq_3 = ops.eq(constant_5, constant_6)
        constant_7 = ops.constant(91, torch.int32)
        constant_8 = ops.constant(95, torch.int32)
        eq_4 = ops.eq(constant_7, constant_8)
        constant_9 = ops.constant(91, torch.int32)
        constant_10 = ops.constant(96, torch.int32)
        eq_5 = ops.eq(constant_9, constant_10)
        constant_11 = ops.constant(91, torch.int32)
        constant_12 = ops.constant(97, torch.int32)
        eq_6 = ops.eq(constant_11, constant_12)
        constant_13 = ops.constant(91, torch.int32)
        constant_14 = ops.constant(98, torch.int32)
        eq_7 = ops.eq(constant_13, constant_14)
        constant_15 = ops.constant(91, torch.int32)
        constant_16 = ops.constant(99, torch.int32)
        eq_8 = ops.eq(constant_15, constant_16)
        get_index_1 = self.get_index('index1')
        load = ops.load('tangents_1', get_index_1)
        constant_17 = ops.constant(0.0, torch.float32)
        where = ops.where(eq_8, constant_17, load)
        constant_18 = ops.constant(0.0, torch.float32)
        where_1 = ops.where(eq_7, constant_18, where)
        constant_19 = ops.constant(0.0, torch.float32)
        where_2 = ops.where(eq_6, constant_19, where_1)
        constant_20 = ops.constant(0.0, torch.float32)
        where_3 = ops.where(eq_5, constant_20, where_2)
        constant_21 = ops.constant(0.0, torch.float32)
        where_4 = ops.where(eq_4, constant_21, where_3)
        constant_22 = ops.constant(0.0, torch.float32)
        where_5 = ops.where(eq_3, constant_22, where_4)
        constant_23 = ops.constant(0.0, torch.float32)
        where_6 = ops.where(eq_2, constant_23, where_5)
        constant_24 = ops.constant(0.0, torch.float32)
        where_7 = ops.where(eq_1, constant_24, where_6)
        constant_25 = ops.constant(2.0, torch.float32)
        mul = ops.mul(where_7, constant_25)
        get_index_2 = self.get_index('index0')
        load_1 = ops.load('full_default', get_index_2)
        where_8 = ops.where(eq, mul, load_1)
        get_index_3 = self.get_index('index0')
        store = ops.store('buf3', get_index_3, where_8, None)
        return store
op3 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[128], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, multi_processor_count=20), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '712B1D69F892A891D8FFA5075DCAB47CFF4E132D88BFC66744701CEAE226F127', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 100
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp19 = tl.load(in_ptr0 + (91))
        tmp20 = tl.broadcast_to(tmp19, [XBLOCK])
        tmp32 = tl.load(in_ptr1 + (x0), xmask)
        tmp0 = x0
        tmp1 = tl.full([1], 91, tl.int32)
        tmp2 = tmp0 == tmp1
        tmp3 = tl.full([1], 92, tl.int32)
        tmp4 = tmp1 == tmp3
        tmp5 = tl.full([1], 93, tl.int32)
        tmp6 = tmp1 == tmp5
        tmp7 = tl.full([1], 94, tl.int32)
        tmp8 = tmp1 == tmp7
        tmp9 = tl.full([1], 95, tl.int32)
        tmp10 = tmp1 == tmp9
        tmp11 = tl.full([1], 96, tl.int32)
        tmp12 = tmp1 == tmp11
        tmp13 = tl.full([1], 97, tl.int32)
        tmp14 = tmp1 == tmp13
        tmp15 = tl.full([1], 98, tl.int32)
        tmp16 = tmp1 == tmp15
        tmp17 = tl.full([1], 99, tl.int32)
        tmp18 = tmp1 == tmp17
        tmp21 = 0.0
        tmp22 = tl.where(tmp18, tmp21, tmp20)
        tmp23 = tl.where(tmp16, tmp21, tmp22)
        tmp24 = tl.where(tmp14, tmp21, tmp23)
        tmp25 = tl.where(tmp12, tmp21, tmp24)
        tmp26 = tl.where(tmp10, tmp21, tmp25)
        tmp27 = tl.where(tmp8, tmp21, tmp26)
        tmp28 = tl.where(tmp6, tmp21, tmp27)
        tmp29 = tl.where(tmp4, tmp21, tmp28)
        tmp30 = 2.0
        tmp31 = tmp29 * tmp30
        tmp33 = tl.where(tmp2, tmp31, tmp32)
        tl.store(out_ptr0 + (x0), tmp33, xmask)


op4: SchedulerNode(ComputedBuffer)
op4.writes = [MemoryDep('buf4', c0, {c0: 100}, None)]
op4.unmet_dependencies = []
op4.met_dependencies = [MemoryDep('tangents_1', c0, {c0: 100}, None)]
op4.outputs = [
    buf4: ComputedBuffer
    buf4.layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
    buf4.users = [
        NodeUser(node=SchedulerNode(name='op6'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op7'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op8'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op9'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op10'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op11'), can_inplace=True, is_weak=False),
        NodeUser(node=SchedulerNode(name='op12'), can_inplace=False, is_weak=False),
    ]
]
op4.group.device = cuda:0
op4.group.iteration = (100, 1)
op4.sizes = ([100], [])
tangents_1_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf4_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
class op4_loop_body:
    var_ranges = {z0: 100}
    index0 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        index_expr = ops.index_expr(get_index, torch.int32)
        constant = ops.constant(90, torch.int32)
        eq = ops.eq(index_expr, constant)
        get_index_1 = self.get_index('index0')
        index_expr_1 = ops.index_expr(get_index_1, torch.int32)
        constant_1 = ops.constant(91, torch.int32)
        eq_1 = ops.eq(index_expr_1, constant_1)
        get_index_2 = self.get_index('index0')
        index_expr_2 = ops.index_expr(get_index_2, torch.int32)
        constant_2 = ops.constant(92, torch.int32)
        eq_2 = ops.eq(index_expr_2, constant_2)
        get_index_3 = self.get_index('index0')
        index_expr_3 = ops.index_expr(get_index_3, torch.int32)
        constant_3 = ops.constant(93, torch.int32)
        eq_3 = ops.eq(index_expr_3, constant_3)
        get_index_4 = self.get_index('index0')
        index_expr_4 = ops.index_expr(get_index_4, torch.int32)
        constant_4 = ops.constant(94, torch.int32)
        eq_4 = ops.eq(index_expr_4, constant_4)
        get_index_5 = self.get_index('index0')
        index_expr_5 = ops.index_expr(get_index_5, torch.int32)
        constant_5 = ops.constant(95, torch.int32)
        eq_5 = ops.eq(index_expr_5, constant_5)
        get_index_6 = self.get_index('index0')
        index_expr_6 = ops.index_expr(get_index_6, torch.int32)
        constant_6 = ops.constant(96, torch.int32)
        eq_6 = ops.eq(index_expr_6, constant_6)
        get_index_7 = self.get_index('index0')
        index_expr_7 = ops.index_expr(get_index_7, torch.int32)
        constant_7 = ops.constant(97, torch.int32)
        eq_7 = ops.eq(index_expr_7, constant_7)
        get_index_8 = self.get_index('index0')
        index_expr_8 = ops.index_expr(get_index_8, torch.int32)
        constant_8 = ops.constant(98, torch.int32)
        eq_8 = ops.eq(index_expr_8, constant_8)
        get_index_9 = self.get_index('index0')
        index_expr_9 = ops.index_expr(get_index_9, torch.int32)
        constant_9 = ops.constant(99, torch.int32)
        eq_9 = ops.eq(index_expr_9, constant_9)
        get_index_10 = self.get_index('index0')
        load = ops.load('tangents_1', get_index_10)
        constant_10 = ops.constant(0.0, torch.float32)
        where = ops.where(eq_9, constant_10, load)
        constant_11 = ops.constant(0.0, torch.float32)
        where_1 = ops.where(eq_8, constant_11, where)
        constant_12 = ops.constant(0.0, torch.float32)
        where_2 = ops.where(eq_7, constant_12, where_1)
        constant_13 = ops.constant(0.0, torch.float32)
        where_3 = ops.where(eq_6, constant_13, where_2)
        constant_14 = ops.constant(0.0, torch.float32)
        where_4 = ops.where(eq_5, constant_14, where_3)
        constant_15 = ops.constant(0.0, torch.float32)
        where_5 = ops.where(eq_4, constant_15, where_4)
        constant_16 = ops.constant(0.0, torch.float32)
        where_6 = ops.where(eq_3, constant_16, where_5)
        constant_17 = ops.constant(0.0, torch.float32)
        where_7 = ops.where(eq_2, constant_17, where_6)
        constant_18 = ops.constant(0.0, torch.float32)
        where_8 = ops.where(eq_1, constant_18, where_7)
        constant_19 = ops.constant(0.0, torch.float32)
        where_9 = ops.where(eq, constant_19, where_8)
        get_index_11 = self.get_index('index0')
        store = ops.store('buf4', get_index_11, where_9, None)
        return store
op4 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[128], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, multi_processor_count=20), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '712B1D69F892A891D8FFA5075DCAB47CFF4E132D88BFC66744701CEAE226F127', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 100
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp21 = tl.load(in_ptr0 + (x0), xmask)
        tmp0 = x0
        tmp1 = tl.full([1], 90, tl.int32)
        tmp2 = tmp0 == tmp1
        tmp3 = tl.full([1], 91, tl.int32)
        tmp4 = tmp0 == tmp3
        tmp5 = tl.full([1], 92, tl.int32)
        tmp6 = tmp0 == tmp5
        tmp7 = tl.full([1], 93, tl.int32)
        tmp8 = tmp0 == tmp7
        tmp9 = tl.full([1], 94, tl.int32)
        tmp10 = tmp0 == tmp9
        tmp11 = tl.full([1], 95, tl.int32)
        tmp12 = tmp0 == tmp11
        tmp13 = tl.full([1], 96, tl.int32)
        tmp14 = tmp0 == tmp13
        tmp15 = tl.full([1], 97, tl.int32)
        tmp16 = tmp0 == tmp15
        tmp17 = tl.full([1], 98, tl.int32)
        tmp18 = tmp0 == tmp17
        tmp19 = tl.full([1], 99, tl.int32)
        tmp20 = tmp0 == tmp19
        tmp22 = 0.0
        tmp23 = tl.where(tmp20, tmp22, tmp21)
        tmp24 = tl.where(tmp18, tmp22, tmp23)
        tmp25 = tl.where(tmp16, tmp22, tmp24)
        tmp26 = tl.where(tmp14, tmp22, tmp25)
        tmp27 = tl.where(tmp12, tmp22, tmp26)
        tmp28 = tl.where(tmp10, tmp22, tmp27)
        tmp29 = tl.where(tmp8, tmp22, tmp28)
        tmp30 = tl.where(tmp6, tmp22, tmp29)
        tmp31 = tl.where(tmp4, tmp22, tmp30)
        tmp32 = tl.where(tmp2, tmp22, tmp31)
        tl.store(out_ptr0 + (x0), tmp32, xmask)


op5: SchedulerNode(ComputedBuffer)
op5.writes = [MemoryDep('buf5', 0, {}, None)]
op5.unmet_dependencies = []
op5.met_dependencies = [MemoryDep('tangents_1', 90, {}, None)]
op5.outputs = [
    buf5: ComputedBuffer
    buf5.layout = FixedLayout('cuda', torch.float32, size=[], stride=[])
    buf5.users = [NodeUser(node=SchedulerNode(name='op6'), can_inplace=False, is_weak=False)]
]
op5.group.device = cuda:0
op5.group.iteration = (1, 1)
op5.sizes = ([], [])
tangents_1_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf5_layout = FixedLayout('cuda', torch.float32, size=[], stride=[])
class op5_loop_body:
    var_ranges = {}
    index0 = 90
    index1 = 0
    def body(self, ops):
        constant = ops.constant(90, torch.int32)
        constant_1 = ops.constant(91, torch.int32)
        eq = ops.eq(constant, constant_1)
        constant_2 = ops.constant(90, torch.int32)
        constant_3 = ops.constant(92, torch.int32)
        eq_1 = ops.eq(constant_2, constant_3)
        constant_4 = ops.constant(90, torch.int32)
        constant_5 = ops.constant(93, torch.int32)
        eq_2 = ops.eq(constant_4, constant_5)
        constant_6 = ops.constant(90, torch.int32)
        constant_7 = ops.constant(94, torch.int32)
        eq_3 = ops.eq(constant_6, constant_7)
        constant_8 = ops.constant(90, torch.int32)
        constant_9 = ops.constant(95, torch.int32)
        eq_4 = ops.eq(constant_8, constant_9)
        constant_10 = ops.constant(90, torch.int32)
        constant_11 = ops.constant(96, torch.int32)
        eq_5 = ops.eq(constant_10, constant_11)
        constant_12 = ops.constant(90, torch.int32)
        constant_13 = ops.constant(97, torch.int32)
        eq_6 = ops.eq(constant_12, constant_13)
        constant_14 = ops.constant(90, torch.int32)
        constant_15 = ops.constant(98, torch.int32)
        eq_7 = ops.eq(constant_14, constant_15)
        constant_16 = ops.constant(90, torch.int32)
        constant_17 = ops.constant(99, torch.int32)
        eq_8 = ops.eq(constant_16, constant_17)
        get_index = self.get_index('index0')
        load = ops.load('tangents_1', get_index)
        constant_18 = ops.constant(0.0, torch.float32)
        where = ops.where(eq_8, constant_18, load)
        constant_19 = ops.constant(0.0, torch.float32)
        where_1 = ops.where(eq_7, constant_19, where)
        constant_20 = ops.constant(0.0, torch.float32)
        where_2 = ops.where(eq_6, constant_20, where_1)
        constant_21 = ops.constant(0.0, torch.float32)
        where_3 = ops.where(eq_5, constant_21, where_2)
        constant_22 = ops.constant(0.0, torch.float32)
        where_4 = ops.where(eq_4, constant_22, where_3)
        constant_23 = ops.constant(0.0, torch.float32)
        where_5 = ops.where(eq_3, constant_23, where_4)
        constant_24 = ops.constant(0.0, torch.float32)
        where_6 = ops.where(eq_2, constant_24, where_5)
        constant_25 = ops.constant(0.0, torch.float32)
        where_7 = ops.where(eq_1, constant_25, where_6)
        constant_26 = ops.constant(0.0, torch.float32)
        where_8 = ops.where(eq, constant_26, where_7)
        constant_27 = ops.constant(2.0, torch.float32)
        mul = ops.mul(where_8, constant_27)
        get_index_1 = self.get_index('index1')
        store = ops.store('buf5', get_index_1, mul, None)
        return store
op5 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[1], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, multi_processor_count=20), 'constants': {2: 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(2,))]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '712B1D69F892A891D8FFA5075DCAB47CFF4E132D88BFC66744701CEAE226F127', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 1
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = tl.full([XBLOCK], True, tl.int1)
        tmp19 = tl.load(in_ptr0 + (90))
        tmp20 = tl.broadcast_to(tmp19, [XBLOCK])
        tmp0 = tl.full([1], 90, tl.int32)
        tmp1 = tl.full([1], 91, tl.int32)
        tmp2 = tmp0 == tmp1
        tmp3 = tl.full([1], 92, tl.int32)
        tmp4 = tmp0 == tmp3
        tmp5 = tl.full([1], 93, tl.int32)
        tmp6 = tmp0 == tmp5
        tmp7 = tl.full([1], 94, tl.int32)
        tmp8 = tmp0 == tmp7
        tmp9 = tl.full([1], 95, tl.int32)
        tmp10 = tmp0 == tmp9
        tmp11 = tl.full([1], 96, tl.int32)
        tmp12 = tmp0 == tmp11
        tmp13 = tl.full([1], 97, tl.int32)
        tmp14 = tmp0 == tmp13
        tmp15 = tl.full([1], 98, tl.int32)
        tmp16 = tmp0 == tmp15
        tmp17 = tl.full([1], 99, tl.int32)
        tmp18 = tmp0 == tmp17
        tmp21 = 0.0
        tmp22 = tl.where(tmp18, tmp21, tmp20)
        tmp23 = tl.where(tmp16, tmp21, tmp22)
        tmp24 = tl.where(tmp14, tmp21, tmp23)
        tmp25 = tl.where(tmp12, tmp21, tmp24)
        tmp26 = tl.where(tmp10, tmp21, tmp25)
        tmp27 = tl.where(tmp8, tmp21, tmp26)
        tmp28 = tl.where(tmp6, tmp21, tmp27)
        tmp29 = tl.where(tmp4, tmp21, tmp28)
        tmp30 = tl.where(tmp2, tmp21, tmp29)
        tmp31 = 2.0
        tmp32 = tmp30 * tmp31
        tl.store(out_ptr0 + (tl.full([XBLOCK], 0, tl.int32)), tmp32, None)


op6: SchedulerNode(ComputedBuffer)
op6.writes = [MemoryDep('buf6', c0, {c0: 100}, None)]
op6.unmet_dependencies = 
    [   MemoryDep('buf2', c0, {c0: 100}, None),
        MemoryDep('buf3', c0, {c0: 100}, None),
        MemoryDep('buf4', 87, {}, None),
        MemoryDep('buf4', 88, {}, None),
        MemoryDep('buf4', 89, {}, None),
        MemoryDep('buf5', 0, {}, None)]
op6.met_dependencies = [MemoryDep('full_default', c0, {c0: 100}, None)]
op6.outputs = [
    buf6: ComputedBuffer
    buf6.layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
    buf6.users = [NodeUser(node=SchedulerNode(name='op7'), can_inplace=True, is_weak=False)]
]
op6.group.device = cuda:0
op6.group.iteration = (100, 1)
op6.sizes = ([100], [])
buf2_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf3_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf5_layout = FixedLayout('cuda', torch.float32, size=[], stride=[])
full_default_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf4_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf4_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf4_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf6_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
class op6_loop_body:
    var_ranges = {z0: 100}
    index0 = z0
    index1 = 0
    index2 = 89
    index3 = 88
    index4 = 87
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf2', get_index)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('buf3', get_index_1)
        add = ops.add(load, load_1)
        get_index_2 = self.get_index('index0')
        index_expr = ops.index_expr(get_index_2, torch.int32)
        constant = ops.constant(90, torch.int32)
        eq = ops.eq(index_expr, constant)
        get_index_3 = self.get_index('index1')
        load_2 = ops.load('buf5', get_index_3)
        get_index_4 = self.get_index('index0')
        load_3 = ops.load('full_default', get_index_4)
        where = ops.where(eq, load_2, load_3)
        add_1 = ops.add(add, where)
        get_index_5 = self.get_index('index0')
        index_expr_1 = ops.index_expr(get_index_5, torch.int32)
        constant_1 = ops.constant(89, torch.int32)
        eq_1 = ops.eq(index_expr_1, constant_1)
        get_index_6 = self.get_index('index2')
        load_4 = ops.load('buf4', get_index_6)
        constant_2 = ops.constant(2.0, torch.float32)
        mul = ops.mul(load_4, constant_2)
        get_index_7 = self.get_index('index0')
        load_5 = ops.load('full_default', get_index_7)
        where_1 = ops.where(eq_1, mul, load_5)
        add_2 = ops.add(add_1, where_1)
        get_index_8 = self.get_index('index0')
        index_expr_2 = ops.index_expr(get_index_8, torch.int32)
        constant_3 = ops.constant(88, torch.int32)
        eq_2 = ops.eq(index_expr_2, constant_3)
        constant_4 = ops.constant(88, torch.int32)
        constant_5 = ops.constant(89, torch.int32)
        eq_3 = ops.eq(constant_4, constant_5)
        get_index_9 = self.get_index('index3')
        load_6 = ops.load('buf4', get_index_9)
        constant_6 = ops.constant(0.0, torch.float32)
        where_2 = ops.where(eq_3, constant_6, load_6)
        constant_7 = ops.constant(2.0, torch.float32)
        mul_1 = ops.mul(where_2, constant_7)
        get_index_10 = self.get_index('index0')
        load_7 = ops.load('full_default', get_index_10)
        where_3 = ops.where(eq_2, mul_1, load_7)
        add_3 = ops.add(add_2, where_3)
        get_index_11 = self.get_index('index0')
        index_expr_3 = ops.index_expr(get_index_11, torch.int32)
        constant_8 = ops.constant(87, torch.int32)
        eq_4 = ops.eq(index_expr_3, constant_8)
        constant_9 = ops.constant(87, torch.int32)
        constant_10 = ops.constant(88, torch.int32)
        eq_5 = ops.eq(constant_9, constant_10)
        constant_11 = ops.constant(87, torch.int32)
        constant_12 = ops.constant(89, torch.int32)
        eq_6 = ops.eq(constant_11, constant_12)
        get_index_12 = self.get_index('index4')
        load_8 = ops.load('buf4', get_index_12)
        constant_13 = ops.constant(0.0, torch.float32)
        where_4 = ops.where(eq_6, constant_13, load_8)
        constant_14 = ops.constant(0.0, torch.float32)
        where_5 = ops.where(eq_5, constant_14, where_4)
        constant_15 = ops.constant(2.0, torch.float32)
        mul_2 = ops.mul(where_5, constant_15)
        get_index_13 = self.get_index('index0')
        load_9 = ops.load('full_default', get_index_13)
        where_6 = ops.where(eq_4, mul_2, load_9)
        add_4 = ops.add(add_3, where_6)
        get_index_14 = self.get_index('index0')
        store = ops.store('buf6', get_index_14, add_4, None)
        return store
op6 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[128], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, multi_processor_count=20), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_out_ptr0'], 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': '712B1D69F892A891D8FFA5075DCAB47CFF4E132D88BFC66744701CEAE226F127', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, xnumel, XBLOCK : tl.constexpr):
        xnumel = 100
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp0 = tl.load(in_out_ptr0 + (x0), xmask)
        tmp1 = tl.load(in_ptr0 + (x0), xmask)
        tmp6 = tl.load(in_ptr1 + (0))
        tmp7 = tl.broadcast_to(tmp6, [XBLOCK])
        tmp8 = tl.load(in_ptr2 + (x0), xmask)
        tmp13 = tl.load(in_ptr3 + (89))
        tmp14 = tl.broadcast_to(tmp13, [XBLOCK])
        tmp22 = tl.load(in_ptr3 + (88))
        tmp23 = tl.broadcast_to(tmp22, [XBLOCK])
        tmp33 = tl.load(in_ptr3 + (87))
        tmp34 = tl.broadcast_to(tmp33, [XBLOCK])
        tmp2 = tmp0 + tmp1
        tmp3 = x0
        tmp4 = tl.full([1], 90, tl.int32)
        tmp5 = tmp3 == tmp4
        tmp9 = tl.where(tmp5, tmp7, tmp8)
        tmp10 = tmp2 + tmp9
        tmp11 = tl.full([1], 89, tl.int32)
        tmp12 = tmp3 == tmp11
        tmp15 = 2.0
        tmp16 = tmp14 * tmp15
        tmp17 = tl.where(tmp12, tmp16, tmp8)
        tmp18 = tmp10 + tmp17
        tmp19 = tl.full([1], 88, tl.int32)
        tmp20 = tmp3 == tmp19
        tmp21 = tmp19 == tmp11
        tmp24 = 0.0
        tmp25 = tl.where(tmp21, tmp24, tmp23)
        tmp26 = tmp25 * tmp15
        tmp27 = tl.where(tmp20, tmp26, tmp8)
        tmp28 = tmp18 + tmp27
        tmp29 = tl.full([1], 87, tl.int32)
        tmp30 = tmp3 == tmp29
        tmp31 = tmp29 == tmp19
        tmp32 = tmp29 == tmp11
        tmp35 = tl.where(tmp32, tmp24, tmp34)
        tmp36 = tl.where(tmp31, tmp24, tmp35)
        tmp37 = tmp36 * tmp15
        tmp38 = tl.where(tmp30, tmp37, tmp8)
        tmp39 = tmp28 + tmp38
        tl.store(in_out_ptr0 + (x0), tmp39, xmask)


op7: SchedulerNode(ComputedBuffer)
op7.writes = [MemoryDep('buf7', c0, {c0: 100}, None)]
op7.unmet_dependencies = 
    [   MemoryDep('buf4', 85, {}, None),
        MemoryDep('buf4', 86, {}, None),
        MemoryDep('buf6', c0, {c0: 100}, None)]
op7.met_dependencies = [MemoryDep('full_default', c0, {c0: 100}, None)]
op7.outputs = [
    buf7: ComputedBuffer
    buf7.layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
    buf7.users = [NodeUser(node=SchedulerNode(name='op8'), can_inplace=True, is_weak=False)]
]
op7.group.device = cuda:0
op7.group.iteration = (100, 1)
op7.sizes = ([100], [])
buf6_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf4_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
full_default_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf4_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf7_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
class op7_loop_body:
    var_ranges = {z0: 100}
    index0 = z0
    index1 = 86
    index2 = 85
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf6', get_index)
        get_index_1 = self.get_index('index0')
        index_expr = ops.index_expr(get_index_1, torch.int32)
        constant = ops.constant(86, torch.int32)
        eq = ops.eq(index_expr, constant)
        constant_1 = ops.constant(86, torch.int32)
        constant_2 = ops.constant(87, torch.int32)
        eq_1 = ops.eq(constant_1, constant_2)
        constant_3 = ops.constant(86, torch.int32)
        constant_4 = ops.constant(88, torch.int32)
        eq_2 = ops.eq(constant_3, constant_4)
        constant_5 = ops.constant(86, torch.int32)
        constant_6 = ops.constant(89, torch.int32)
        eq_3 = ops.eq(constant_5, constant_6)
        get_index_2 = self.get_index('index1')
        load_1 = ops.load('buf4', get_index_2)
        constant_7 = ops.constant(0.0, torch.float32)
        where = ops.where(eq_3, constant_7, load_1)
        constant_8 = ops.constant(0.0, torch.float32)
        where_1 = ops.where(eq_2, constant_8, where)
        constant_9 = ops.constant(0.0, torch.float32)
        where_2 = ops.where(eq_1, constant_9, where_1)
        constant_10 = ops.constant(2.0, torch.float32)
        mul = ops.mul(where_2, constant_10)
        get_index_3 = self.get_index('index0')
        load_2 = ops.load('full_default', get_index_3)
        where_3 = ops.where(eq, mul, load_2)
        add = ops.add(load, where_3)
        get_index_4 = self.get_index('index0')
        index_expr_1 = ops.index_expr(get_index_4, torch.int32)
        constant_11 = ops.constant(85, torch.int32)
        eq_4 = ops.eq(index_expr_1, constant_11)
        constant_12 = ops.constant(85, torch.int32)
        constant_13 = ops.constant(86, torch.int32)
        eq_5 = ops.eq(constant_12, constant_13)
        constant_14 = ops.constant(85, torch.int32)
        constant_15 = ops.constant(87, torch.int32)
        eq_6 = ops.eq(constant_14, constant_15)
        constant_16 = ops.constant(85, torch.int32)
        constant_17 = ops.constant(88, torch.int32)
        eq_7 = ops.eq(constant_16, constant_17)
        constant_18 = ops.constant(85, torch.int32)
        constant_19 = ops.constant(89, torch.int32)
        eq_8 = ops.eq(constant_18, constant_19)
        get_index_5 = self.get_index('index2')
        load_3 = ops.load('buf4', get_index_5)
        constant_20 = ops.constant(0.0, torch.float32)
        where_4 = ops.where(eq_8, constant_20, load_3)
        constant_21 = ops.constant(0.0, torch.float32)
        where_5 = ops.where(eq_7, constant_21, where_4)
        constant_22 = ops.constant(0.0, torch.float32)
        where_6 = ops.where(eq_6, constant_22, where_5)
        constant_23 = ops.constant(0.0, torch.float32)
        where_7 = ops.where(eq_5, constant_23, where_6)
        constant_24 = ops.constant(2.0, torch.float32)
        mul_1 = ops.mul(where_7, constant_24)
        get_index_6 = self.get_index('index0')
        load_4 = ops.load('full_default', get_index_6)
        where_8 = ops.where(eq_4, mul_1, load_4)
        add_1 = ops.add(add, where_8)
        get_index_7 = self.get_index('index0')
        store = ops.store('buf7', get_index_7, add_1, None)
        return store
op7 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[128], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, multi_processor_count=20), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_out_ptr0'], 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': '712B1D69F892A891D8FFA5075DCAB47CFF4E132D88BFC66744701CEAE226F127', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_out_ptr0, in_ptr0, in_ptr1, xnumel, XBLOCK : tl.constexpr):
        xnumel = 100
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp0 = tl.load(in_out_ptr0 + (x0), xmask)
        tmp10 = tl.load(in_ptr0 + (86))
        tmp11 = tl.broadcast_to(tmp10, [XBLOCK])
        tmp18 = tl.load(in_ptr1 + (x0), xmask)
        tmp27 = tl.load(in_ptr0 + (85))
        tmp28 = tl.broadcast_to(tmp27, [XBLOCK])
        tmp1 = x0
        tmp2 = tl.full([1], 86, tl.int32)
        tmp3 = tmp1 == tmp2
        tmp4 = tl.full([1], 87, tl.int32)
        tmp5 = tmp2 == tmp4
        tmp6 = tl.full([1], 88, tl.int32)
        tmp7 = tmp2 == tmp6
        tmp8 = tl.full([1], 89, tl.int32)
        tmp9 = tmp2 == tmp8
        tmp12 = 0.0
        tmp13 = tl.where(tmp9, tmp12, tmp11)
        tmp14 = tl.where(tmp7, tmp12, tmp13)
        tmp15 = tl.where(tmp5, tmp12, tmp14)
        tmp16 = 2.0
        tmp17 = tmp15 * tmp16
        tmp19 = tl.where(tmp3, tmp17, tmp18)
        tmp20 = tmp0 + tmp19
        tmp21 = tl.full([1], 85, tl.int32)
        tmp22 = tmp1 == tmp21
        tmp23 = tmp21 == tmp2
        tmp24 = tmp21 == tmp4
        tmp25 = tmp21 == tmp6
        tmp26 = tmp21 == tmp8
        tmp29 = tl.where(tmp26, tmp12, tmp28)
        tmp30 = tl.where(tmp25, tmp12, tmp29)
        tmp31 = tl.where(tmp24, tmp12, tmp30)
        tmp32 = tl.where(tmp23, tmp12, tmp31)
        tmp33 = tmp32 * tmp16
        tmp34 = tl.where(tmp22, tmp33, tmp18)
        tmp35 = tmp20 + tmp34
        tl.store(in_out_ptr0 + (x0), tmp35, xmask)


op8: SchedulerNode(ComputedBuffer)
op8.writes = [MemoryDep('buf8', c0, {c0: 100}, None)]
op8.unmet_dependencies = 
    [   MemoryDep('buf4', 83, {}, None),
        MemoryDep('buf4', 84, {}, None),
        MemoryDep('buf7', c0, {c0: 100}, None)]
op8.met_dependencies = [MemoryDep('full_default', c0, {c0: 100}, None)]
op8.outputs = [
    buf8: ComputedBuffer
    buf8.layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
    buf8.users = [NodeUser(node=SchedulerNode(name='op9'), can_inplace=True, is_weak=False)]
]
op8.group.device = cuda:0
op8.group.iteration = (100, 1)
op8.sizes = ([100], [])
buf7_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf4_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
full_default_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf4_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf8_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
class op8_loop_body:
    var_ranges = {z0: 100}
    index0 = z0
    index1 = 84
    index2 = 83
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf7', get_index)
        get_index_1 = self.get_index('index0')
        index_expr = ops.index_expr(get_index_1, torch.int32)
        constant = ops.constant(84, torch.int32)
        eq = ops.eq(index_expr, constant)
        constant_1 = ops.constant(84, torch.int32)
        constant_2 = ops.constant(85, torch.int32)
        eq_1 = ops.eq(constant_1, constant_2)
        constant_3 = ops.constant(84, torch.int32)
        constant_4 = ops.constant(86, torch.int32)
        eq_2 = ops.eq(constant_3, constant_4)
        constant_5 = ops.constant(84, torch.int32)
        constant_6 = ops.constant(87, torch.int32)
        eq_3 = ops.eq(constant_5, constant_6)
        constant_7 = ops.constant(84, torch.int32)
        constant_8 = ops.constant(88, torch.int32)
        eq_4 = ops.eq(constant_7, constant_8)
        constant_9 = ops.constant(84, torch.int32)
        constant_10 = ops.constant(89, torch.int32)
        eq_5 = ops.eq(constant_9, constant_10)
        get_index_2 = self.get_index('index1')
        load_1 = ops.load('buf4', get_index_2)
        constant_11 = ops.constant(0.0, torch.float32)
        where = ops.where(eq_5, constant_11, load_1)
        constant_12 = ops.constant(0.0, torch.float32)
        where_1 = ops.where(eq_4, constant_12, where)
        constant_13 = ops.constant(0.0, torch.float32)
        where_2 = ops.where(eq_3, constant_13, where_1)
        constant_14 = ops.constant(0.0, torch.float32)
        where_3 = ops.where(eq_2, constant_14, where_2)
        constant_15 = ops.constant(0.0, torch.float32)
        where_4 = ops.where(eq_1, constant_15, where_3)
        constant_16 = ops.constant(2.0, torch.float32)
        mul = ops.mul(where_4, constant_16)
        get_index_3 = self.get_index('index0')
        load_2 = ops.load('full_default', get_index_3)
        where_5 = ops.where(eq, mul, load_2)
        add = ops.add(load, where_5)
        get_index_4 = self.get_index('index0')
        index_expr_1 = ops.index_expr(get_index_4, torch.int32)
        constant_17 = ops.constant(83, torch.int32)
        eq_6 = ops.eq(index_expr_1, constant_17)
        constant_18 = ops.constant(83, torch.int32)
        constant_19 = ops.constant(84, torch.int32)
        eq_7 = ops.eq(constant_18, constant_19)
        constant_20 = ops.constant(83, torch.int32)
        constant_21 = ops.constant(85, torch.int32)
        eq_8 = ops.eq(constant_20, constant_21)
        constant_22 = ops.constant(83, torch.int32)
        constant_23 = ops.constant(86, torch.int32)
        eq_9 = ops.eq(constant_22, constant_23)
        constant_24 = ops.constant(83, torch.int32)
        constant_25 = ops.constant(87, torch.int32)
        eq_10 = ops.eq(constant_24, constant_25)
        constant_26 = ops.constant(83, torch.int32)
        constant_27 = ops.constant(88, torch.int32)
        eq_11 = ops.eq(constant_26, constant_27)
        constant_28 = ops.constant(83, torch.int32)
        constant_29 = ops.constant(89, torch.int32)
        eq_12 = ops.eq(constant_28, constant_29)
        get_index_5 = self.get_index('index2')
        load_3 = ops.load('buf4', get_index_5)
        constant_30 = ops.constant(0.0, torch.float32)
        where_6 = ops.where(eq_12, constant_30, load_3)
        constant_31 = ops.constant(0.0, torch.float32)
        where_7 = ops.where(eq_11, constant_31, where_6)
        constant_32 = ops.constant(0.0, torch.float32)
        where_8 = ops.where(eq_10, constant_32, where_7)
        constant_33 = ops.constant(0.0, torch.float32)
        where_9 = ops.where(eq_9, constant_33, where_8)
        constant_34 = ops.constant(0.0, torch.float32)
        where_10 = ops.where(eq_8, constant_34, where_9)
        constant_35 = ops.constant(0.0, torch.float32)
        where_11 = ops.where(eq_7, constant_35, where_10)
        constant_36 = ops.constant(2.0, torch.float32)
        mul_1 = ops.mul(where_11, constant_36)
        get_index_6 = self.get_index('index0')
        load_4 = ops.load('full_default', get_index_6)
        where_12 = ops.where(eq_6, mul_1, load_4)
        add_1 = ops.add(add, where_12)
        get_index_7 = self.get_index('index0')
        store = ops.store('buf8', get_index_7, add_1, None)
        return store
op8 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[128], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, multi_processor_count=20), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_out_ptr0'], 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': '712B1D69F892A891D8FFA5075DCAB47CFF4E132D88BFC66744701CEAE226F127', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_out_ptr0, in_ptr0, in_ptr1, xnumel, XBLOCK : tl.constexpr):
        xnumel = 100
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp0 = tl.load(in_out_ptr0 + (x0), xmask)
        tmp14 = tl.load(in_ptr0 + (84))
        tmp15 = tl.broadcast_to(tmp14, [XBLOCK])
        tmp24 = tl.load(in_ptr1 + (x0), xmask)
        tmp35 = tl.load(in_ptr0 + (83))
        tmp36 = tl.broadcast_to(tmp35, [XBLOCK])
        tmp1 = x0
        tmp2 = tl.full([1], 84, tl.int32)
        tmp3 = tmp1 == tmp2
        tmp4 = tl.full([1], 85, tl.int32)
        tmp5 = tmp2 == tmp4
        tmp6 = tl.full([1], 86, tl.int32)
        tmp7 = tmp2 == tmp6
        tmp8 = tl.full([1], 87, tl.int32)
        tmp9 = tmp2 == tmp8
        tmp10 = tl.full([1], 88, tl.int32)
        tmp11 = tmp2 == tmp10
        tmp12 = tl.full([1], 89, tl.int32)
        tmp13 = tmp2 == tmp12
        tmp16 = 0.0
        tmp17 = tl.where(tmp13, tmp16, tmp15)
        tmp18 = tl.where(tmp11, tmp16, tmp17)
        tmp19 = tl.where(tmp9, tmp16, tmp18)
        tmp20 = tl.where(tmp7, tmp16, tmp19)
        tmp21 = tl.where(tmp5, tmp16, tmp20)
        tmp22 = 2.0
        tmp23 = tmp21 * tmp22
        tmp25 = tl.where(tmp3, tmp23, tmp24)
        tmp26 = tmp0 + tmp25
        tmp27 = tl.full([1], 83, tl.int32)
        tmp28 = tmp1 == tmp27
        tmp29 = tmp27 == tmp2
        tmp30 = tmp27 == tmp4
        tmp31 = tmp27 == tmp6
        tmp32 = tmp27 == tmp8
        tmp33 = tmp27 == tmp10
        tmp34 = tmp27 == tmp12
        tmp37 = tl.where(tmp34, tmp16, tmp36)
        tmp38 = tl.where(tmp33, tmp16, tmp37)
        tmp39 = tl.where(tmp32, tmp16, tmp38)
        tmp40 = tl.where(tmp31, tmp16, tmp39)
        tmp41 = tl.where(tmp30, tmp16, tmp40)
        tmp42 = tl.where(tmp29, tmp16, tmp41)
        tmp43 = tmp42 * tmp22
        tmp44 = tl.where(tmp28, tmp43, tmp24)
        tmp45 = tmp26 + tmp44
        tl.store(in_out_ptr0 + (x0), tmp45, xmask)


op9: SchedulerNode(ComputedBuffer)
op9.writes = [MemoryDep('buf9', c0, {c0: 100}, None)]
op9.unmet_dependencies = [MemoryDep('buf4', 82, {}, None), MemoryDep('buf8', c0, {c0: 100}, None)]
op9.met_dependencies = [MemoryDep('full_default', c0, {c0: 100}, None)]
op9.outputs = [
    buf9: ComputedBuffer
    buf9.layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
    buf9.users = [NodeUser(node=SchedulerNode(name='op13'), can_inplace=True, is_weak=False)]
]
op9.group.device = cuda:0
op9.group.iteration = (100, 1)
op9.sizes = ([100], [])
buf8_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf4_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
full_default_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf9_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
class op9_loop_body:
    var_ranges = {z0: 100}
    index0 = z0
    index1 = 82
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf8', get_index)
        get_index_1 = self.get_index('index0')
        index_expr = ops.index_expr(get_index_1, torch.int32)
        constant = ops.constant(82, torch.int32)
        eq = ops.eq(index_expr, constant)
        constant_1 = ops.constant(82, torch.int32)
        constant_2 = ops.constant(83, torch.int32)
        eq_1 = ops.eq(constant_1, constant_2)
        constant_3 = ops.constant(82, torch.int32)
        constant_4 = ops.constant(84, torch.int32)
        eq_2 = ops.eq(constant_3, constant_4)
        constant_5 = ops.constant(82, torch.int32)
        constant_6 = ops.constant(85, torch.int32)
        eq_3 = ops.eq(constant_5, constant_6)
        constant_7 = ops.constant(82, torch.int32)
        constant_8 = ops.constant(86, torch.int32)
        eq_4 = ops.eq(constant_7, constant_8)
        constant_9 = ops.constant(82, torch.int32)
        constant_10 = ops.constant(87, torch.int32)
        eq_5 = ops.eq(constant_9, constant_10)
        constant_11 = ops.constant(82, torch.int32)
        constant_12 = ops.constant(88, torch.int32)
        eq_6 = ops.eq(constant_11, constant_12)
        constant_13 = ops.constant(82, torch.int32)
        constant_14 = ops.constant(89, torch.int32)
        eq_7 = ops.eq(constant_13, constant_14)
        get_index_2 = self.get_index('index1')
        load_1 = ops.load('buf4', get_index_2)
        constant_15 = ops.constant(0.0, torch.float32)
        where = ops.where(eq_7, constant_15, load_1)
        constant_16 = ops.constant(0.0, torch.float32)
        where_1 = ops.where(eq_6, constant_16, where)
        constant_17 = ops.constant(0.0, torch.float32)
        where_2 = ops.where(eq_5, constant_17, where_1)
        constant_18 = ops.constant(0.0, torch.float32)
        where_3 = ops.where(eq_4, constant_18, where_2)
        constant_19 = ops.constant(0.0, torch.float32)
        where_4 = ops.where(eq_3, constant_19, where_3)
        constant_20 = ops.constant(0.0, torch.float32)
        where_5 = ops.where(eq_2, constant_20, where_4)
        constant_21 = ops.constant(0.0, torch.float32)
        where_6 = ops.where(eq_1, constant_21, where_5)
        constant_22 = ops.constant(2.0, torch.float32)
        mul = ops.mul(where_6, constant_22)
        get_index_3 = self.get_index('index0')
        load_2 = ops.load('full_default', get_index_3)
        where_7 = ops.where(eq, mul, load_2)
        add = ops.add(load, where_7)
        get_index_4 = self.get_index('index0')
        store = ops.store('buf9', get_index_4, add, None)
        return store
op9 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[128], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, multi_processor_count=20), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_out_ptr0'], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 0, 'backend_hash': '712B1D69F892A891D8FFA5075DCAB47CFF4E132D88BFC66744701CEAE226F127', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_out_ptr0, in_ptr0, in_ptr1, xnumel, XBLOCK : tl.constexpr):
        xnumel = 100
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp0 = tl.load(in_out_ptr0 + (x0), xmask)
        tmp18 = tl.load(in_ptr0 + (82))
        tmp19 = tl.broadcast_to(tmp18, [XBLOCK])
        tmp30 = tl.load(in_ptr1 + (x0), xmask)
        tmp1 = x0
        tmp2 = tl.full([1], 82, tl.int32)
        tmp3 = tmp1 == tmp2
        tmp4 = tl.full([1], 83, tl.int32)
        tmp5 = tmp2 == tmp4
        tmp6 = tl.full([1], 84, tl.int32)
        tmp7 = tmp2 == tmp6
        tmp8 = tl.full([1], 85, tl.int32)
        tmp9 = tmp2 == tmp8
        tmp10 = tl.full([1], 86, tl.int32)
        tmp11 = tmp2 == tmp10
        tmp12 = tl.full([1], 87, tl.int32)
        tmp13 = tmp2 == tmp12
        tmp14 = tl.full([1], 88, tl.int32)
        tmp15 = tmp2 == tmp14
        tmp16 = tl.full([1], 89, tl.int32)
        tmp17 = tmp2 == tmp16
        tmp20 = 0.0
        tmp21 = tl.where(tmp17, tmp20, tmp19)
        tmp22 = tl.where(tmp15, tmp20, tmp21)
        tmp23 = tl.where(tmp13, tmp20, tmp22)
        tmp24 = tl.where(tmp11, tmp20, tmp23)
        tmp25 = tl.where(tmp9, tmp20, tmp24)
        tmp26 = tl.where(tmp7, tmp20, tmp25)
        tmp27 = tl.where(tmp5, tmp20, tmp26)
        tmp28 = 2.0
        tmp29 = tmp27 * tmp28
        tmp31 = tl.where(tmp3, tmp29, tmp30)
        tmp32 = tmp0 + tmp31
        tl.store(in_out_ptr0 + (x0), tmp32, xmask)


op10: SchedulerNode(ComputedBuffer)
op10.writes = [MemoryDep('buf10', c0, {c0: 100}, None)]
op10.unmet_dependencies = [MemoryDep('buf4', 81, {}, None)]
op10.met_dependencies = [MemoryDep('full_default', c0, {c0: 100}, None)]
op10.outputs = [
    buf10: ComputedBuffer
    buf10.layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
    buf10.users = [NodeUser(node=SchedulerNode(name='op13'), can_inplace=True, is_weak=False)]
]
op10.group.device = cuda:0
op10.group.iteration = (100, 1)
op10.sizes = ([100], [])
buf4_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
full_default_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf10_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
class op10_loop_body:
    var_ranges = {z0: 100}
    index0 = z0
    index1 = 81
    def body(self, ops):
        get_index = self.get_index('index0')
        index_expr = ops.index_expr(get_index, torch.int32)
        constant = ops.constant(81, torch.int32)
        eq = ops.eq(index_expr, constant)
        constant_1 = ops.constant(81, torch.int32)
        constant_2 = ops.constant(82, torch.int32)
        eq_1 = ops.eq(constant_1, constant_2)
        constant_3 = ops.constant(81, torch.int32)
        constant_4 = ops.constant(83, torch.int32)
        eq_2 = ops.eq(constant_3, constant_4)
        constant_5 = ops.constant(81, torch.int32)
        constant_6 = ops.constant(84, torch.int32)
        eq_3 = ops.eq(constant_5, constant_6)
        constant_7 = ops.constant(81, torch.int32)
        constant_8 = ops.constant(85, torch.int32)
        eq_4 = ops.eq(constant_7, constant_8)
        constant_9 = ops.constant(81, torch.int32)
        constant_10 = ops.constant(86, torch.int32)
        eq_5 = ops.eq(constant_9, constant_10)
        constant_11 = ops.constant(81, torch.int32)
        constant_12 = ops.constant(87, torch.int32)
        eq_6 = ops.eq(constant_11, constant_12)
        constant_13 = ops.constant(81, torch.int32)
        constant_14 = ops.constant(88, torch.int32)
        eq_7 = ops.eq(constant_13, constant_14)
        constant_15 = ops.constant(81, torch.int32)
        constant_16 = ops.constant(89, torch.int32)
        eq_8 = ops.eq(constant_15, constant_16)
        get_index_1 = self.get_index('index1')
        load = ops.load('buf4', get_index_1)
        constant_17 = ops.constant(0.0, torch.float32)
        where = ops.where(eq_8, constant_17, load)
        constant_18 = ops.constant(0.0, torch.float32)
        where_1 = ops.where(eq_7, constant_18, where)
        constant_19 = ops.constant(0.0, torch.float32)
        where_2 = ops.where(eq_6, constant_19, where_1)
        constant_20 = ops.constant(0.0, torch.float32)
        where_3 = ops.where(eq_5, constant_20, where_2)
        constant_21 = ops.constant(0.0, torch.float32)
        where_4 = ops.where(eq_4, constant_21, where_3)
        constant_22 = ops.constant(0.0, torch.float32)
        where_5 = ops.where(eq_3, constant_22, where_4)
        constant_23 = ops.constant(0.0, torch.float32)
        where_6 = ops.where(eq_2, constant_23, where_5)
        constant_24 = ops.constant(0.0, torch.float32)
        where_7 = ops.where(eq_1, constant_24, where_6)
        constant_25 = ops.constant(2.0, torch.float32)
        mul = ops.mul(where_7, constant_25)
        get_index_2 = self.get_index('index0')
        load_1 = ops.load('full_default', get_index_2)
        where_8 = ops.where(eq, mul, load_1)
        get_index_3 = self.get_index('index0')
        store = ops.store('buf10', get_index_3, where_8, None)
        return store
op10 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[128], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, multi_processor_count=20), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '712B1D69F892A891D8FFA5075DCAB47CFF4E132D88BFC66744701CEAE226F127', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 100
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp19 = tl.load(in_ptr0 + (81))
        tmp20 = tl.broadcast_to(tmp19, [XBLOCK])
        tmp32 = tl.load(in_ptr1 + (x0), xmask)
        tmp0 = x0
        tmp1 = tl.full([1], 81, tl.int32)
        tmp2 = tmp0 == tmp1
        tmp3 = tl.full([1], 82, tl.int32)
        tmp4 = tmp1 == tmp3
        tmp5 = tl.full([1], 83, tl.int32)
        tmp6 = tmp1 == tmp5
        tmp7 = tl.full([1], 84, tl.int32)
        tmp8 = tmp1 == tmp7
        tmp9 = tl.full([1], 85, tl.int32)
        tmp10 = tmp1 == tmp9
        tmp11 = tl.full([1], 86, tl.int32)
        tmp12 = tmp1 == tmp11
        tmp13 = tl.full([1], 87, tl.int32)
        tmp14 = tmp1 == tmp13
        tmp15 = tl.full([1], 88, tl.int32)
        tmp16 = tmp1 == tmp15
        tmp17 = tl.full([1], 89, tl.int32)
        tmp18 = tmp1 == tmp17
        tmp21 = 0.0
        tmp22 = tl.where(tmp18, tmp21, tmp20)
        tmp23 = tl.where(tmp16, tmp21, tmp22)
        tmp24 = tl.where(tmp14, tmp21, tmp23)
        tmp25 = tl.where(tmp12, tmp21, tmp24)
        tmp26 = tl.where(tmp10, tmp21, tmp25)
        tmp27 = tl.where(tmp8, tmp21, tmp26)
        tmp28 = tl.where(tmp6, tmp21, tmp27)
        tmp29 = tl.where(tmp4, tmp21, tmp28)
        tmp30 = 2.0
        tmp31 = tmp29 * tmp30
        tmp33 = tl.where(tmp2, tmp31, tmp32)
        tl.store(out_ptr0 + (x0), tmp33, xmask)


op11: SchedulerNode(ComputedBuffer)
op11.writes = [MemoryDep('buf11', c0, {c0: 100}, None)]
op11.unmet_dependencies = [MemoryDep('buf4', c0, {c0: 100}, None)]
op11.met_dependencies = []
op11.outputs = [
    buf11: ComputedBuffer
    buf11.layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
    buf11.users = [
        NodeUser(node=SchedulerNode(name='op13'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op14'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op15'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op16'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op17'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op18'), can_inplace=True, is_weak=False),
        NodeUser(node=SchedulerNode(name='op19'), can_inplace=False, is_weak=False),
    ]
]
op11.group.device = cuda:0
op11.group.iteration = (100, 1)
op11.sizes = ([100], [])
buf4_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf11_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
class op11_loop_body:
    var_ranges = {z0: 100}
    index0 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        index_expr = ops.index_expr(get_index, torch.int32)
        constant = ops.constant(80, torch.int32)
        eq = ops.eq(index_expr, constant)
        get_index_1 = self.get_index('index0')
        index_expr_1 = ops.index_expr(get_index_1, torch.int32)
        constant_1 = ops.constant(81, torch.int32)
        eq_1 = ops.eq(index_expr_1, constant_1)
        get_index_2 = self.get_index('index0')
        index_expr_2 = ops.index_expr(get_index_2, torch.int32)
        constant_2 = ops.constant(82, torch.int32)
        eq_2 = ops.eq(index_expr_2, constant_2)
        get_index_3 = self.get_index('index0')
        index_expr_3 = ops.index_expr(get_index_3, torch.int32)
        constant_3 = ops.constant(83, torch.int32)
        eq_3 = ops.eq(index_expr_3, constant_3)
        get_index_4 = self.get_index('index0')
        index_expr_4 = ops.index_expr(get_index_4, torch.int32)
        constant_4 = ops.constant(84, torch.int32)
        eq_4 = ops.eq(index_expr_4, constant_4)
        get_index_5 = self.get_index('index0')
        index_expr_5 = ops.index_expr(get_index_5, torch.int32)
        constant_5 = ops.constant(85, torch.int32)
        eq_5 = ops.eq(index_expr_5, constant_5)
        get_index_6 = self.get_index('index0')
        index_expr_6 = ops.index_expr(get_index_6, torch.int32)
        constant_6 = ops.constant(86, torch.int32)
        eq_6 = ops.eq(index_expr_6, constant_6)
        get_index_7 = self.get_index('index0')
        index_expr_7 = ops.index_expr(get_index_7, torch.int32)
        constant_7 = ops.constant(87, torch.int32)
        eq_7 = ops.eq(index_expr_7, constant_7)
        get_index_8 = self.get_index('index0')
        index_expr_8 = ops.index_expr(get_index_8, torch.int32)
        constant_8 = ops.constant(88, torch.int32)
        eq_8 = ops.eq(index_expr_8, constant_8)
        get_index_9 = self.get_index('index0')
        index_expr_9 = ops.index_expr(get_index_9, torch.int32)
        constant_9 = ops.constant(89, torch.int32)
        eq_9 = ops.eq(index_expr_9, constant_9)
        get_index_10 = self.get_index('index0')
        load = ops.load('buf4', get_index_10)
        constant_10 = ops.constant(0.0, torch.float32)
        where = ops.where(eq_9, constant_10, load)
        constant_11 = ops.constant(0.0, torch.float32)
        where_1 = ops.where(eq_8, constant_11, where)
        constant_12 = ops.constant(0.0, torch.float32)
        where_2 = ops.where(eq_7, constant_12, where_1)
        constant_13 = ops.constant(0.0, torch.float32)
        where_3 = ops.where(eq_6, constant_13, where_2)
        constant_14 = ops.constant(0.0, torch.float32)
        where_4 = ops.where(eq_5, constant_14, where_3)
        constant_15 = ops.constant(0.0, torch.float32)
        where_5 = ops.where(eq_4, constant_15, where_4)
        constant_16 = ops.constant(0.0, torch.float32)
        where_6 = ops.where(eq_3, constant_16, where_5)
        constant_17 = ops.constant(0.0, torch.float32)
        where_7 = ops.where(eq_2, constant_17, where_6)
        constant_18 = ops.constant(0.0, torch.float32)
        where_8 = ops.where(eq_1, constant_18, where_7)
        constant_19 = ops.constant(0.0, torch.float32)
        where_9 = ops.where(eq, constant_19, where_8)
        get_index_11 = self.get_index('index0')
        store = ops.store('buf11', get_index_11, where_9, None)
        return store
op11 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[128], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, multi_processor_count=20), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '712B1D69F892A891D8FFA5075DCAB47CFF4E132D88BFC66744701CEAE226F127', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 100
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp21 = tl.load(in_ptr0 + (x0), xmask)
        tmp0 = x0
        tmp1 = tl.full([1], 80, tl.int32)
        tmp2 = tmp0 == tmp1
        tmp3 = tl.full([1], 81, tl.int32)
        tmp4 = tmp0 == tmp3
        tmp5 = tl.full([1], 82, tl.int32)
        tmp6 = tmp0 == tmp5
        tmp7 = tl.full([1], 83, tl.int32)
        tmp8 = tmp0 == tmp7
        tmp9 = tl.full([1], 84, tl.int32)
        tmp10 = tmp0 == tmp9
        tmp11 = tl.full([1], 85, tl.int32)
        tmp12 = tmp0 == tmp11
        tmp13 = tl.full([1], 86, tl.int32)
        tmp14 = tmp0 == tmp13
        tmp15 = tl.full([1], 87, tl.int32)
        tmp16 = tmp0 == tmp15
        tmp17 = tl.full([1], 88, tl.int32)
        tmp18 = tmp0 == tmp17
        tmp19 = tl.full([1], 89, tl.int32)
        tmp20 = tmp0 == tmp19
        tmp22 = 0.0
        tmp23 = tl.where(tmp20, tmp22, tmp21)
        tmp24 = tl.where(tmp18, tmp22, tmp23)
        tmp25 = tl.where(tmp16, tmp22, tmp24)
        tmp26 = tl.where(tmp14, tmp22, tmp25)
        tmp27 = tl.where(tmp12, tmp22, tmp26)
        tmp28 = tl.where(tmp10, tmp22, tmp27)
        tmp29 = tl.where(tmp8, tmp22, tmp28)
        tmp30 = tl.where(tmp6, tmp22, tmp29)
        tmp31 = tl.where(tmp4, tmp22, tmp30)
        tmp32 = tl.where(tmp2, tmp22, tmp31)
        tl.store(out_ptr0 + (x0), tmp32, xmask)


op12: SchedulerNode(ComputedBuffer)
op12.writes = [MemoryDep('buf12', 0, {}, None)]
op12.unmet_dependencies = [MemoryDep('buf4', 80, {}, None)]
op12.met_dependencies = []
op12.outputs = [
    buf12: ComputedBuffer
    buf12.layout = FixedLayout('cuda', torch.float32, size=[], stride=[])
    buf12.users = [NodeUser(node=SchedulerNode(name='op13'), can_inplace=False, is_weak=False)]
]
op12.group.device = cuda:0
op12.group.iteration = (1, 1)
op12.sizes = ([], [])
buf4_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf12_layout = FixedLayout('cuda', torch.float32, size=[], stride=[])
class op12_loop_body:
    var_ranges = {}
    index0 = 80
    index1 = 0
    def body(self, ops):
        constant = ops.constant(80, torch.int32)
        constant_1 = ops.constant(81, torch.int32)
        eq = ops.eq(constant, constant_1)
        constant_2 = ops.constant(80, torch.int32)
        constant_3 = ops.constant(82, torch.int32)
        eq_1 = ops.eq(constant_2, constant_3)
        constant_4 = ops.constant(80, torch.int32)
        constant_5 = ops.constant(83, torch.int32)
        eq_2 = ops.eq(constant_4, constant_5)
        constant_6 = ops.constant(80, torch.int32)
        constant_7 = ops.constant(84, torch.int32)
        eq_3 = ops.eq(constant_6, constant_7)
        constant_8 = ops.constant(80, torch.int32)
        constant_9 = ops.constant(85, torch.int32)
        eq_4 = ops.eq(constant_8, constant_9)
        constant_10 = ops.constant(80, torch.int32)
        constant_11 = ops.constant(86, torch.int32)
        eq_5 = ops.eq(constant_10, constant_11)
        constant_12 = ops.constant(80, torch.int32)
        constant_13 = ops.constant(87, torch.int32)
        eq_6 = ops.eq(constant_12, constant_13)
        constant_14 = ops.constant(80, torch.int32)
        constant_15 = ops.constant(88, torch.int32)
        eq_7 = ops.eq(constant_14, constant_15)
        constant_16 = ops.constant(80, torch.int32)
        constant_17 = ops.constant(89, torch.int32)
        eq_8 = ops.eq(constant_16, constant_17)
        get_index = self.get_index('index0')
        load = ops.load('buf4', get_index)
        constant_18 = ops.constant(0.0, torch.float32)
        where = ops.where(eq_8, constant_18, load)
        constant_19 = ops.constant(0.0, torch.float32)
        where_1 = ops.where(eq_7, constant_19, where)
        constant_20 = ops.constant(0.0, torch.float32)
        where_2 = ops.where(eq_6, constant_20, where_1)
        constant_21 = ops.constant(0.0, torch.float32)
        where_3 = ops.where(eq_5, constant_21, where_2)
        constant_22 = ops.constant(0.0, torch.float32)
        where_4 = ops.where(eq_4, constant_22, where_3)
        constant_23 = ops.constant(0.0, torch.float32)
        where_5 = ops.where(eq_3, constant_23, where_4)
        constant_24 = ops.constant(0.0, torch.float32)
        where_6 = ops.where(eq_2, constant_24, where_5)
        constant_25 = ops.constant(0.0, torch.float32)
        where_7 = ops.where(eq_1, constant_25, where_6)
        constant_26 = ops.constant(0.0, torch.float32)
        where_8 = ops.where(eq, constant_26, where_7)
        constant_27 = ops.constant(2.0, torch.float32)
        mul = ops.mul(where_8, constant_27)
        get_index_1 = self.get_index('index1')
        store = ops.store('buf12', get_index_1, mul, None)
        return store
op12 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[1], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, multi_processor_count=20), 'constants': {2: 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(2,))]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '712B1D69F892A891D8FFA5075DCAB47CFF4E132D88BFC66744701CEAE226F127', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 1
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = tl.full([XBLOCK], True, tl.int1)
        tmp19 = tl.load(in_ptr0 + (80))
        tmp20 = tl.broadcast_to(tmp19, [XBLOCK])
        tmp0 = tl.full([1], 80, tl.int32)
        tmp1 = tl.full([1], 81, tl.int32)
        tmp2 = tmp0 == tmp1
        tmp3 = tl.full([1], 82, tl.int32)
        tmp4 = tmp0 == tmp3
        tmp5 = tl.full([1], 83, tl.int32)
        tmp6 = tmp0 == tmp5
        tmp7 = tl.full([1], 84, tl.int32)
        tmp8 = tmp0 == tmp7
        tmp9 = tl.full([1], 85, tl.int32)
        tmp10 = tmp0 == tmp9
        tmp11 = tl.full([1], 86, tl.int32)
        tmp12 = tmp0 == tmp11
        tmp13 = tl.full([1], 87, tl.int32)
        tmp14 = tmp0 == tmp13
        tmp15 = tl.full([1], 88, tl.int32)
        tmp16 = tmp0 == tmp15
        tmp17 = tl.full([1], 89, tl.int32)
        tmp18 = tmp0 == tmp17
        tmp21 = 0.0
        tmp22 = tl.where(tmp18, tmp21, tmp20)
        tmp23 = tl.where(tmp16, tmp21, tmp22)
        tmp24 = tl.where(tmp14, tmp21, tmp23)
        tmp25 = tl.where(tmp12, tmp21, tmp24)
        tmp26 = tl.where(tmp10, tmp21, tmp25)
        tmp27 = tl.where(tmp8, tmp21, tmp26)
        tmp28 = tl.where(tmp6, tmp21, tmp27)
        tmp29 = tl.where(tmp4, tmp21, tmp28)
        tmp30 = tl.where(tmp2, tmp21, tmp29)
        tmp31 = 2.0
        tmp32 = tmp30 * tmp31
        tl.store(out_ptr0 + (tl.full([XBLOCK], 0, tl.int32)), tmp32, None)


op13: SchedulerNode(ComputedBuffer)
op13.writes = [MemoryDep('buf13', c0, {c0: 100}, None)]
op13.unmet_dependencies = 
    [   MemoryDep('buf10', c0, {c0: 100}, None),
        MemoryDep('buf11', 77, {}, None),
        MemoryDep('buf11', 78, {}, None),
        MemoryDep('buf11', 79, {}, None),
        MemoryDep('buf12', 0, {}, None),
        MemoryDep('buf9', c0, {c0: 100}, None)]
op13.met_dependencies = [MemoryDep('full_default', c0, {c0: 100}, None)]
op13.outputs = [
    buf13: ComputedBuffer
    buf13.layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
    buf13.users = [NodeUser(node=SchedulerNode(name='op14'), can_inplace=True, is_weak=False)]
]
op13.group.device = cuda:0
op13.group.iteration = (100, 1)
op13.sizes = ([100], [])
buf9_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf10_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf12_layout = FixedLayout('cuda', torch.float32, size=[], stride=[])
full_default_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf11_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf11_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf11_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf13_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
class op13_loop_body:
    var_ranges = {z0: 100}
    index0 = z0
    index1 = 0
    index2 = 79
    index3 = 78
    index4 = 77
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf9', get_index)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('buf10', get_index_1)
        add = ops.add(load, load_1)
        get_index_2 = self.get_index('index0')
        index_expr = ops.index_expr(get_index_2, torch.int32)
        constant = ops.constant(80, torch.int32)
        eq = ops.eq(index_expr, constant)
        get_index_3 = self.get_index('index1')
        load_2 = ops.load('buf12', get_index_3)
        get_index_4 = self.get_index('index0')
        load_3 = ops.load('full_default', get_index_4)
        where = ops.where(eq, load_2, load_3)
        add_1 = ops.add(add, where)
        get_index_5 = self.get_index('index0')
        index_expr_1 = ops.index_expr(get_index_5, torch.int32)
        constant_1 = ops.constant(79, torch.int32)
        eq_1 = ops.eq(index_expr_1, constant_1)
        get_index_6 = self.get_index('index2')
        load_4 = ops.load('buf11', get_index_6)
        constant_2 = ops.constant(2.0, torch.float32)
        mul = ops.mul(load_4, constant_2)
        get_index_7 = self.get_index('index0')
        load_5 = ops.load('full_default', get_index_7)
        where_1 = ops.where(eq_1, mul, load_5)
        add_2 = ops.add(add_1, where_1)
        get_index_8 = self.get_index('index0')
        index_expr_2 = ops.index_expr(get_index_8, torch.int32)
        constant_3 = ops.constant(78, torch.int32)
        eq_2 = ops.eq(index_expr_2, constant_3)
        constant_4 = ops.constant(78, torch.int32)
        constant_5 = ops.constant(79, torch.int32)
        eq_3 = ops.eq(constant_4, constant_5)
        get_index_9 = self.get_index('index3')
        load_6 = ops.load('buf11', get_index_9)
        constant_6 = ops.constant(0.0, torch.float32)
        where_2 = ops.where(eq_3, constant_6, load_6)
        constant_7 = ops.constant(2.0, torch.float32)
        mul_1 = ops.mul(where_2, constant_7)
        get_index_10 = self.get_index('index0')
        load_7 = ops.load('full_default', get_index_10)
        where_3 = ops.where(eq_2, mul_1, load_7)
        add_3 = ops.add(add_2, where_3)
        get_index_11 = self.get_index('index0')
        index_expr_3 = ops.index_expr(get_index_11, torch.int32)
        constant_8 = ops.constant(77, torch.int32)
        eq_4 = ops.eq(index_expr_3, constant_8)
        constant_9 = ops.constant(77, torch.int32)
        constant_10 = ops.constant(78, torch.int32)
        eq_5 = ops.eq(constant_9, constant_10)
        constant_11 = ops.constant(77, torch.int32)
        constant_12 = ops.constant(79, torch.int32)
        eq_6 = ops.eq(constant_11, constant_12)
        get_index_12 = self.get_index('index4')
        load_8 = ops.load('buf11', get_index_12)
        constant_13 = ops.constant(0.0, torch.float32)
        where_4 = ops.where(eq_6, constant_13, load_8)
        constant_14 = ops.constant(0.0, torch.float32)
        where_5 = ops.where(eq_5, constant_14, where_4)
        constant_15 = ops.constant(2.0, torch.float32)
        mul_2 = ops.mul(where_5, constant_15)
        get_index_13 = self.get_index('index0')
        load_9 = ops.load('full_default', get_index_13)
        where_6 = ops.where(eq_4, mul_2, load_9)
        add_4 = ops.add(add_3, where_6)
        get_index_14 = self.get_index('index0')
        store = ops.store('buf13', get_index_14, add_4, None)
        return store
op13 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[128], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, multi_processor_count=20), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_out_ptr0'], 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': '712B1D69F892A891D8FFA5075DCAB47CFF4E132D88BFC66744701CEAE226F127', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, xnumel, XBLOCK : tl.constexpr):
        xnumel = 100
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp0 = tl.load(in_ptr0 + (x0), xmask)
        tmp1 = tl.load(in_out_ptr0 + (x0), xmask)
        tmp6 = tl.load(in_ptr1 + (0))
        tmp7 = tl.broadcast_to(tmp6, [XBLOCK])
        tmp8 = tl.load(in_ptr2 + (x0), xmask)
        tmp13 = tl.load(in_ptr3 + (79))
        tmp14 = tl.broadcast_to(tmp13, [XBLOCK])
        tmp22 = tl.load(in_ptr3 + (78))
        tmp23 = tl.broadcast_to(tmp22, [XBLOCK])
        tmp33 = tl.load(in_ptr3 + (77))
        tmp34 = tl.broadcast_to(tmp33, [XBLOCK])
        tmp2 = tmp0 + tmp1
        tmp3 = x0
        tmp4 = tl.full([1], 80, tl.int32)
        tmp5 = tmp3 == tmp4
        tmp9 = tl.where(tmp5, tmp7, tmp8)
        tmp10 = tmp2 + tmp9
        tmp11 = tl.full([1], 79, tl.int32)
        tmp12 = tmp3 == tmp11
        tmp15 = 2.0
        tmp16 = tmp14 * tmp15
        tmp17 = tl.where(tmp12, tmp16, tmp8)
        tmp18 = tmp10 + tmp17
        tmp19 = tl.full([1], 78, tl.int32)
        tmp20 = tmp3 == tmp19
        tmp21 = tmp19 == tmp11
        tmp24 = 0.0
        tmp25 = tl.where(tmp21, tmp24, tmp23)
        tmp26 = tmp25 * tmp15
        tmp27 = tl.where(tmp20, tmp26, tmp8)
        tmp28 = tmp18 + tmp27
        tmp29 = tl.full([1], 77, tl.int32)
        tmp30 = tmp3 == tmp29
        tmp31 = tmp29 == tmp19
        tmp32 = tmp29 == tmp11
        tmp35 = tl.where(tmp32, tmp24, tmp34)
        tmp36 = tl.where(tmp31, tmp24, tmp35)
        tmp37 = tmp36 * tmp15
        tmp38 = tl.where(tmp30, tmp37, tmp8)
        tmp39 = tmp28 + tmp38
        tl.store(in_out_ptr0 + (x0), tmp39, xmask)


op14: SchedulerNode(ComputedBuffer)
op14.writes = [MemoryDep('buf14', c0, {c0: 100}, None)]
op14.unmet_dependencies = 
    [   MemoryDep('buf11', 75, {}, None),
        MemoryDep('buf11', 76, {}, None),
        MemoryDep('buf13', c0, {c0: 100}, None)]
op14.met_dependencies = [MemoryDep('full_default', c0, {c0: 100}, None)]
op14.outputs = [
    buf14: ComputedBuffer
    buf14.layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
    buf14.users = [NodeUser(node=SchedulerNode(name='op15'), can_inplace=True, is_weak=False)]
]
op14.group.device = cuda:0
op14.group.iteration = (100, 1)
op14.sizes = ([100], [])
buf13_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf11_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
full_default_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf11_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf14_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
class op14_loop_body:
    var_ranges = {z0: 100}
    index0 = z0
    index1 = 76
    index2 = 75
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf13', get_index)
        get_index_1 = self.get_index('index0')
        index_expr = ops.index_expr(get_index_1, torch.int32)
        constant = ops.constant(76, torch.int32)
        eq = ops.eq(index_expr, constant)
        constant_1 = ops.constant(76, torch.int32)
        constant_2 = ops.constant(77, torch.int32)
        eq_1 = ops.eq(constant_1, constant_2)
        constant_3 = ops.constant(76, torch.int32)
        constant_4 = ops.constant(78, torch.int32)
        eq_2 = ops.eq(constant_3, constant_4)
        constant_5 = ops.constant(76, torch.int32)
        constant_6 = ops.constant(79, torch.int32)
        eq_3 = ops.eq(constant_5, constant_6)
        get_index_2 = self.get_index('index1')
        load_1 = ops.load('buf11', get_index_2)
        constant_7 = ops.constant(0.0, torch.float32)
        where = ops.where(eq_3, constant_7, load_1)
        constant_8 = ops.constant(0.0, torch.float32)
        where_1 = ops.where(eq_2, constant_8, where)
        constant_9 = ops.constant(0.0, torch.float32)
        where_2 = ops.where(eq_1, constant_9, where_1)
        constant_10 = ops.constant(2.0, torch.float32)
        mul = ops.mul(where_2, constant_10)
        get_index_3 = self.get_index('index0')
        load_2 = ops.load('full_default', get_index_3)
        where_3 = ops.where(eq, mul, load_2)
        add = ops.add(load, where_3)
        get_index_4 = self.get_index('index0')
        index_expr_1 = ops.index_expr(get_index_4, torch.int32)
        constant_11 = ops.constant(75, torch.int32)
        eq_4 = ops.eq(index_expr_1, constant_11)
        constant_12 = ops.constant(75, torch.int32)
        constant_13 = ops.constant(76, torch.int32)
        eq_5 = ops.eq(constant_12, constant_13)
        constant_14 = ops.constant(75, torch.int32)
        constant_15 = ops.constant(77, torch.int32)
        eq_6 = ops.eq(constant_14, constant_15)
        constant_16 = ops.constant(75, torch.int32)
        constant_17 = ops.constant(78, torch.int32)
        eq_7 = ops.eq(constant_16, constant_17)
        constant_18 = ops.constant(75, torch.int32)
        constant_19 = ops.constant(79, torch.int32)
        eq_8 = ops.eq(constant_18, constant_19)
        get_index_5 = self.get_index('index2')
        load_3 = ops.load('buf11', get_index_5)
        constant_20 = ops.constant(0.0, torch.float32)
        where_4 = ops.where(eq_8, constant_20, load_3)
        constant_21 = ops.constant(0.0, torch.float32)
        where_5 = ops.where(eq_7, constant_21, where_4)
        constant_22 = ops.constant(0.0, torch.float32)
        where_6 = ops.where(eq_6, constant_22, where_5)
        constant_23 = ops.constant(0.0, torch.float32)
        where_7 = ops.where(eq_5, constant_23, where_6)
        constant_24 = ops.constant(2.0, torch.float32)
        mul_1 = ops.mul(where_7, constant_24)
        get_index_6 = self.get_index('index0')
        load_4 = ops.load('full_default', get_index_6)
        where_8 = ops.where(eq_4, mul_1, load_4)
        add_1 = ops.add(add, where_8)
        get_index_7 = self.get_index('index0')
        store = ops.store('buf14', get_index_7, add_1, None)
        return store
op14 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[128], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, multi_processor_count=20), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_out_ptr0'], 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': '712B1D69F892A891D8FFA5075DCAB47CFF4E132D88BFC66744701CEAE226F127', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_out_ptr0, in_ptr0, in_ptr1, xnumel, XBLOCK : tl.constexpr):
        xnumel = 100
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp0 = tl.load(in_out_ptr0 + (x0), xmask)
        tmp10 = tl.load(in_ptr0 + (76))
        tmp11 = tl.broadcast_to(tmp10, [XBLOCK])
        tmp18 = tl.load(in_ptr1 + (x0), xmask)
        tmp27 = tl.load(in_ptr0 + (75))
        tmp28 = tl.broadcast_to(tmp27, [XBLOCK])
        tmp1 = x0
        tmp2 = tl.full([1], 76, tl.int32)
        tmp3 = tmp1 == tmp2
        tmp4 = tl.full([1], 77, tl.int32)
        tmp5 = tmp2 == tmp4
        tmp6 = tl.full([1], 78, tl.int32)
        tmp7 = tmp2 == tmp6
        tmp8 = tl.full([1], 79, tl.int32)
        tmp9 = tmp2 == tmp8
        tmp12 = 0.0
        tmp13 = tl.where(tmp9, tmp12, tmp11)
        tmp14 = tl.where(tmp7, tmp12, tmp13)
        tmp15 = tl.where(tmp5, tmp12, tmp14)
        tmp16 = 2.0
        tmp17 = tmp15 * tmp16
        tmp19 = tl.where(tmp3, tmp17, tmp18)
        tmp20 = tmp0 + tmp19
        tmp21 = tl.full([1], 75, tl.int32)
        tmp22 = tmp1 == tmp21
        tmp23 = tmp21 == tmp2
        tmp24 = tmp21 == tmp4
        tmp25 = tmp21 == tmp6
        tmp26 = tmp21 == tmp8
        tmp29 = tl.where(tmp26, tmp12, tmp28)
        tmp30 = tl.where(tmp25, tmp12, tmp29)
        tmp31 = tl.where(tmp24, tmp12, tmp30)
        tmp32 = tl.where(tmp23, tmp12, tmp31)
        tmp33 = tmp32 * tmp16
        tmp34 = tl.where(tmp22, tmp33, tmp18)
        tmp35 = tmp20 + tmp34
        tl.store(in_out_ptr0 + (x0), tmp35, xmask)


op15: SchedulerNode(ComputedBuffer)
op15.writes = [MemoryDep('buf15', c0, {c0: 100}, None)]
op15.unmet_dependencies = 
    [   MemoryDep('buf11', 73, {}, None),
        MemoryDep('buf11', 74, {}, None),
        MemoryDep('buf14', c0, {c0: 100}, None)]
op15.met_dependencies = [MemoryDep('full_default', c0, {c0: 100}, None)]
op15.outputs = [
    buf15: ComputedBuffer
    buf15.layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
    buf15.users = [NodeUser(node=SchedulerNode(name='op16'), can_inplace=True, is_weak=False)]
]
op15.group.device = cuda:0
op15.group.iteration = (100, 1)
op15.sizes = ([100], [])
buf14_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf11_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
full_default_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf11_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf15_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
class op15_loop_body:
    var_ranges = {z0: 100}
    index0 = z0
    index1 = 74
    index2 = 73
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf14', get_index)
        get_index_1 = self.get_index('index0')
        index_expr = ops.index_expr(get_index_1, torch.int32)
        constant = ops.constant(74, torch.int32)
        eq = ops.eq(index_expr, constant)
        constant_1 = ops.constant(74, torch.int32)
        constant_2 = ops.constant(75, torch.int32)
        eq_1 = ops.eq(constant_1, constant_2)
        constant_3 = ops.constant(74, torch.int32)
        constant_4 = ops.constant(76, torch.int32)
        eq_2 = ops.eq(constant_3, constant_4)
        constant_5 = ops.constant(74, torch.int32)
        constant_6 = ops.constant(77, torch.int32)
        eq_3 = ops.eq(constant_5, constant_6)
        constant_7 = ops.constant(74, torch.int32)
        constant_8 = ops.constant(78, torch.int32)
        eq_4 = ops.eq(constant_7, constant_8)
        constant_9 = ops.constant(74, torch.int32)
        constant_10 = ops.constant(79, torch.int32)
        eq_5 = ops.eq(constant_9, constant_10)
        get_index_2 = self.get_index('index1')
        load_1 = ops.load('buf11', get_index_2)
        constant_11 = ops.constant(0.0, torch.float32)
        where = ops.where(eq_5, constant_11, load_1)
        constant_12 = ops.constant(0.0, torch.float32)
        where_1 = ops.where(eq_4, constant_12, where)
        constant_13 = ops.constant(0.0, torch.float32)
        where_2 = ops.where(eq_3, constant_13, where_1)
        constant_14 = ops.constant(0.0, torch.float32)
        where_3 = ops.where(eq_2, constant_14, where_2)
        constant_15 = ops.constant(0.0, torch.float32)
        where_4 = ops.where(eq_1, constant_15, where_3)
        constant_16 = ops.constant(2.0, torch.float32)
        mul = ops.mul(where_4, constant_16)
        get_index_3 = self.get_index('index0')
        load_2 = ops.load('full_default', get_index_3)
        where_5 = ops.where(eq, mul, load_2)
        add = ops.add(load, where_5)
        get_index_4 = self.get_index('index0')
        index_expr_1 = ops.index_expr(get_index_4, torch.int32)
        constant_17 = ops.constant(73, torch.int32)
        eq_6 = ops.eq(index_expr_1, constant_17)
        constant_18 = ops.constant(73, torch.int32)
        constant_19 = ops.constant(74, torch.int32)
        eq_7 = ops.eq(constant_18, constant_19)
        constant_20 = ops.constant(73, torch.int32)
        constant_21 = ops.constant(75, torch.int32)
        eq_8 = ops.eq(constant_20, constant_21)
        constant_22 = ops.constant(73, torch.int32)
        constant_23 = ops.constant(76, torch.int32)
        eq_9 = ops.eq(constant_22, constant_23)
        constant_24 = ops.constant(73, torch.int32)
        constant_25 = ops.constant(77, torch.int32)
        eq_10 = ops.eq(constant_24, constant_25)
        constant_26 = ops.constant(73, torch.int32)
        constant_27 = ops.constant(78, torch.int32)
        eq_11 = ops.eq(constant_26, constant_27)
        constant_28 = ops.constant(73, torch.int32)
        constant_29 = ops.constant(79, torch.int32)
        eq_12 = ops.eq(constant_28, constant_29)
        get_index_5 = self.get_index('index2')
        load_3 = ops.load('buf11', get_index_5)
        constant_30 = ops.constant(0.0, torch.float32)
        where_6 = ops.where(eq_12, constant_30, load_3)
        constant_31 = ops.constant(0.0, torch.float32)
        where_7 = ops.where(eq_11, constant_31, where_6)
        constant_32 = ops.constant(0.0, torch.float32)
        where_8 = ops.where(eq_10, constant_32, where_7)
        constant_33 = ops.constant(0.0, torch.float32)
        where_9 = ops.where(eq_9, constant_33, where_8)
        constant_34 = ops.constant(0.0, torch.float32)
        where_10 = ops.where(eq_8, constant_34, where_9)
        constant_35 = ops.constant(0.0, torch.float32)
        where_11 = ops.where(eq_7, constant_35, where_10)
        constant_36 = ops.constant(2.0, torch.float32)
        mul_1 = ops.mul(where_11, constant_36)
        get_index_6 = self.get_index('index0')
        load_4 = ops.load('full_default', get_index_6)
        where_12 = ops.where(eq_6, mul_1, load_4)
        add_1 = ops.add(add, where_12)
        get_index_7 = self.get_index('index0')
        store = ops.store('buf15', get_index_7, add_1, None)
        return store
op15 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[128], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, multi_processor_count=20), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_out_ptr0'], 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': '712B1D69F892A891D8FFA5075DCAB47CFF4E132D88BFC66744701CEAE226F127', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_out_ptr0, in_ptr0, in_ptr1, xnumel, XBLOCK : tl.constexpr):
        xnumel = 100
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp0 = tl.load(in_out_ptr0 + (x0), xmask)
        tmp14 = tl.load(in_ptr0 + (74))
        tmp15 = tl.broadcast_to(tmp14, [XBLOCK])
        tmp24 = tl.load(in_ptr1 + (x0), xmask)
        tmp35 = tl.load(in_ptr0 + (73))
        tmp36 = tl.broadcast_to(tmp35, [XBLOCK])
        tmp1 = x0
        tmp2 = tl.full([1], 74, tl.int32)
        tmp3 = tmp1 == tmp2
        tmp4 = tl.full([1], 75, tl.int32)
        tmp5 = tmp2 == tmp4
        tmp6 = tl.full([1], 76, tl.int32)
        tmp7 = tmp2 == tmp6
        tmp8 = tl.full([1], 77, tl.int32)
        tmp9 = tmp2 == tmp8
        tmp10 = tl.full([1], 78, tl.int32)
        tmp11 = tmp2 == tmp10
        tmp12 = tl.full([1], 79, tl.int32)
        tmp13 = tmp2 == tmp12
        tmp16 = 0.0
        tmp17 = tl.where(tmp13, tmp16, tmp15)
        tmp18 = tl.where(tmp11, tmp16, tmp17)
        tmp19 = tl.where(tmp9, tmp16, tmp18)
        tmp20 = tl.where(tmp7, tmp16, tmp19)
        tmp21 = tl.where(tmp5, tmp16, tmp20)
        tmp22 = 2.0
        tmp23 = tmp21 * tmp22
        tmp25 = tl.where(tmp3, tmp23, tmp24)
        tmp26 = tmp0 + tmp25
        tmp27 = tl.full([1], 73, tl.int32)
        tmp28 = tmp1 == tmp27
        tmp29 = tmp27 == tmp2
        tmp30 = tmp27 == tmp4
        tmp31 = tmp27 == tmp6
        tmp32 = tmp27 == tmp8
        tmp33 = tmp27 == tmp10
        tmp34 = tmp27 == tmp12
        tmp37 = tl.where(tmp34, tmp16, tmp36)
        tmp38 = tl.where(tmp33, tmp16, tmp37)
        tmp39 = tl.where(tmp32, tmp16, tmp38)
        tmp40 = tl.where(tmp31, tmp16, tmp39)
        tmp41 = tl.where(tmp30, tmp16, tmp40)
        tmp42 = tl.where(tmp29, tmp16, tmp41)
        tmp43 = tmp42 * tmp22
        tmp44 = tl.where(tmp28, tmp43, tmp24)
        tmp45 = tmp26 + tmp44
        tl.store(in_out_ptr0 + (x0), tmp45, xmask)


op16: SchedulerNode(ComputedBuffer)
op16.writes = [MemoryDep('buf16', c0, {c0: 100}, None)]
op16.unmet_dependencies = [MemoryDep('buf11', 72, {}, None), MemoryDep('buf15', c0, {c0: 100}, None)]
op16.met_dependencies = [MemoryDep('full_default', c0, {c0: 100}, None)]
op16.outputs = [
    buf16: ComputedBuffer
    buf16.layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
    buf16.users = [NodeUser(node=SchedulerNode(name='op20'), can_inplace=True, is_weak=False)]
]
op16.group.device = cuda:0
op16.group.iteration = (100, 1)
op16.sizes = ([100], [])
buf15_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf11_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
full_default_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf16_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
class op16_loop_body:
    var_ranges = {z0: 100}
    index0 = z0
    index1 = 72
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf15', get_index)
        get_index_1 = self.get_index('index0')
        index_expr = ops.index_expr(get_index_1, torch.int32)
        constant = ops.constant(72, torch.int32)
        eq = ops.eq(index_expr, constant)
        constant_1 = ops.constant(72, torch.int32)
        constant_2 = ops.constant(73, torch.int32)
        eq_1 = ops.eq(constant_1, constant_2)
        constant_3 = ops.constant(72, torch.int32)
        constant_4 = ops.constant(74, torch.int32)
        eq_2 = ops.eq(constant_3, constant_4)
        constant_5 = ops.constant(72, torch.int32)
        constant_6 = ops.constant(75, torch.int32)
        eq_3 = ops.eq(constant_5, constant_6)
        constant_7 = ops.constant(72, torch.int32)
        constant_8 = ops.constant(76, torch.int32)
        eq_4 = ops.eq(constant_7, constant_8)
        constant_9 = ops.constant(72, torch.int32)
        constant_10 = ops.constant(77, torch.int32)
        eq_5 = ops.eq(constant_9, constant_10)
        constant_11 = ops.constant(72, torch.int32)
        constant_12 = ops.constant(78, torch.int32)
        eq_6 = ops.eq(constant_11, constant_12)
        constant_13 = ops.constant(72, torch.int32)
        constant_14 = ops.constant(79, torch.int32)
        eq_7 = ops.eq(constant_13, constant_14)
        get_index_2 = self.get_index('index1')
        load_1 = ops.load('buf11', get_index_2)
        constant_15 = ops.constant(0.0, torch.float32)
        where = ops.where(eq_7, constant_15, load_1)
        constant_16 = ops.constant(0.0, torch.float32)
        where_1 = ops.where(eq_6, constant_16, where)
        constant_17 = ops.constant(0.0, torch.float32)
        where_2 = ops.where(eq_5, constant_17, where_1)
        constant_18 = ops.constant(0.0, torch.float32)
        where_3 = ops.where(eq_4, constant_18, where_2)
        constant_19 = ops.constant(0.0, torch.float32)
        where_4 = ops.where(eq_3, constant_19, where_3)
        constant_20 = ops.constant(0.0, torch.float32)
        where_5 = ops.where(eq_2, constant_20, where_4)
        constant_21 = ops.constant(0.0, torch.float32)
        where_6 = ops.where(eq_1, constant_21, where_5)
        constant_22 = ops.constant(2.0, torch.float32)
        mul = ops.mul(where_6, constant_22)
        get_index_3 = self.get_index('index0')
        load_2 = ops.load('full_default', get_index_3)
        where_7 = ops.where(eq, mul, load_2)
        add = ops.add(load, where_7)
        get_index_4 = self.get_index('index0')
        store = ops.store('buf16', get_index_4, add, None)
        return store
op16 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[128], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, multi_processor_count=20), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_out_ptr0'], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 0, 'backend_hash': '712B1D69F892A891D8FFA5075DCAB47CFF4E132D88BFC66744701CEAE226F127', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_out_ptr0, in_ptr0, in_ptr1, xnumel, XBLOCK : tl.constexpr):
        xnumel = 100
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp0 = tl.load(in_out_ptr0 + (x0), xmask)
        tmp18 = tl.load(in_ptr0 + (72))
        tmp19 = tl.broadcast_to(tmp18, [XBLOCK])
        tmp30 = tl.load(in_ptr1 + (x0), xmask)
        tmp1 = x0
        tmp2 = tl.full([1], 72, tl.int32)
        tmp3 = tmp1 == tmp2
        tmp4 = tl.full([1], 73, tl.int32)
        tmp5 = tmp2 == tmp4
        tmp6 = tl.full([1], 74, tl.int32)
        tmp7 = tmp2 == tmp6
        tmp8 = tl.full([1], 75, tl.int32)
        tmp9 = tmp2 == tmp8
        tmp10 = tl.full([1], 76, tl.int32)
        tmp11 = tmp2 == tmp10
        tmp12 = tl.full([1], 77, tl.int32)
        tmp13 = tmp2 == tmp12
        tmp14 = tl.full([1], 78, tl.int32)
        tmp15 = tmp2 == tmp14
        tmp16 = tl.full([1], 79, tl.int32)
        tmp17 = tmp2 == tmp16
        tmp20 = 0.0
        tmp21 = tl.where(tmp17, tmp20, tmp19)
        tmp22 = tl.where(tmp15, tmp20, tmp21)
        tmp23 = tl.where(tmp13, tmp20, tmp22)
        tmp24 = tl.where(tmp11, tmp20, tmp23)
        tmp25 = tl.where(tmp9, tmp20, tmp24)
        tmp26 = tl.where(tmp7, tmp20, tmp25)
        tmp27 = tl.where(tmp5, tmp20, tmp26)
        tmp28 = 2.0
        tmp29 = tmp27 * tmp28
        tmp31 = tl.where(tmp3, tmp29, tmp30)
        tmp32 = tmp0 + tmp31
        tl.store(in_out_ptr0 + (x0), tmp32, xmask)


op17: SchedulerNode(ComputedBuffer)
op17.writes = [MemoryDep('buf17', c0, {c0: 100}, None)]
op17.unmet_dependencies = [MemoryDep('buf11', 71, {}, None)]
op17.met_dependencies = [MemoryDep('full_default', c0, {c0: 100}, None)]
op17.outputs = [
    buf17: ComputedBuffer
    buf17.layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
    buf17.users = [NodeUser(node=SchedulerNode(name='op20'), can_inplace=True, is_weak=False)]
]
op17.group.device = cuda:0
op17.group.iteration = (100, 1)
op17.sizes = ([100], [])
buf11_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
full_default_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf17_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
class op17_loop_body:
    var_ranges = {z0: 100}
    index0 = z0
    index1 = 71
    def body(self, ops):
        get_index = self.get_index('index0')
        index_expr = ops.index_expr(get_index, torch.int32)
        constant = ops.constant(71, torch.int32)
        eq = ops.eq(index_expr, constant)
        constant_1 = ops.constant(71, torch.int32)
        constant_2 = ops.constant(72, torch.int32)
        eq_1 = ops.eq(constant_1, constant_2)
        constant_3 = ops.constant(71, torch.int32)
        constant_4 = ops.constant(73, torch.int32)
        eq_2 = ops.eq(constant_3, constant_4)
        constant_5 = ops.constant(71, torch.int32)
        constant_6 = ops.constant(74, torch.int32)
        eq_3 = ops.eq(constant_5, constant_6)
        constant_7 = ops.constant(71, torch.int32)
        constant_8 = ops.constant(75, torch.int32)
        eq_4 = ops.eq(constant_7, constant_8)
        constant_9 = ops.constant(71, torch.int32)
        constant_10 = ops.constant(76, torch.int32)
        eq_5 = ops.eq(constant_9, constant_10)
        constant_11 = ops.constant(71, torch.int32)
        constant_12 = ops.constant(77, torch.int32)
        eq_6 = ops.eq(constant_11, constant_12)
        constant_13 = ops.constant(71, torch.int32)
        constant_14 = ops.constant(78, torch.int32)
        eq_7 = ops.eq(constant_13, constant_14)
        constant_15 = ops.constant(71, torch.int32)
        constant_16 = ops.constant(79, torch.int32)
        eq_8 = ops.eq(constant_15, constant_16)
        get_index_1 = self.get_index('index1')
        load = ops.load('buf11', get_index_1)
        constant_17 = ops.constant(0.0, torch.float32)
        where = ops.where(eq_8, constant_17, load)
        constant_18 = ops.constant(0.0, torch.float32)
        where_1 = ops.where(eq_7, constant_18, where)
        constant_19 = ops.constant(0.0, torch.float32)
        where_2 = ops.where(eq_6, constant_19, where_1)
        constant_20 = ops.constant(0.0, torch.float32)
        where_3 = ops.where(eq_5, constant_20, where_2)
        constant_21 = ops.constant(0.0, torch.float32)
        where_4 = ops.where(eq_4, constant_21, where_3)
        constant_22 = ops.constant(0.0, torch.float32)
        where_5 = ops.where(eq_3, constant_22, where_4)
        constant_23 = ops.constant(0.0, torch.float32)
        where_6 = ops.where(eq_2, constant_23, where_5)
        constant_24 = ops.constant(0.0, torch.float32)
        where_7 = ops.where(eq_1, constant_24, where_6)
        constant_25 = ops.constant(2.0, torch.float32)
        mul = ops.mul(where_7, constant_25)
        get_index_2 = self.get_index('index0')
        load_1 = ops.load('full_default', get_index_2)
        where_8 = ops.where(eq, mul, load_1)
        get_index_3 = self.get_index('index0')
        store = ops.store('buf17', get_index_3, where_8, None)
        return store
op17 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[128], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, multi_processor_count=20), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '712B1D69F892A891D8FFA5075DCAB47CFF4E132D88BFC66744701CEAE226F127', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 100
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp19 = tl.load(in_ptr0 + (71))
        tmp20 = tl.broadcast_to(tmp19, [XBLOCK])
        tmp32 = tl.load(in_ptr1 + (x0), xmask)
        tmp0 = x0
        tmp1 = tl.full([1], 71, tl.int32)
        tmp2 = tmp0 == tmp1
        tmp3 = tl.full([1], 72, tl.int32)
        tmp4 = tmp1 == tmp3
        tmp5 = tl.full([1], 73, tl.int32)
        tmp6 = tmp1 == tmp5
        tmp7 = tl.full([1], 74, tl.int32)
        tmp8 = tmp1 == tmp7
        tmp9 = tl.full([1], 75, tl.int32)
        tmp10 = tmp1 == tmp9
        tmp11 = tl.full([1], 76, tl.int32)
        tmp12 = tmp1 == tmp11
        tmp13 = tl.full([1], 77, tl.int32)
        tmp14 = tmp1 == tmp13
        tmp15 = tl.full([1], 78, tl.int32)
        tmp16 = tmp1 == tmp15
        tmp17 = tl.full([1], 79, tl.int32)
        tmp18 = tmp1 == tmp17
        tmp21 = 0.0
        tmp22 = tl.where(tmp18, tmp21, tmp20)
        tmp23 = tl.where(tmp16, tmp21, tmp22)
        tmp24 = tl.where(tmp14, tmp21, tmp23)
        tmp25 = tl.where(tmp12, tmp21, tmp24)
        tmp26 = tl.where(tmp10, tmp21, tmp25)
        tmp27 = tl.where(tmp8, tmp21, tmp26)
        tmp28 = tl.where(tmp6, tmp21, tmp27)
        tmp29 = tl.where(tmp4, tmp21, tmp28)
        tmp30 = 2.0
        tmp31 = tmp29 * tmp30
        tmp33 = tl.where(tmp2, tmp31, tmp32)
        tl.store(out_ptr0 + (x0), tmp33, xmask)


op18: SchedulerNode(ComputedBuffer)
op18.writes = [MemoryDep('buf18', c0, {c0: 100}, None)]
op18.unmet_dependencies = [MemoryDep('buf11', c0, {c0: 100}, None)]
op18.met_dependencies = []
op18.outputs = [
    buf18: ComputedBuffer
    buf18.layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
    buf18.users = [
        NodeUser(node=SchedulerNode(name='op20'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op21'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op22'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op23'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op24'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op25'), can_inplace=True, is_weak=False),
        NodeUser(node=SchedulerNode(name='op26'), can_inplace=False, is_weak=False),
    ]
]
op18.group.device = cuda:0
op18.group.iteration = (100, 1)
op18.sizes = ([100], [])
buf11_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf18_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
class op18_loop_body:
    var_ranges = {z0: 100}
    index0 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        index_expr = ops.index_expr(get_index, torch.int32)
        constant = ops.constant(70, torch.int32)
        eq = ops.eq(index_expr, constant)
        get_index_1 = self.get_index('index0')
        index_expr_1 = ops.index_expr(get_index_1, torch.int32)
        constant_1 = ops.constant(71, torch.int32)
        eq_1 = ops.eq(index_expr_1, constant_1)
        get_index_2 = self.get_index('index0')
        index_expr_2 = ops.index_expr(get_index_2, torch.int32)
        constant_2 = ops.constant(72, torch.int32)
        eq_2 = ops.eq(index_expr_2, constant_2)
        get_index_3 = self.get_index('index0')
        index_expr_3 = ops.index_expr(get_index_3, torch.int32)
        constant_3 = ops.constant(73, torch.int32)
        eq_3 = ops.eq(index_expr_3, constant_3)
        get_index_4 = self.get_index('index0')
        index_expr_4 = ops.index_expr(get_index_4, torch.int32)
        constant_4 = ops.constant(74, torch.int32)
        eq_4 = ops.eq(index_expr_4, constant_4)
        get_index_5 = self.get_index('index0')
        index_expr_5 = ops.index_expr(get_index_5, torch.int32)
        constant_5 = ops.constant(75, torch.int32)
        eq_5 = ops.eq(index_expr_5, constant_5)
        get_index_6 = self.get_index('index0')
        index_expr_6 = ops.index_expr(get_index_6, torch.int32)
        constant_6 = ops.constant(76, torch.int32)
        eq_6 = ops.eq(index_expr_6, constant_6)
        get_index_7 = self.get_index('index0')
        index_expr_7 = ops.index_expr(get_index_7, torch.int32)
        constant_7 = ops.constant(77, torch.int32)
        eq_7 = ops.eq(index_expr_7, constant_7)
        get_index_8 = self.get_index('index0')
        index_expr_8 = ops.index_expr(get_index_8, torch.int32)
        constant_8 = ops.constant(78, torch.int32)
        eq_8 = ops.eq(index_expr_8, constant_8)
        get_index_9 = self.get_index('index0')
        index_expr_9 = ops.index_expr(get_index_9, torch.int32)
        constant_9 = ops.constant(79, torch.int32)
        eq_9 = ops.eq(index_expr_9, constant_9)
        get_index_10 = self.get_index('index0')
        load = ops.load('buf11', get_index_10)
        constant_10 = ops.constant(0.0, torch.float32)
        where = ops.where(eq_9, constant_10, load)
        constant_11 = ops.constant(0.0, torch.float32)
        where_1 = ops.where(eq_8, constant_11, where)
        constant_12 = ops.constant(0.0, torch.float32)
        where_2 = ops.where(eq_7, constant_12, where_1)
        constant_13 = ops.constant(0.0, torch.float32)
        where_3 = ops.where(eq_6, constant_13, where_2)
        constant_14 = ops.constant(0.0, torch.float32)
        where_4 = ops.where(eq_5, constant_14, where_3)
        constant_15 = ops.constant(0.0, torch.float32)
        where_5 = ops.where(eq_4, constant_15, where_4)
        constant_16 = ops.constant(0.0, torch.float32)
        where_6 = ops.where(eq_3, constant_16, where_5)
        constant_17 = ops.constant(0.0, torch.float32)
        where_7 = ops.where(eq_2, constant_17, where_6)
        constant_18 = ops.constant(0.0, torch.float32)
        where_8 = ops.where(eq_1, constant_18, where_7)
        constant_19 = ops.constant(0.0, torch.float32)
        where_9 = ops.where(eq, constant_19, where_8)
        get_index_11 = self.get_index('index0')
        store = ops.store('buf18', get_index_11, where_9, None)
        return store
op18 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[128], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, multi_processor_count=20), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '712B1D69F892A891D8FFA5075DCAB47CFF4E132D88BFC66744701CEAE226F127', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 100
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp21 = tl.load(in_ptr0 + (x0), xmask)
        tmp0 = x0
        tmp1 = tl.full([1], 70, tl.int32)
        tmp2 = tmp0 == tmp1
        tmp3 = tl.full([1], 71, tl.int32)
        tmp4 = tmp0 == tmp3
        tmp5 = tl.full([1], 72, tl.int32)
        tmp6 = tmp0 == tmp5
        tmp7 = tl.full([1], 73, tl.int32)
        tmp8 = tmp0 == tmp7
        tmp9 = tl.full([1], 74, tl.int32)
        tmp10 = tmp0 == tmp9
        tmp11 = tl.full([1], 75, tl.int32)
        tmp12 = tmp0 == tmp11
        tmp13 = tl.full([1], 76, tl.int32)
        tmp14 = tmp0 == tmp13
        tmp15 = tl.full([1], 77, tl.int32)
        tmp16 = tmp0 == tmp15
        tmp17 = tl.full([1], 78, tl.int32)
        tmp18 = tmp0 == tmp17
        tmp19 = tl.full([1], 79, tl.int32)
        tmp20 = tmp0 == tmp19
        tmp22 = 0.0
        tmp23 = tl.where(tmp20, tmp22, tmp21)
        tmp24 = tl.where(tmp18, tmp22, tmp23)
        tmp25 = tl.where(tmp16, tmp22, tmp24)
        tmp26 = tl.where(tmp14, tmp22, tmp25)
        tmp27 = tl.where(tmp12, tmp22, tmp26)
        tmp28 = tl.where(tmp10, tmp22, tmp27)
        tmp29 = tl.where(tmp8, tmp22, tmp28)
        tmp30 = tl.where(tmp6, tmp22, tmp29)
        tmp31 = tl.where(tmp4, tmp22, tmp30)
        tmp32 = tl.where(tmp2, tmp22, tmp31)
        tl.store(out_ptr0 + (x0), tmp32, xmask)


op19: SchedulerNode(ComputedBuffer)
op19.writes = [MemoryDep('buf19', 0, {}, None)]
op19.unmet_dependencies = [MemoryDep('buf11', 70, {}, None)]
op19.met_dependencies = []
op19.outputs = [
    buf19: ComputedBuffer
    buf19.layout = FixedLayout('cuda', torch.float32, size=[], stride=[])
    buf19.users = [NodeUser(node=SchedulerNode(name='op20'), can_inplace=False, is_weak=False)]
]
op19.group.device = cuda:0
op19.group.iteration = (1, 1)
op19.sizes = ([], [])
buf11_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf19_layout = FixedLayout('cuda', torch.float32, size=[], stride=[])
class op19_loop_body:
    var_ranges = {}
    index0 = 70
    index1 = 0
    def body(self, ops):
        constant = ops.constant(70, torch.int32)
        constant_1 = ops.constant(71, torch.int32)
        eq = ops.eq(constant, constant_1)
        constant_2 = ops.constant(70, torch.int32)
        constant_3 = ops.constant(72, torch.int32)
        eq_1 = ops.eq(constant_2, constant_3)
        constant_4 = ops.constant(70, torch.int32)
        constant_5 = ops.constant(73, torch.int32)
        eq_2 = ops.eq(constant_4, constant_5)
        constant_6 = ops.constant(70, torch.int32)
        constant_7 = ops.constant(74, torch.int32)
        eq_3 = ops.eq(constant_6, constant_7)
        constant_8 = ops.constant(70, torch.int32)
        constant_9 = ops.constant(75, torch.int32)
        eq_4 = ops.eq(constant_8, constant_9)
        constant_10 = ops.constant(70, torch.int32)
        constant_11 = ops.constant(76, torch.int32)
        eq_5 = ops.eq(constant_10, constant_11)
        constant_12 = ops.constant(70, torch.int32)
        constant_13 = ops.constant(77, torch.int32)
        eq_6 = ops.eq(constant_12, constant_13)
        constant_14 = ops.constant(70, torch.int32)
        constant_15 = ops.constant(78, torch.int32)
        eq_7 = ops.eq(constant_14, constant_15)
        constant_16 = ops.constant(70, torch.int32)
        constant_17 = ops.constant(79, torch.int32)
        eq_8 = ops.eq(constant_16, constant_17)
        get_index = self.get_index('index0')
        load = ops.load('buf11', get_index)
        constant_18 = ops.constant(0.0, torch.float32)
        where = ops.where(eq_8, constant_18, load)
        constant_19 = ops.constant(0.0, torch.float32)
        where_1 = ops.where(eq_7, constant_19, where)
        constant_20 = ops.constant(0.0, torch.float32)
        where_2 = ops.where(eq_6, constant_20, where_1)
        constant_21 = ops.constant(0.0, torch.float32)
        where_3 = ops.where(eq_5, constant_21, where_2)
        constant_22 = ops.constant(0.0, torch.float32)
        where_4 = ops.where(eq_4, constant_22, where_3)
        constant_23 = ops.constant(0.0, torch.float32)
        where_5 = ops.where(eq_3, constant_23, where_4)
        constant_24 = ops.constant(0.0, torch.float32)
        where_6 = ops.where(eq_2, constant_24, where_5)
        constant_25 = ops.constant(0.0, torch.float32)
        where_7 = ops.where(eq_1, constant_25, where_6)
        constant_26 = ops.constant(0.0, torch.float32)
        where_8 = ops.where(eq, constant_26, where_7)
        constant_27 = ops.constant(2.0, torch.float32)
        mul = ops.mul(where_8, constant_27)
        get_index_1 = self.get_index('index1')
        store = ops.store('buf19', get_index_1, mul, None)
        return store
op19 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[1], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, multi_processor_count=20), 'constants': {2: 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(2,))]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '712B1D69F892A891D8FFA5075DCAB47CFF4E132D88BFC66744701CEAE226F127', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 1
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = tl.full([XBLOCK], True, tl.int1)
        tmp19 = tl.load(in_ptr0 + (70))
        tmp20 = tl.broadcast_to(tmp19, [XBLOCK])
        tmp0 = tl.full([1], 70, tl.int32)
        tmp1 = tl.full([1], 71, tl.int32)
        tmp2 = tmp0 == tmp1
        tmp3 = tl.full([1], 72, tl.int32)
        tmp4 = tmp0 == tmp3
        tmp5 = tl.full([1], 73, tl.int32)
        tmp6 = tmp0 == tmp5
        tmp7 = tl.full([1], 74, tl.int32)
        tmp8 = tmp0 == tmp7
        tmp9 = tl.full([1], 75, tl.int32)
        tmp10 = tmp0 == tmp9
        tmp11 = tl.full([1], 76, tl.int32)
        tmp12 = tmp0 == tmp11
        tmp13 = tl.full([1], 77, tl.int32)
        tmp14 = tmp0 == tmp13
        tmp15 = tl.full([1], 78, tl.int32)
        tmp16 = tmp0 == tmp15
        tmp17 = tl.full([1], 79, tl.int32)
        tmp18 = tmp0 == tmp17
        tmp21 = 0.0
        tmp22 = tl.where(tmp18, tmp21, tmp20)
        tmp23 = tl.where(tmp16, tmp21, tmp22)
        tmp24 = tl.where(tmp14, tmp21, tmp23)
        tmp25 = tl.where(tmp12, tmp21, tmp24)
        tmp26 = tl.where(tmp10, tmp21, tmp25)
        tmp27 = tl.where(tmp8, tmp21, tmp26)
        tmp28 = tl.where(tmp6, tmp21, tmp27)
        tmp29 = tl.where(tmp4, tmp21, tmp28)
        tmp30 = tl.where(tmp2, tmp21, tmp29)
        tmp31 = 2.0
        tmp32 = tmp30 * tmp31
        tl.store(out_ptr0 + (tl.full([XBLOCK], 0, tl.int32)), tmp32, None)


op20: SchedulerNode(ComputedBuffer)
op20.writes = [MemoryDep('buf20', c0, {c0: 100}, None)]
op20.unmet_dependencies = 
    [   MemoryDep('buf16', c0, {c0: 100}, None),
        MemoryDep('buf17', c0, {c0: 100}, None),
        MemoryDep('buf18', 67, {}, None),
        MemoryDep('buf18', 68, {}, None),
        MemoryDep('buf18', 69, {}, None),
        MemoryDep('buf19', 0, {}, None)]
op20.met_dependencies = [MemoryDep('full_default', c0, {c0: 100}, None)]
op20.outputs = [
    buf20: ComputedBuffer
    buf20.layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
    buf20.users = [NodeUser(node=SchedulerNode(name='op21'), can_inplace=True, is_weak=False)]
]
op20.group.device = cuda:0
op20.group.iteration = (100, 1)
op20.sizes = ([100], [])
buf16_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf17_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf19_layout = FixedLayout('cuda', torch.float32, size=[], stride=[])
full_default_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf18_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf18_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf18_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf20_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
class op20_loop_body:
    var_ranges = {z0: 100}
    index0 = z0
    index1 = 0
    index2 = 69
    index3 = 68
    index4 = 67
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf16', get_index)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('buf17', get_index_1)
        add = ops.add(load, load_1)
        get_index_2 = self.get_index('index0')
        index_expr = ops.index_expr(get_index_2, torch.int32)
        constant = ops.constant(70, torch.int32)
        eq = ops.eq(index_expr, constant)
        get_index_3 = self.get_index('index1')
        load_2 = ops.load('buf19', get_index_3)
        get_index_4 = self.get_index('index0')
        load_3 = ops.load('full_default', get_index_4)
        where = ops.where(eq, load_2, load_3)
        add_1 = ops.add(add, where)
        get_index_5 = self.get_index('index0')
        index_expr_1 = ops.index_expr(get_index_5, torch.int32)
        constant_1 = ops.constant(69, torch.int32)
        eq_1 = ops.eq(index_expr_1, constant_1)
        get_index_6 = self.get_index('index2')
        load_4 = ops.load('buf18', get_index_6)
        constant_2 = ops.constant(2.0, torch.float32)
        mul = ops.mul(load_4, constant_2)
        get_index_7 = self.get_index('index0')
        load_5 = ops.load('full_default', get_index_7)
        where_1 = ops.where(eq_1, mul, load_5)
        add_2 = ops.add(add_1, where_1)
        get_index_8 = self.get_index('index0')
        index_expr_2 = ops.index_expr(get_index_8, torch.int32)
        constant_3 = ops.constant(68, torch.int32)
        eq_2 = ops.eq(index_expr_2, constant_3)
        constant_4 = ops.constant(68, torch.int32)
        constant_5 = ops.constant(69, torch.int32)
        eq_3 = ops.eq(constant_4, constant_5)
        get_index_9 = self.get_index('index3')
        load_6 = ops.load('buf18', get_index_9)
        constant_6 = ops.constant(0.0, torch.float32)
        where_2 = ops.where(eq_3, constant_6, load_6)
        constant_7 = ops.constant(2.0, torch.float32)
        mul_1 = ops.mul(where_2, constant_7)
        get_index_10 = self.get_index('index0')
        load_7 = ops.load('full_default', get_index_10)
        where_3 = ops.where(eq_2, mul_1, load_7)
        add_3 = ops.add(add_2, where_3)
        get_index_11 = self.get_index('index0')
        index_expr_3 = ops.index_expr(get_index_11, torch.int32)
        constant_8 = ops.constant(67, torch.int32)
        eq_4 = ops.eq(index_expr_3, constant_8)
        constant_9 = ops.constant(67, torch.int32)
        constant_10 = ops.constant(68, torch.int32)
        eq_5 = ops.eq(constant_9, constant_10)
        constant_11 = ops.constant(67, torch.int32)
        constant_12 = ops.constant(69, torch.int32)
        eq_6 = ops.eq(constant_11, constant_12)
        get_index_12 = self.get_index('index4')
        load_8 = ops.load('buf18', get_index_12)
        constant_13 = ops.constant(0.0, torch.float32)
        where_4 = ops.where(eq_6, constant_13, load_8)
        constant_14 = ops.constant(0.0, torch.float32)
        where_5 = ops.where(eq_5, constant_14, where_4)
        constant_15 = ops.constant(2.0, torch.float32)
        mul_2 = ops.mul(where_5, constant_15)
        get_index_13 = self.get_index('index0')
        load_9 = ops.load('full_default', get_index_13)
        where_6 = ops.where(eq_4, mul_2, load_9)
        add_4 = ops.add(add_3, where_6)
        get_index_14 = self.get_index('index0')
        store = ops.store('buf20', get_index_14, add_4, None)
        return store
op20 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[128], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, multi_processor_count=20), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_out_ptr0'], 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': '712B1D69F892A891D8FFA5075DCAB47CFF4E132D88BFC66744701CEAE226F127', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, xnumel, XBLOCK : tl.constexpr):
        xnumel = 100
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp0 = tl.load(in_out_ptr0 + (x0), xmask)
        tmp1 = tl.load(in_ptr0 + (x0), xmask)
        tmp6 = tl.load(in_ptr1 + (0))
        tmp7 = tl.broadcast_to(tmp6, [XBLOCK])
        tmp8 = tl.load(in_ptr2 + (x0), xmask)
        tmp13 = tl.load(in_ptr3 + (69))
        tmp14 = tl.broadcast_to(tmp13, [XBLOCK])
        tmp22 = tl.load(in_ptr3 + (68))
        tmp23 = tl.broadcast_to(tmp22, [XBLOCK])
        tmp33 = tl.load(in_ptr3 + (67))
        tmp34 = tl.broadcast_to(tmp33, [XBLOCK])
        tmp2 = tmp0 + tmp1
        tmp3 = x0
        tmp4 = tl.full([1], 70, tl.int32)
        tmp5 = tmp3 == tmp4
        tmp9 = tl.where(tmp5, tmp7, tmp8)
        tmp10 = tmp2 + tmp9
        tmp11 = tl.full([1], 69, tl.int32)
        tmp12 = tmp3 == tmp11
        tmp15 = 2.0
        tmp16 = tmp14 * tmp15
        tmp17 = tl.where(tmp12, tmp16, tmp8)
        tmp18 = tmp10 + tmp17
        tmp19 = tl.full([1], 68, tl.int32)
        tmp20 = tmp3 == tmp19
        tmp21 = tmp19 == tmp11
        tmp24 = 0.0
        tmp25 = tl.where(tmp21, tmp24, tmp23)
        tmp26 = tmp25 * tmp15
        tmp27 = tl.where(tmp20, tmp26, tmp8)
        tmp28 = tmp18 + tmp27
        tmp29 = tl.full([1], 67, tl.int32)
        tmp30 = tmp3 == tmp29
        tmp31 = tmp29 == tmp19
        tmp32 = tmp29 == tmp11
        tmp35 = tl.where(tmp32, tmp24, tmp34)
        tmp36 = tl.where(tmp31, tmp24, tmp35)
        tmp37 = tmp36 * tmp15
        tmp38 = tl.where(tmp30, tmp37, tmp8)
        tmp39 = tmp28 + tmp38
        tl.store(in_out_ptr0 + (x0), tmp39, xmask)


op21: SchedulerNode(ComputedBuffer)
op21.writes = [MemoryDep('buf21', c0, {c0: 100}, None)]
op21.unmet_dependencies = 
    [   MemoryDep('buf18', 65, {}, None),
        MemoryDep('buf18', 66, {}, None),
        MemoryDep('buf20', c0, {c0: 100}, None)]
op21.met_dependencies = [MemoryDep('full_default', c0, {c0: 100}, None)]
op21.outputs = [
    buf21: ComputedBuffer
    buf21.layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
    buf21.users = [NodeUser(node=SchedulerNode(name='op22'), can_inplace=True, is_weak=False)]
]
op21.group.device = cuda:0
op21.group.iteration = (100, 1)
op21.sizes = ([100], [])
buf20_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf18_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
full_default_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf18_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf21_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
class op21_loop_body:
    var_ranges = {z0: 100}
    index0 = z0
    index1 = 66
    index2 = 65
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf20', get_index)
        get_index_1 = self.get_index('index0')
        index_expr = ops.index_expr(get_index_1, torch.int32)
        constant = ops.constant(66, torch.int32)
        eq = ops.eq(index_expr, constant)
        constant_1 = ops.constant(66, torch.int32)
        constant_2 = ops.constant(67, torch.int32)
        eq_1 = ops.eq(constant_1, constant_2)
        constant_3 = ops.constant(66, torch.int32)
        constant_4 = ops.constant(68, torch.int32)
        eq_2 = ops.eq(constant_3, constant_4)
        constant_5 = ops.constant(66, torch.int32)
        constant_6 = ops.constant(69, torch.int32)
        eq_3 = ops.eq(constant_5, constant_6)
        get_index_2 = self.get_index('index1')
        load_1 = ops.load('buf18', get_index_2)
        constant_7 = ops.constant(0.0, torch.float32)
        where = ops.where(eq_3, constant_7, load_1)
        constant_8 = ops.constant(0.0, torch.float32)
        where_1 = ops.where(eq_2, constant_8, where)
        constant_9 = ops.constant(0.0, torch.float32)
        where_2 = ops.where(eq_1, constant_9, where_1)
        constant_10 = ops.constant(2.0, torch.float32)
        mul = ops.mul(where_2, constant_10)
        get_index_3 = self.get_index('index0')
        load_2 = ops.load('full_default', get_index_3)
        where_3 = ops.where(eq, mul, load_2)
        add = ops.add(load, where_3)
        get_index_4 = self.get_index('index0')
        index_expr_1 = ops.index_expr(get_index_4, torch.int32)
        constant_11 = ops.constant(65, torch.int32)
        eq_4 = ops.eq(index_expr_1, constant_11)
        constant_12 = ops.constant(65, torch.int32)
        constant_13 = ops.constant(66, torch.int32)
        eq_5 = ops.eq(constant_12, constant_13)
        constant_14 = ops.constant(65, torch.int32)
        constant_15 = ops.constant(67, torch.int32)
        eq_6 = ops.eq(constant_14, constant_15)
        constant_16 = ops.constant(65, torch.int32)
        constant_17 = ops.constant(68, torch.int32)
        eq_7 = ops.eq(constant_16, constant_17)
        constant_18 = ops.constant(65, torch.int32)
        constant_19 = ops.constant(69, torch.int32)
        eq_8 = ops.eq(constant_18, constant_19)
        get_index_5 = self.get_index('index2')
        load_3 = ops.load('buf18', get_index_5)
        constant_20 = ops.constant(0.0, torch.float32)
        where_4 = ops.where(eq_8, constant_20, load_3)
        constant_21 = ops.constant(0.0, torch.float32)
        where_5 = ops.where(eq_7, constant_21, where_4)
        constant_22 = ops.constant(0.0, torch.float32)
        where_6 = ops.where(eq_6, constant_22, where_5)
        constant_23 = ops.constant(0.0, torch.float32)
        where_7 = ops.where(eq_5, constant_23, where_6)
        constant_24 = ops.constant(2.0, torch.float32)
        mul_1 = ops.mul(where_7, constant_24)
        get_index_6 = self.get_index('index0')
        load_4 = ops.load('full_default', get_index_6)
        where_8 = ops.where(eq_4, mul_1, load_4)
        add_1 = ops.add(add, where_8)
        get_index_7 = self.get_index('index0')
        store = ops.store('buf21', get_index_7, add_1, None)
        return store
op21 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[128], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, multi_processor_count=20), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_out_ptr0'], 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': '712B1D69F892A891D8FFA5075DCAB47CFF4E132D88BFC66744701CEAE226F127', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_out_ptr0, in_ptr0, in_ptr1, xnumel, XBLOCK : tl.constexpr):
        xnumel = 100
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp0 = tl.load(in_out_ptr0 + (x0), xmask)
        tmp10 = tl.load(in_ptr0 + (66))
        tmp11 = tl.broadcast_to(tmp10, [XBLOCK])
        tmp18 = tl.load(in_ptr1 + (x0), xmask)
        tmp27 = tl.load(in_ptr0 + (65))
        tmp28 = tl.broadcast_to(tmp27, [XBLOCK])
        tmp1 = x0
        tmp2 = tl.full([1], 66, tl.int32)
        tmp3 = tmp1 == tmp2
        tmp4 = tl.full([1], 67, tl.int32)
        tmp5 = tmp2 == tmp4
        tmp6 = tl.full([1], 68, tl.int32)
        tmp7 = tmp2 == tmp6
        tmp8 = tl.full([1], 69, tl.int32)
        tmp9 = tmp2 == tmp8
        tmp12 = 0.0
        tmp13 = tl.where(tmp9, tmp12, tmp11)
        tmp14 = tl.where(tmp7, tmp12, tmp13)
        tmp15 = tl.where(tmp5, tmp12, tmp14)
        tmp16 = 2.0
        tmp17 = tmp15 * tmp16
        tmp19 = tl.where(tmp3, tmp17, tmp18)
        tmp20 = tmp0 + tmp19
        tmp21 = tl.full([1], 65, tl.int32)
        tmp22 = tmp1 == tmp21
        tmp23 = tmp21 == tmp2
        tmp24 = tmp21 == tmp4
        tmp25 = tmp21 == tmp6
        tmp26 = tmp21 == tmp8
        tmp29 = tl.where(tmp26, tmp12, tmp28)
        tmp30 = tl.where(tmp25, tmp12, tmp29)
        tmp31 = tl.where(tmp24, tmp12, tmp30)
        tmp32 = tl.where(tmp23, tmp12, tmp31)
        tmp33 = tmp32 * tmp16
        tmp34 = tl.where(tmp22, tmp33, tmp18)
        tmp35 = tmp20 + tmp34
        tl.store(in_out_ptr0 + (x0), tmp35, xmask)


op22: SchedulerNode(ComputedBuffer)
op22.writes = [MemoryDep('buf22', c0, {c0: 100}, None)]
op22.unmet_dependencies = 
    [   MemoryDep('buf18', 63, {}, None),
        MemoryDep('buf18', 64, {}, None),
        MemoryDep('buf21', c0, {c0: 100}, None)]
op22.met_dependencies = [MemoryDep('full_default', c0, {c0: 100}, None)]
op22.outputs = [
    buf22: ComputedBuffer
    buf22.layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
    buf22.users = [NodeUser(node=SchedulerNode(name='op23'), can_inplace=True, is_weak=False)]
]
op22.group.device = cuda:0
op22.group.iteration = (100, 1)
op22.sizes = ([100], [])
buf21_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf18_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
full_default_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf18_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf22_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
class op22_loop_body:
    var_ranges = {z0: 100}
    index0 = z0
    index1 = 64
    index2 = 63
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf21', get_index)
        get_index_1 = self.get_index('index0')
        index_expr = ops.index_expr(get_index_1, torch.int32)
        constant = ops.constant(64, torch.int32)
        eq = ops.eq(index_expr, constant)
        constant_1 = ops.constant(64, torch.int32)
        constant_2 = ops.constant(65, torch.int32)
        eq_1 = ops.eq(constant_1, constant_2)
        constant_3 = ops.constant(64, torch.int32)
        constant_4 = ops.constant(66, torch.int32)
        eq_2 = ops.eq(constant_3, constant_4)
        constant_5 = ops.constant(64, torch.int32)
        constant_6 = ops.constant(67, torch.int32)
        eq_3 = ops.eq(constant_5, constant_6)
        constant_7 = ops.constant(64, torch.int32)
        constant_8 = ops.constant(68, torch.int32)
        eq_4 = ops.eq(constant_7, constant_8)
        constant_9 = ops.constant(64, torch.int32)
        constant_10 = ops.constant(69, torch.int32)
        eq_5 = ops.eq(constant_9, constant_10)
        get_index_2 = self.get_index('index1')
        load_1 = ops.load('buf18', get_index_2)
        constant_11 = ops.constant(0.0, torch.float32)
        where = ops.where(eq_5, constant_11, load_1)
        constant_12 = ops.constant(0.0, torch.float32)
        where_1 = ops.where(eq_4, constant_12, where)
        constant_13 = ops.constant(0.0, torch.float32)
        where_2 = ops.where(eq_3, constant_13, where_1)
        constant_14 = ops.constant(0.0, torch.float32)
        where_3 = ops.where(eq_2, constant_14, where_2)
        constant_15 = ops.constant(0.0, torch.float32)
        where_4 = ops.where(eq_1, constant_15, where_3)
        constant_16 = ops.constant(2.0, torch.float32)
        mul = ops.mul(where_4, constant_16)
        get_index_3 = self.get_index('index0')
        load_2 = ops.load('full_default', get_index_3)
        where_5 = ops.where(eq, mul, load_2)
        add = ops.add(load, where_5)
        get_index_4 = self.get_index('index0')
        index_expr_1 = ops.index_expr(get_index_4, torch.int32)
        constant_17 = ops.constant(63, torch.int32)
        eq_6 = ops.eq(index_expr_1, constant_17)
        constant_18 = ops.constant(63, torch.int32)
        constant_19 = ops.constant(64, torch.int32)
        eq_7 = ops.eq(constant_18, constant_19)
        constant_20 = ops.constant(63, torch.int32)
        constant_21 = ops.constant(65, torch.int32)
        eq_8 = ops.eq(constant_20, constant_21)
        constant_22 = ops.constant(63, torch.int32)
        constant_23 = ops.constant(66, torch.int32)
        eq_9 = ops.eq(constant_22, constant_23)
        constant_24 = ops.constant(63, torch.int32)
        constant_25 = ops.constant(67, torch.int32)
        eq_10 = ops.eq(constant_24, constant_25)
        constant_26 = ops.constant(63, torch.int32)
        constant_27 = ops.constant(68, torch.int32)
        eq_11 = ops.eq(constant_26, constant_27)
        constant_28 = ops.constant(63, torch.int32)
        constant_29 = ops.constant(69, torch.int32)
        eq_12 = ops.eq(constant_28, constant_29)
        get_index_5 = self.get_index('index2')
        load_3 = ops.load('buf18', get_index_5)
        constant_30 = ops.constant(0.0, torch.float32)
        where_6 = ops.where(eq_12, constant_30, load_3)
        constant_31 = ops.constant(0.0, torch.float32)
        where_7 = ops.where(eq_11, constant_31, where_6)
        constant_32 = ops.constant(0.0, torch.float32)
        where_8 = ops.where(eq_10, constant_32, where_7)
        constant_33 = ops.constant(0.0, torch.float32)
        where_9 = ops.where(eq_9, constant_33, where_8)
        constant_34 = ops.constant(0.0, torch.float32)
        where_10 = ops.where(eq_8, constant_34, where_9)
        constant_35 = ops.constant(0.0, torch.float32)
        where_11 = ops.where(eq_7, constant_35, where_10)
        constant_36 = ops.constant(2.0, torch.float32)
        mul_1 = ops.mul(where_11, constant_36)
        get_index_6 = self.get_index('index0')
        load_4 = ops.load('full_default', get_index_6)
        where_12 = ops.where(eq_6, mul_1, load_4)
        add_1 = ops.add(add, where_12)
        get_index_7 = self.get_index('index0')
        store = ops.store('buf22', get_index_7, add_1, None)
        return store
op22 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[128], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, multi_processor_count=20), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_out_ptr0'], 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': '712B1D69F892A891D8FFA5075DCAB47CFF4E132D88BFC66744701CEAE226F127', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_out_ptr0, in_ptr0, in_ptr1, xnumel, XBLOCK : tl.constexpr):
        xnumel = 100
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp0 = tl.load(in_out_ptr0 + (x0), xmask)
        tmp14 = tl.load(in_ptr0 + (64))
        tmp15 = tl.broadcast_to(tmp14, [XBLOCK])
        tmp24 = tl.load(in_ptr1 + (x0), xmask)
        tmp35 = tl.load(in_ptr0 + (63))
        tmp36 = tl.broadcast_to(tmp35, [XBLOCK])
        tmp1 = x0
        tmp2 = tl.full([1], 64, tl.int32)
        tmp3 = tmp1 == tmp2
        tmp4 = tl.full([1], 65, tl.int32)
        tmp5 = tmp2 == tmp4
        tmp6 = tl.full([1], 66, tl.int32)
        tmp7 = tmp2 == tmp6
        tmp8 = tl.full([1], 67, tl.int32)
        tmp9 = tmp2 == tmp8
        tmp10 = tl.full([1], 68, tl.int32)
        tmp11 = tmp2 == tmp10
        tmp12 = tl.full([1], 69, tl.int32)
        tmp13 = tmp2 == tmp12
        tmp16 = 0.0
        tmp17 = tl.where(tmp13, tmp16, tmp15)
        tmp18 = tl.where(tmp11, tmp16, tmp17)
        tmp19 = tl.where(tmp9, tmp16, tmp18)
        tmp20 = tl.where(tmp7, tmp16, tmp19)
        tmp21 = tl.where(tmp5, tmp16, tmp20)
        tmp22 = 2.0
        tmp23 = tmp21 * tmp22
        tmp25 = tl.where(tmp3, tmp23, tmp24)
        tmp26 = tmp0 + tmp25
        tmp27 = tl.full([1], 63, tl.int32)
        tmp28 = tmp1 == tmp27
        tmp29 = tmp27 == tmp2
        tmp30 = tmp27 == tmp4
        tmp31 = tmp27 == tmp6
        tmp32 = tmp27 == tmp8
        tmp33 = tmp27 == tmp10
        tmp34 = tmp27 == tmp12
        tmp37 = tl.where(tmp34, tmp16, tmp36)
        tmp38 = tl.where(tmp33, tmp16, tmp37)
        tmp39 = tl.where(tmp32, tmp16, tmp38)
        tmp40 = tl.where(tmp31, tmp16, tmp39)
        tmp41 = tl.where(tmp30, tmp16, tmp40)
        tmp42 = tl.where(tmp29, tmp16, tmp41)
        tmp43 = tmp42 * tmp22
        tmp44 = tl.where(tmp28, tmp43, tmp24)
        tmp45 = tmp26 + tmp44
        tl.store(in_out_ptr0 + (x0), tmp45, xmask)


op23: SchedulerNode(ComputedBuffer)
op23.writes = [MemoryDep('buf23', c0, {c0: 100}, None)]
op23.unmet_dependencies = [MemoryDep('buf18', 62, {}, None), MemoryDep('buf22', c0, {c0: 100}, None)]
op23.met_dependencies = [MemoryDep('full_default', c0, {c0: 100}, None)]
op23.outputs = [
    buf23: ComputedBuffer
    buf23.layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
    buf23.users = [NodeUser(node=SchedulerNode(name='op27'), can_inplace=True, is_weak=False)]
]
op23.group.device = cuda:0
op23.group.iteration = (100, 1)
op23.sizes = ([100], [])
buf22_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf18_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
full_default_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf23_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
class op23_loop_body:
    var_ranges = {z0: 100}
    index0 = z0
    index1 = 62
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf22', get_index)
        get_index_1 = self.get_index('index0')
        index_expr = ops.index_expr(get_index_1, torch.int32)
        constant = ops.constant(62, torch.int32)
        eq = ops.eq(index_expr, constant)
        constant_1 = ops.constant(62, torch.int32)
        constant_2 = ops.constant(63, torch.int32)
        eq_1 = ops.eq(constant_1, constant_2)
        constant_3 = ops.constant(62, torch.int32)
        constant_4 = ops.constant(64, torch.int32)
        eq_2 = ops.eq(constant_3, constant_4)
        constant_5 = ops.constant(62, torch.int32)
        constant_6 = ops.constant(65, torch.int32)
        eq_3 = ops.eq(constant_5, constant_6)
        constant_7 = ops.constant(62, torch.int32)
        constant_8 = ops.constant(66, torch.int32)
        eq_4 = ops.eq(constant_7, constant_8)
        constant_9 = ops.constant(62, torch.int32)
        constant_10 = ops.constant(67, torch.int32)
        eq_5 = ops.eq(constant_9, constant_10)
        constant_11 = ops.constant(62, torch.int32)
        constant_12 = ops.constant(68, torch.int32)
        eq_6 = ops.eq(constant_11, constant_12)
        constant_13 = ops.constant(62, torch.int32)
        constant_14 = ops.constant(69, torch.int32)
        eq_7 = ops.eq(constant_13, constant_14)
        get_index_2 = self.get_index('index1')
        load_1 = ops.load('buf18', get_index_2)
        constant_15 = ops.constant(0.0, torch.float32)
        where = ops.where(eq_7, constant_15, load_1)
        constant_16 = ops.constant(0.0, torch.float32)
        where_1 = ops.where(eq_6, constant_16, where)
        constant_17 = ops.constant(0.0, torch.float32)
        where_2 = ops.where(eq_5, constant_17, where_1)
        constant_18 = ops.constant(0.0, torch.float32)
        where_3 = ops.where(eq_4, constant_18, where_2)
        constant_19 = ops.constant(0.0, torch.float32)
        where_4 = ops.where(eq_3, constant_19, where_3)
        constant_20 = ops.constant(0.0, torch.float32)
        where_5 = ops.where(eq_2, constant_20, where_4)
        constant_21 = ops.constant(0.0, torch.float32)
        where_6 = ops.where(eq_1, constant_21, where_5)
        constant_22 = ops.constant(2.0, torch.float32)
        mul = ops.mul(where_6, constant_22)
        get_index_3 = self.get_index('index0')
        load_2 = ops.load('full_default', get_index_3)
        where_7 = ops.where(eq, mul, load_2)
        add = ops.add(load, where_7)
        get_index_4 = self.get_index('index0')
        store = ops.store('buf23', get_index_4, add, None)
        return store
op23 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[128], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, multi_processor_count=20), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_out_ptr0'], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 0, 'backend_hash': '712B1D69F892A891D8FFA5075DCAB47CFF4E132D88BFC66744701CEAE226F127', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_out_ptr0, in_ptr0, in_ptr1, xnumel, XBLOCK : tl.constexpr):
        xnumel = 100
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp0 = tl.load(in_out_ptr0 + (x0), xmask)
        tmp18 = tl.load(in_ptr0 + (62))
        tmp19 = tl.broadcast_to(tmp18, [XBLOCK])
        tmp30 = tl.load(in_ptr1 + (x0), xmask)
        tmp1 = x0
        tmp2 = tl.full([1], 62, tl.int32)
        tmp3 = tmp1 == tmp2
        tmp4 = tl.full([1], 63, tl.int32)
        tmp5 = tmp2 == tmp4
        tmp6 = tl.full([1], 64, tl.int32)
        tmp7 = tmp2 == tmp6
        tmp8 = tl.full([1], 65, tl.int32)
        tmp9 = tmp2 == tmp8
        tmp10 = tl.full([1], 66, tl.int32)
        tmp11 = tmp2 == tmp10
        tmp12 = tl.full([1], 67, tl.int32)
        tmp13 = tmp2 == tmp12
        tmp14 = tl.full([1], 68, tl.int32)
        tmp15 = tmp2 == tmp14
        tmp16 = tl.full([1], 69, tl.int32)
        tmp17 = tmp2 == tmp16
        tmp20 = 0.0
        tmp21 = tl.where(tmp17, tmp20, tmp19)
        tmp22 = tl.where(tmp15, tmp20, tmp21)
        tmp23 = tl.where(tmp13, tmp20, tmp22)
        tmp24 = tl.where(tmp11, tmp20, tmp23)
        tmp25 = tl.where(tmp9, tmp20, tmp24)
        tmp26 = tl.where(tmp7, tmp20, tmp25)
        tmp27 = tl.where(tmp5, tmp20, tmp26)
        tmp28 = 2.0
        tmp29 = tmp27 * tmp28
        tmp31 = tl.where(tmp3, tmp29, tmp30)
        tmp32 = tmp0 + tmp31
        tl.store(in_out_ptr0 + (x0), tmp32, xmask)


op24: SchedulerNode(ComputedBuffer)
op24.writes = [MemoryDep('buf24', c0, {c0: 100}, None)]
op24.unmet_dependencies = [MemoryDep('buf18', 61, {}, None)]
op24.met_dependencies = [MemoryDep('full_default', c0, {c0: 100}, None)]
op24.outputs = [
    buf24: ComputedBuffer
    buf24.layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
    buf24.users = [NodeUser(node=SchedulerNode(name='op27'), can_inplace=True, is_weak=False)]
]
op24.group.device = cuda:0
op24.group.iteration = (100, 1)
op24.sizes = ([100], [])
buf18_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
full_default_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf24_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
class op24_loop_body:
    var_ranges = {z0: 100}
    index0 = z0
    index1 = 61
    def body(self, ops):
        get_index = self.get_index('index0')
        index_expr = ops.index_expr(get_index, torch.int32)
        constant = ops.constant(61, torch.int32)
        eq = ops.eq(index_expr, constant)
        constant_1 = ops.constant(61, torch.int32)
        constant_2 = ops.constant(62, torch.int32)
        eq_1 = ops.eq(constant_1, constant_2)
        constant_3 = ops.constant(61, torch.int32)
        constant_4 = ops.constant(63, torch.int32)
        eq_2 = ops.eq(constant_3, constant_4)
        constant_5 = ops.constant(61, torch.int32)
        constant_6 = ops.constant(64, torch.int32)
        eq_3 = ops.eq(constant_5, constant_6)
        constant_7 = ops.constant(61, torch.int32)
        constant_8 = ops.constant(65, torch.int32)
        eq_4 = ops.eq(constant_7, constant_8)
        constant_9 = ops.constant(61, torch.int32)
        constant_10 = ops.constant(66, torch.int32)
        eq_5 = ops.eq(constant_9, constant_10)
        constant_11 = ops.constant(61, torch.int32)
        constant_12 = ops.constant(67, torch.int32)
        eq_6 = ops.eq(constant_11, constant_12)
        constant_13 = ops.constant(61, torch.int32)
        constant_14 = ops.constant(68, torch.int32)
        eq_7 = ops.eq(constant_13, constant_14)
        constant_15 = ops.constant(61, torch.int32)
        constant_16 = ops.constant(69, torch.int32)
        eq_8 = ops.eq(constant_15, constant_16)
        get_index_1 = self.get_index('index1')
        load = ops.load('buf18', get_index_1)
        constant_17 = ops.constant(0.0, torch.float32)
        where = ops.where(eq_8, constant_17, load)
        constant_18 = ops.constant(0.0, torch.float32)
        where_1 = ops.where(eq_7, constant_18, where)
        constant_19 = ops.constant(0.0, torch.float32)
        where_2 = ops.where(eq_6, constant_19, where_1)
        constant_20 = ops.constant(0.0, torch.float32)
        where_3 = ops.where(eq_5, constant_20, where_2)
        constant_21 = ops.constant(0.0, torch.float32)
        where_4 = ops.where(eq_4, constant_21, where_3)
        constant_22 = ops.constant(0.0, torch.float32)
        where_5 = ops.where(eq_3, constant_22, where_4)
        constant_23 = ops.constant(0.0, torch.float32)
        where_6 = ops.where(eq_2, constant_23, where_5)
        constant_24 = ops.constant(0.0, torch.float32)
        where_7 = ops.where(eq_1, constant_24, where_6)
        constant_25 = ops.constant(2.0, torch.float32)
        mul = ops.mul(where_7, constant_25)
        get_index_2 = self.get_index('index0')
        load_1 = ops.load('full_default', get_index_2)
        where_8 = ops.where(eq, mul, load_1)
        get_index_3 = self.get_index('index0')
        store = ops.store('buf24', get_index_3, where_8, None)
        return store
op24 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[128], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, multi_processor_count=20), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '712B1D69F892A891D8FFA5075DCAB47CFF4E132D88BFC66744701CEAE226F127', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 100
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp19 = tl.load(in_ptr0 + (61))
        tmp20 = tl.broadcast_to(tmp19, [XBLOCK])
        tmp32 = tl.load(in_ptr1 + (x0), xmask)
        tmp0 = x0
        tmp1 = tl.full([1], 61, tl.int32)
        tmp2 = tmp0 == tmp1
        tmp3 = tl.full([1], 62, tl.int32)
        tmp4 = tmp1 == tmp3
        tmp5 = tl.full([1], 63, tl.int32)
        tmp6 = tmp1 == tmp5
        tmp7 = tl.full([1], 64, tl.int32)
        tmp8 = tmp1 == tmp7
        tmp9 = tl.full([1], 65, tl.int32)
        tmp10 = tmp1 == tmp9
        tmp11 = tl.full([1], 66, tl.int32)
        tmp12 = tmp1 == tmp11
        tmp13 = tl.full([1], 67, tl.int32)
        tmp14 = tmp1 == tmp13
        tmp15 = tl.full([1], 68, tl.int32)
        tmp16 = tmp1 == tmp15
        tmp17 = tl.full([1], 69, tl.int32)
        tmp18 = tmp1 == tmp17
        tmp21 = 0.0
        tmp22 = tl.where(tmp18, tmp21, tmp20)
        tmp23 = tl.where(tmp16, tmp21, tmp22)
        tmp24 = tl.where(tmp14, tmp21, tmp23)
        tmp25 = tl.where(tmp12, tmp21, tmp24)
        tmp26 = tl.where(tmp10, tmp21, tmp25)
        tmp27 = tl.where(tmp8, tmp21, tmp26)
        tmp28 = tl.where(tmp6, tmp21, tmp27)
        tmp29 = tl.where(tmp4, tmp21, tmp28)
        tmp30 = 2.0
        tmp31 = tmp29 * tmp30
        tmp33 = tl.where(tmp2, tmp31, tmp32)
        tl.store(out_ptr0 + (x0), tmp33, xmask)


op25: SchedulerNode(ComputedBuffer)
op25.writes = [MemoryDep('buf25', c0, {c0: 100}, None)]
op25.unmet_dependencies = [MemoryDep('buf18', c0, {c0: 100}, None)]
op25.met_dependencies = []
op25.outputs = [
    buf25: ComputedBuffer
    buf25.layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
    buf25.users = [
        NodeUser(node=SchedulerNode(name='op27'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op28'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op29'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op30'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op31'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op32'), can_inplace=True, is_weak=False),
        NodeUser(node=SchedulerNode(name='op33'), can_inplace=False, is_weak=False),
    ]
]
op25.group.device = cuda:0
op25.group.iteration = (100, 1)
op25.sizes = ([100], [])
buf18_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf25_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
class op25_loop_body:
    var_ranges = {z0: 100}
    index0 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        index_expr = ops.index_expr(get_index, torch.int32)
        constant = ops.constant(60, torch.int32)
        eq = ops.eq(index_expr, constant)
        get_index_1 = self.get_index('index0')
        index_expr_1 = ops.index_expr(get_index_1, torch.int32)
        constant_1 = ops.constant(61, torch.int32)
        eq_1 = ops.eq(index_expr_1, constant_1)
        get_index_2 = self.get_index('index0')
        index_expr_2 = ops.index_expr(get_index_2, torch.int32)
        constant_2 = ops.constant(62, torch.int32)
        eq_2 = ops.eq(index_expr_2, constant_2)
        get_index_3 = self.get_index('index0')
        index_expr_3 = ops.index_expr(get_index_3, torch.int32)
        constant_3 = ops.constant(63, torch.int32)
        eq_3 = ops.eq(index_expr_3, constant_3)
        get_index_4 = self.get_index('index0')
        index_expr_4 = ops.index_expr(get_index_4, torch.int32)
        constant_4 = ops.constant(64, torch.int32)
        eq_4 = ops.eq(index_expr_4, constant_4)
        get_index_5 = self.get_index('index0')
        index_expr_5 = ops.index_expr(get_index_5, torch.int32)
        constant_5 = ops.constant(65, torch.int32)
        eq_5 = ops.eq(index_expr_5, constant_5)
        get_index_6 = self.get_index('index0')
        index_expr_6 = ops.index_expr(get_index_6, torch.int32)
        constant_6 = ops.constant(66, torch.int32)
        eq_6 = ops.eq(index_expr_6, constant_6)
        get_index_7 = self.get_index('index0')
        index_expr_7 = ops.index_expr(get_index_7, torch.int32)
        constant_7 = ops.constant(67, torch.int32)
        eq_7 = ops.eq(index_expr_7, constant_7)
        get_index_8 = self.get_index('index0')
        index_expr_8 = ops.index_expr(get_index_8, torch.int32)
        constant_8 = ops.constant(68, torch.int32)
        eq_8 = ops.eq(index_expr_8, constant_8)
        get_index_9 = self.get_index('index0')
        index_expr_9 = ops.index_expr(get_index_9, torch.int32)
        constant_9 = ops.constant(69, torch.int32)
        eq_9 = ops.eq(index_expr_9, constant_9)
        get_index_10 = self.get_index('index0')
        load = ops.load('buf18', get_index_10)
        constant_10 = ops.constant(0.0, torch.float32)
        where = ops.where(eq_9, constant_10, load)
        constant_11 = ops.constant(0.0, torch.float32)
        where_1 = ops.where(eq_8, constant_11, where)
        constant_12 = ops.constant(0.0, torch.float32)
        where_2 = ops.where(eq_7, constant_12, where_1)
        constant_13 = ops.constant(0.0, torch.float32)
        where_3 = ops.where(eq_6, constant_13, where_2)
        constant_14 = ops.constant(0.0, torch.float32)
        where_4 = ops.where(eq_5, constant_14, where_3)
        constant_15 = ops.constant(0.0, torch.float32)
        where_5 = ops.where(eq_4, constant_15, where_4)
        constant_16 = ops.constant(0.0, torch.float32)
        where_6 = ops.where(eq_3, constant_16, where_5)
        constant_17 = ops.constant(0.0, torch.float32)
        where_7 = ops.where(eq_2, constant_17, where_6)
        constant_18 = ops.constant(0.0, torch.float32)
        where_8 = ops.where(eq_1, constant_18, where_7)
        constant_19 = ops.constant(0.0, torch.float32)
        where_9 = ops.where(eq, constant_19, where_8)
        get_index_11 = self.get_index('index0')
        store = ops.store('buf25', get_index_11, where_9, None)
        return store
op25 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[128], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, multi_processor_count=20), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '712B1D69F892A891D8FFA5075DCAB47CFF4E132D88BFC66744701CEAE226F127', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 100
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp21 = tl.load(in_ptr0 + (x0), xmask)
        tmp0 = x0
        tmp1 = tl.full([1], 60, tl.int32)
        tmp2 = tmp0 == tmp1
        tmp3 = tl.full([1], 61, tl.int32)
        tmp4 = tmp0 == tmp3
        tmp5 = tl.full([1], 62, tl.int32)
        tmp6 = tmp0 == tmp5
        tmp7 = tl.full([1], 63, tl.int32)
        tmp8 = tmp0 == tmp7
        tmp9 = tl.full([1], 64, tl.int32)
        tmp10 = tmp0 == tmp9
        tmp11 = tl.full([1], 65, tl.int32)
        tmp12 = tmp0 == tmp11
        tmp13 = tl.full([1], 66, tl.int32)
        tmp14 = tmp0 == tmp13
        tmp15 = tl.full([1], 67, tl.int32)
        tmp16 = tmp0 == tmp15
        tmp17 = tl.full([1], 68, tl.int32)
        tmp18 = tmp0 == tmp17
        tmp19 = tl.full([1], 69, tl.int32)
        tmp20 = tmp0 == tmp19
        tmp22 = 0.0
        tmp23 = tl.where(tmp20, tmp22, tmp21)
        tmp24 = tl.where(tmp18, tmp22, tmp23)
        tmp25 = tl.where(tmp16, tmp22, tmp24)
        tmp26 = tl.where(tmp14, tmp22, tmp25)
        tmp27 = tl.where(tmp12, tmp22, tmp26)
        tmp28 = tl.where(tmp10, tmp22, tmp27)
        tmp29 = tl.where(tmp8, tmp22, tmp28)
        tmp30 = tl.where(tmp6, tmp22, tmp29)
        tmp31 = tl.where(tmp4, tmp22, tmp30)
        tmp32 = tl.where(tmp2, tmp22, tmp31)
        tl.store(out_ptr0 + (x0), tmp32, xmask)


op26: SchedulerNode(ComputedBuffer)
op26.writes = [MemoryDep('buf26', 0, {}, None)]
op26.unmet_dependencies = [MemoryDep('buf18', 60, {}, None)]
op26.met_dependencies = []
op26.outputs = [
    buf26: ComputedBuffer
    buf26.layout = FixedLayout('cuda', torch.float32, size=[], stride=[])
    buf26.users = [NodeUser(node=SchedulerNode(name='op27'), can_inplace=False, is_weak=False)]
]
op26.group.device = cuda:0
op26.group.iteration = (1, 1)
op26.sizes = ([], [])
buf18_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf26_layout = FixedLayout('cuda', torch.float32, size=[], stride=[])
class op26_loop_body:
    var_ranges = {}
    index0 = 60
    index1 = 0
    def body(self, ops):
        constant = ops.constant(60, torch.int32)
        constant_1 = ops.constant(61, torch.int32)
        eq = ops.eq(constant, constant_1)
        constant_2 = ops.constant(60, torch.int32)
        constant_3 = ops.constant(62, torch.int32)
        eq_1 = ops.eq(constant_2, constant_3)
        constant_4 = ops.constant(60, torch.int32)
        constant_5 = ops.constant(63, torch.int32)
        eq_2 = ops.eq(constant_4, constant_5)
        constant_6 = ops.constant(60, torch.int32)
        constant_7 = ops.constant(64, torch.int32)
        eq_3 = ops.eq(constant_6, constant_7)
        constant_8 = ops.constant(60, torch.int32)
        constant_9 = ops.constant(65, torch.int32)
        eq_4 = ops.eq(constant_8, constant_9)
        constant_10 = ops.constant(60, torch.int32)
        constant_11 = ops.constant(66, torch.int32)
        eq_5 = ops.eq(constant_10, constant_11)
        constant_12 = ops.constant(60, torch.int32)
        constant_13 = ops.constant(67, torch.int32)
        eq_6 = ops.eq(constant_12, constant_13)
        constant_14 = ops.constant(60, torch.int32)
        constant_15 = ops.constant(68, torch.int32)
        eq_7 = ops.eq(constant_14, constant_15)
        constant_16 = ops.constant(60, torch.int32)
        constant_17 = ops.constant(69, torch.int32)
        eq_8 = ops.eq(constant_16, constant_17)
        get_index = self.get_index('index0')
        load = ops.load('buf18', get_index)
        constant_18 = ops.constant(0.0, torch.float32)
        where = ops.where(eq_8, constant_18, load)
        constant_19 = ops.constant(0.0, torch.float32)
        where_1 = ops.where(eq_7, constant_19, where)
        constant_20 = ops.constant(0.0, torch.float32)
        where_2 = ops.where(eq_6, constant_20, where_1)
        constant_21 = ops.constant(0.0, torch.float32)
        where_3 = ops.where(eq_5, constant_21, where_2)
        constant_22 = ops.constant(0.0, torch.float32)
        where_4 = ops.where(eq_4, constant_22, where_3)
        constant_23 = ops.constant(0.0, torch.float32)
        where_5 = ops.where(eq_3, constant_23, where_4)
        constant_24 = ops.constant(0.0, torch.float32)
        where_6 = ops.where(eq_2, constant_24, where_5)
        constant_25 = ops.constant(0.0, torch.float32)
        where_7 = ops.where(eq_1, constant_25, where_6)
        constant_26 = ops.constant(0.0, torch.float32)
        where_8 = ops.where(eq, constant_26, where_7)
        constant_27 = ops.constant(2.0, torch.float32)
        mul = ops.mul(where_8, constant_27)
        get_index_1 = self.get_index('index1')
        store = ops.store('buf26', get_index_1, mul, None)
        return store
op26 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[1], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, multi_processor_count=20), 'constants': {2: 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(2,))]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '712B1D69F892A891D8FFA5075DCAB47CFF4E132D88BFC66744701CEAE226F127', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 1
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = tl.full([XBLOCK], True, tl.int1)
        tmp19 = tl.load(in_ptr0 + (60))
        tmp20 = tl.broadcast_to(tmp19, [XBLOCK])
        tmp0 = tl.full([1], 60, tl.int32)
        tmp1 = tl.full([1], 61, tl.int32)
        tmp2 = tmp0 == tmp1
        tmp3 = tl.full([1], 62, tl.int32)
        tmp4 = tmp0 == tmp3
        tmp5 = tl.full([1], 63, tl.int32)
        tmp6 = tmp0 == tmp5
        tmp7 = tl.full([1], 64, tl.int32)
        tmp8 = tmp0 == tmp7
        tmp9 = tl.full([1], 65, tl.int32)
        tmp10 = tmp0 == tmp9
        tmp11 = tl.full([1], 66, tl.int32)
        tmp12 = tmp0 == tmp11
        tmp13 = tl.full([1], 67, tl.int32)
        tmp14 = tmp0 == tmp13
        tmp15 = tl.full([1], 68, tl.int32)
        tmp16 = tmp0 == tmp15
        tmp17 = tl.full([1], 69, tl.int32)
        tmp18 = tmp0 == tmp17
        tmp21 = 0.0
        tmp22 = tl.where(tmp18, tmp21, tmp20)
        tmp23 = tl.where(tmp16, tmp21, tmp22)
        tmp24 = tl.where(tmp14, tmp21, tmp23)
        tmp25 = tl.where(tmp12, tmp21, tmp24)
        tmp26 = tl.where(tmp10, tmp21, tmp25)
        tmp27 = tl.where(tmp8, tmp21, tmp26)
        tmp28 = tl.where(tmp6, tmp21, tmp27)
        tmp29 = tl.where(tmp4, tmp21, tmp28)
        tmp30 = tl.where(tmp2, tmp21, tmp29)
        tmp31 = 2.0
        tmp32 = tmp30 * tmp31
        tl.store(out_ptr0 + (tl.full([XBLOCK], 0, tl.int32)), tmp32, None)


op27: SchedulerNode(ComputedBuffer)
op27.writes = [MemoryDep('buf27', c0, {c0: 100}, None)]
op27.unmet_dependencies = 
    [   MemoryDep('buf23', c0, {c0: 100}, None),
        MemoryDep('buf24', c0, {c0: 100}, None),
        MemoryDep('buf25', 57, {}, None),
        MemoryDep('buf25', 58, {}, None),
        MemoryDep('buf25', 59, {}, None),
        MemoryDep('buf26', 0, {}, None)]
op27.met_dependencies = [MemoryDep('full_default', c0, {c0: 100}, None)]
op27.outputs = [
    buf27: ComputedBuffer
    buf27.layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
    buf27.users = [NodeUser(node=SchedulerNode(name='op28'), can_inplace=True, is_weak=False)]
]
op27.group.device = cuda:0
op27.group.iteration = (100, 1)
op27.sizes = ([100], [])
buf23_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf24_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf26_layout = FixedLayout('cuda', torch.float32, size=[], stride=[])
full_default_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf25_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf25_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf25_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf27_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
class op27_loop_body:
    var_ranges = {z0: 100}
    index0 = z0
    index1 = 0
    index2 = 59
    index3 = 58
    index4 = 57
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf23', get_index)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('buf24', get_index_1)
        add = ops.add(load, load_1)
        get_index_2 = self.get_index('index0')
        index_expr = ops.index_expr(get_index_2, torch.int32)
        constant = ops.constant(60, torch.int32)
        eq = ops.eq(index_expr, constant)
        get_index_3 = self.get_index('index1')
        load_2 = ops.load('buf26', get_index_3)
        get_index_4 = self.get_index('index0')
        load_3 = ops.load('full_default', get_index_4)
        where = ops.where(eq, load_2, load_3)
        add_1 = ops.add(add, where)
        get_index_5 = self.get_index('index0')
        index_expr_1 = ops.index_expr(get_index_5, torch.int32)
        constant_1 = ops.constant(59, torch.int32)
        eq_1 = ops.eq(index_expr_1, constant_1)
        get_index_6 = self.get_index('index2')
        load_4 = ops.load('buf25', get_index_6)
        constant_2 = ops.constant(2.0, torch.float32)
        mul = ops.mul(load_4, constant_2)
        get_index_7 = self.get_index('index0')
        load_5 = ops.load('full_default', get_index_7)
        where_1 = ops.where(eq_1, mul, load_5)
        add_2 = ops.add(add_1, where_1)
        get_index_8 = self.get_index('index0')
        index_expr_2 = ops.index_expr(get_index_8, torch.int32)
        constant_3 = ops.constant(58, torch.int32)
        eq_2 = ops.eq(index_expr_2, constant_3)
        constant_4 = ops.constant(58, torch.int32)
        constant_5 = ops.constant(59, torch.int32)
        eq_3 = ops.eq(constant_4, constant_5)
        get_index_9 = self.get_index('index3')
        load_6 = ops.load('buf25', get_index_9)
        constant_6 = ops.constant(0.0, torch.float32)
        where_2 = ops.where(eq_3, constant_6, load_6)
        constant_7 = ops.constant(2.0, torch.float32)
        mul_1 = ops.mul(where_2, constant_7)
        get_index_10 = self.get_index('index0')
        load_7 = ops.load('full_default', get_index_10)
        where_3 = ops.where(eq_2, mul_1, load_7)
        add_3 = ops.add(add_2, where_3)
        get_index_11 = self.get_index('index0')
        index_expr_3 = ops.index_expr(get_index_11, torch.int32)
        constant_8 = ops.constant(57, torch.int32)
        eq_4 = ops.eq(index_expr_3, constant_8)
        constant_9 = ops.constant(57, torch.int32)
        constant_10 = ops.constant(58, torch.int32)
        eq_5 = ops.eq(constant_9, constant_10)
        constant_11 = ops.constant(57, torch.int32)
        constant_12 = ops.constant(59, torch.int32)
        eq_6 = ops.eq(constant_11, constant_12)
        get_index_12 = self.get_index('index4')
        load_8 = ops.load('buf25', get_index_12)
        constant_13 = ops.constant(0.0, torch.float32)
        where_4 = ops.where(eq_6, constant_13, load_8)
        constant_14 = ops.constant(0.0, torch.float32)
        where_5 = ops.where(eq_5, constant_14, where_4)
        constant_15 = ops.constant(2.0, torch.float32)
        mul_2 = ops.mul(where_5, constant_15)
        get_index_13 = self.get_index('index0')
        load_9 = ops.load('full_default', get_index_13)
        where_6 = ops.where(eq_4, mul_2, load_9)
        add_4 = ops.add(add_3, where_6)
        get_index_14 = self.get_index('index0')
        store = ops.store('buf27', get_index_14, add_4, None)
        return store
op27 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[128], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, multi_processor_count=20), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_out_ptr0'], 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': '712B1D69F892A891D8FFA5075DCAB47CFF4E132D88BFC66744701CEAE226F127', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, xnumel, XBLOCK : tl.constexpr):
        xnumel = 100
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp0 = tl.load(in_out_ptr0 + (x0), xmask)
        tmp1 = tl.load(in_ptr0 + (x0), xmask)
        tmp6 = tl.load(in_ptr1 + (0))
        tmp7 = tl.broadcast_to(tmp6, [XBLOCK])
        tmp8 = tl.load(in_ptr2 + (x0), xmask)
        tmp13 = tl.load(in_ptr3 + (59))
        tmp14 = tl.broadcast_to(tmp13, [XBLOCK])
        tmp22 = tl.load(in_ptr3 + (58))
        tmp23 = tl.broadcast_to(tmp22, [XBLOCK])
        tmp33 = tl.load(in_ptr3 + (57))
        tmp34 = tl.broadcast_to(tmp33, [XBLOCK])
        tmp2 = tmp0 + tmp1
        tmp3 = x0
        tmp4 = tl.full([1], 60, tl.int32)
        tmp5 = tmp3 == tmp4
        tmp9 = tl.where(tmp5, tmp7, tmp8)
        tmp10 = tmp2 + tmp9
        tmp11 = tl.full([1], 59, tl.int32)
        tmp12 = tmp3 == tmp11
        tmp15 = 2.0
        tmp16 = tmp14 * tmp15
        tmp17 = tl.where(tmp12, tmp16, tmp8)
        tmp18 = tmp10 + tmp17
        tmp19 = tl.full([1], 58, tl.int32)
        tmp20 = tmp3 == tmp19
        tmp21 = tmp19 == tmp11
        tmp24 = 0.0
        tmp25 = tl.where(tmp21, tmp24, tmp23)
        tmp26 = tmp25 * tmp15
        tmp27 = tl.where(tmp20, tmp26, tmp8)
        tmp28 = tmp18 + tmp27
        tmp29 = tl.full([1], 57, tl.int32)
        tmp30 = tmp3 == tmp29
        tmp31 = tmp29 == tmp19
        tmp32 = tmp29 == tmp11
        tmp35 = tl.where(tmp32, tmp24, tmp34)
        tmp36 = tl.where(tmp31, tmp24, tmp35)
        tmp37 = tmp36 * tmp15
        tmp38 = tl.where(tmp30, tmp37, tmp8)
        tmp39 = tmp28 + tmp38
        tl.store(in_out_ptr0 + (x0), tmp39, xmask)


op28: SchedulerNode(ComputedBuffer)
op28.writes = [MemoryDep('buf28', c0, {c0: 100}, None)]
op28.unmet_dependencies = 
    [   MemoryDep('buf25', 55, {}, None),
        MemoryDep('buf25', 56, {}, None),
        MemoryDep('buf27', c0, {c0: 100}, None)]
op28.met_dependencies = [MemoryDep('full_default', c0, {c0: 100}, None)]
op28.outputs = [
    buf28: ComputedBuffer
    buf28.layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
    buf28.users = [NodeUser(node=SchedulerNode(name='op29'), can_inplace=True, is_weak=False)]
]
op28.group.device = cuda:0
op28.group.iteration = (100, 1)
op28.sizes = ([100], [])
buf27_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf25_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
full_default_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf25_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf28_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
class op28_loop_body:
    var_ranges = {z0: 100}
    index0 = z0
    index1 = 56
    index2 = 55
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf27', get_index)
        get_index_1 = self.get_index('index0')
        index_expr = ops.index_expr(get_index_1, torch.int32)
        constant = ops.constant(56, torch.int32)
        eq = ops.eq(index_expr, constant)
        constant_1 = ops.constant(56, torch.int32)
        constant_2 = ops.constant(57, torch.int32)
        eq_1 = ops.eq(constant_1, constant_2)
        constant_3 = ops.constant(56, torch.int32)
        constant_4 = ops.constant(58, torch.int32)
        eq_2 = ops.eq(constant_3, constant_4)
        constant_5 = ops.constant(56, torch.int32)
        constant_6 = ops.constant(59, torch.int32)
        eq_3 = ops.eq(constant_5, constant_6)
        get_index_2 = self.get_index('index1')
        load_1 = ops.load('buf25', get_index_2)
        constant_7 = ops.constant(0.0, torch.float32)
        where = ops.where(eq_3, constant_7, load_1)
        constant_8 = ops.constant(0.0, torch.float32)
        where_1 = ops.where(eq_2, constant_8, where)
        constant_9 = ops.constant(0.0, torch.float32)
        where_2 = ops.where(eq_1, constant_9, where_1)
        constant_10 = ops.constant(2.0, torch.float32)
        mul = ops.mul(where_2, constant_10)
        get_index_3 = self.get_index('index0')
        load_2 = ops.load('full_default', get_index_3)
        where_3 = ops.where(eq, mul, load_2)
        add = ops.add(load, where_3)
        get_index_4 = self.get_index('index0')
        index_expr_1 = ops.index_expr(get_index_4, torch.int32)
        constant_11 = ops.constant(55, torch.int32)
        eq_4 = ops.eq(index_expr_1, constant_11)
        constant_12 = ops.constant(55, torch.int32)
        constant_13 = ops.constant(56, torch.int32)
        eq_5 = ops.eq(constant_12, constant_13)
        constant_14 = ops.constant(55, torch.int32)
        constant_15 = ops.constant(57, torch.int32)
        eq_6 = ops.eq(constant_14, constant_15)
        constant_16 = ops.constant(55, torch.int32)
        constant_17 = ops.constant(58, torch.int32)
        eq_7 = ops.eq(constant_16, constant_17)
        constant_18 = ops.constant(55, torch.int32)
        constant_19 = ops.constant(59, torch.int32)
        eq_8 = ops.eq(constant_18, constant_19)
        get_index_5 = self.get_index('index2')
        load_3 = ops.load('buf25', get_index_5)
        constant_20 = ops.constant(0.0, torch.float32)
        where_4 = ops.where(eq_8, constant_20, load_3)
        constant_21 = ops.constant(0.0, torch.float32)
        where_5 = ops.where(eq_7, constant_21, where_4)
        constant_22 = ops.constant(0.0, torch.float32)
        where_6 = ops.where(eq_6, constant_22, where_5)
        constant_23 = ops.constant(0.0, torch.float32)
        where_7 = ops.where(eq_5, constant_23, where_6)
        constant_24 = ops.constant(2.0, torch.float32)
        mul_1 = ops.mul(where_7, constant_24)
        get_index_6 = self.get_index('index0')
        load_4 = ops.load('full_default', get_index_6)
        where_8 = ops.where(eq_4, mul_1, load_4)
        add_1 = ops.add(add, where_8)
        get_index_7 = self.get_index('index0')
        store = ops.store('buf28', get_index_7, add_1, None)
        return store
op28 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[128], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, multi_processor_count=20), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_out_ptr0'], 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': '712B1D69F892A891D8FFA5075DCAB47CFF4E132D88BFC66744701CEAE226F127', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_out_ptr0, in_ptr0, in_ptr1, xnumel, XBLOCK : tl.constexpr):
        xnumel = 100
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp0 = tl.load(in_out_ptr0 + (x0), xmask)
        tmp10 = tl.load(in_ptr0 + (56))
        tmp11 = tl.broadcast_to(tmp10, [XBLOCK])
        tmp18 = tl.load(in_ptr1 + (x0), xmask)
        tmp27 = tl.load(in_ptr0 + (55))
        tmp28 = tl.broadcast_to(tmp27, [XBLOCK])
        tmp1 = x0
        tmp2 = tl.full([1], 56, tl.int32)
        tmp3 = tmp1 == tmp2
        tmp4 = tl.full([1], 57, tl.int32)
        tmp5 = tmp2 == tmp4
        tmp6 = tl.full([1], 58, tl.int32)
        tmp7 = tmp2 == tmp6
        tmp8 = tl.full([1], 59, tl.int32)
        tmp9 = tmp2 == tmp8
        tmp12 = 0.0
        tmp13 = tl.where(tmp9, tmp12, tmp11)
        tmp14 = tl.where(tmp7, tmp12, tmp13)
        tmp15 = tl.where(tmp5, tmp12, tmp14)
        tmp16 = 2.0
        tmp17 = tmp15 * tmp16
        tmp19 = tl.where(tmp3, tmp17, tmp18)
        tmp20 = tmp0 + tmp19
        tmp21 = tl.full([1], 55, tl.int32)
        tmp22 = tmp1 == tmp21
        tmp23 = tmp21 == tmp2
        tmp24 = tmp21 == tmp4
        tmp25 = tmp21 == tmp6
        tmp26 = tmp21 == tmp8
        tmp29 = tl.where(tmp26, tmp12, tmp28)
        tmp30 = tl.where(tmp25, tmp12, tmp29)
        tmp31 = tl.where(tmp24, tmp12, tmp30)
        tmp32 = tl.where(tmp23, tmp12, tmp31)
        tmp33 = tmp32 * tmp16
        tmp34 = tl.where(tmp22, tmp33, tmp18)
        tmp35 = tmp20 + tmp34
        tl.store(in_out_ptr0 + (x0), tmp35, xmask)


op29: SchedulerNode(ComputedBuffer)
op29.writes = [MemoryDep('buf29', c0, {c0: 100}, None)]
op29.unmet_dependencies = 
    [   MemoryDep('buf25', 53, {}, None),
        MemoryDep('buf25', 54, {}, None),
        MemoryDep('buf28', c0, {c0: 100}, None)]
op29.met_dependencies = [MemoryDep('full_default', c0, {c0: 100}, None)]
op29.outputs = [
    buf29: ComputedBuffer
    buf29.layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
    buf29.users = [NodeUser(node=SchedulerNode(name='op30'), can_inplace=True, is_weak=False)]
]
op29.group.device = cuda:0
op29.group.iteration = (100, 1)
op29.sizes = ([100], [])
buf28_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf25_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
full_default_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf25_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf29_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
class op29_loop_body:
    var_ranges = {z0: 100}
    index0 = z0
    index1 = 54
    index2 = 53
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf28', get_index)
        get_index_1 = self.get_index('index0')
        index_expr = ops.index_expr(get_index_1, torch.int32)
        constant = ops.constant(54, torch.int32)
        eq = ops.eq(index_expr, constant)
        constant_1 = ops.constant(54, torch.int32)
        constant_2 = ops.constant(55, torch.int32)
        eq_1 = ops.eq(constant_1, constant_2)
        constant_3 = ops.constant(54, torch.int32)
        constant_4 = ops.constant(56, torch.int32)
        eq_2 = ops.eq(constant_3, constant_4)
        constant_5 = ops.constant(54, torch.int32)
        constant_6 = ops.constant(57, torch.int32)
        eq_3 = ops.eq(constant_5, constant_6)
        constant_7 = ops.constant(54, torch.int32)
        constant_8 = ops.constant(58, torch.int32)
        eq_4 = ops.eq(constant_7, constant_8)
        constant_9 = ops.constant(54, torch.int32)
        constant_10 = ops.constant(59, torch.int32)
        eq_5 = ops.eq(constant_9, constant_10)
        get_index_2 = self.get_index('index1')
        load_1 = ops.load('buf25', get_index_2)
        constant_11 = ops.constant(0.0, torch.float32)
        where = ops.where(eq_5, constant_11, load_1)
        constant_12 = ops.constant(0.0, torch.float32)
        where_1 = ops.where(eq_4, constant_12, where)
        constant_13 = ops.constant(0.0, torch.float32)
        where_2 = ops.where(eq_3, constant_13, where_1)
        constant_14 = ops.constant(0.0, torch.float32)
        where_3 = ops.where(eq_2, constant_14, where_2)
        constant_15 = ops.constant(0.0, torch.float32)
        where_4 = ops.where(eq_1, constant_15, where_3)
        constant_16 = ops.constant(2.0, torch.float32)
        mul = ops.mul(where_4, constant_16)
        get_index_3 = self.get_index('index0')
        load_2 = ops.load('full_default', get_index_3)
        where_5 = ops.where(eq, mul, load_2)
        add = ops.add(load, where_5)
        get_index_4 = self.get_index('index0')
        index_expr_1 = ops.index_expr(get_index_4, torch.int32)
        constant_17 = ops.constant(53, torch.int32)
        eq_6 = ops.eq(index_expr_1, constant_17)
        constant_18 = ops.constant(53, torch.int32)
        constant_19 = ops.constant(54, torch.int32)
        eq_7 = ops.eq(constant_18, constant_19)
        constant_20 = ops.constant(53, torch.int32)
        constant_21 = ops.constant(55, torch.int32)
        eq_8 = ops.eq(constant_20, constant_21)
        constant_22 = ops.constant(53, torch.int32)
        constant_23 = ops.constant(56, torch.int32)
        eq_9 = ops.eq(constant_22, constant_23)
        constant_24 = ops.constant(53, torch.int32)
        constant_25 = ops.constant(57, torch.int32)
        eq_10 = ops.eq(constant_24, constant_25)
        constant_26 = ops.constant(53, torch.int32)
        constant_27 = ops.constant(58, torch.int32)
        eq_11 = ops.eq(constant_26, constant_27)
        constant_28 = ops.constant(53, torch.int32)
        constant_29 = ops.constant(59, torch.int32)
        eq_12 = ops.eq(constant_28, constant_29)
        get_index_5 = self.get_index('index2')
        load_3 = ops.load('buf25', get_index_5)
        constant_30 = ops.constant(0.0, torch.float32)
        where_6 = ops.where(eq_12, constant_30, load_3)
        constant_31 = ops.constant(0.0, torch.float32)
        where_7 = ops.where(eq_11, constant_31, where_6)
        constant_32 = ops.constant(0.0, torch.float32)
        where_8 = ops.where(eq_10, constant_32, where_7)
        constant_33 = ops.constant(0.0, torch.float32)
        where_9 = ops.where(eq_9, constant_33, where_8)
        constant_34 = ops.constant(0.0, torch.float32)
        where_10 = ops.where(eq_8, constant_34, where_9)
        constant_35 = ops.constant(0.0, torch.float32)
        where_11 = ops.where(eq_7, constant_35, where_10)
        constant_36 = ops.constant(2.0, torch.float32)
        mul_1 = ops.mul(where_11, constant_36)
        get_index_6 = self.get_index('index0')
        load_4 = ops.load('full_default', get_index_6)
        where_12 = ops.where(eq_6, mul_1, load_4)
        add_1 = ops.add(add, where_12)
        get_index_7 = self.get_index('index0')
        store = ops.store('buf29', get_index_7, add_1, None)
        return store
op29 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[128], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, multi_processor_count=20), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_out_ptr0'], 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': '712B1D69F892A891D8FFA5075DCAB47CFF4E132D88BFC66744701CEAE226F127', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_out_ptr0, in_ptr0, in_ptr1, xnumel, XBLOCK : tl.constexpr):
        xnumel = 100
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp0 = tl.load(in_out_ptr0 + (x0), xmask)
        tmp14 = tl.load(in_ptr0 + (54))
        tmp15 = tl.broadcast_to(tmp14, [XBLOCK])
        tmp24 = tl.load(in_ptr1 + (x0), xmask)
        tmp35 = tl.load(in_ptr0 + (53))
        tmp36 = tl.broadcast_to(tmp35, [XBLOCK])
        tmp1 = x0
        tmp2 = tl.full([1], 54, tl.int32)
        tmp3 = tmp1 == tmp2
        tmp4 = tl.full([1], 55, tl.int32)
        tmp5 = tmp2 == tmp4
        tmp6 = tl.full([1], 56, tl.int32)
        tmp7 = tmp2 == tmp6
        tmp8 = tl.full([1], 57, tl.int32)
        tmp9 = tmp2 == tmp8
        tmp10 = tl.full([1], 58, tl.int32)
        tmp11 = tmp2 == tmp10
        tmp12 = tl.full([1], 59, tl.int32)
        tmp13 = tmp2 == tmp12
        tmp16 = 0.0
        tmp17 = tl.where(tmp13, tmp16, tmp15)
        tmp18 = tl.where(tmp11, tmp16, tmp17)
        tmp19 = tl.where(tmp9, tmp16, tmp18)
        tmp20 = tl.where(tmp7, tmp16, tmp19)
        tmp21 = tl.where(tmp5, tmp16, tmp20)
        tmp22 = 2.0
        tmp23 = tmp21 * tmp22
        tmp25 = tl.where(tmp3, tmp23, tmp24)
        tmp26 = tmp0 + tmp25
        tmp27 = tl.full([1], 53, tl.int32)
        tmp28 = tmp1 == tmp27
        tmp29 = tmp27 == tmp2
        tmp30 = tmp27 == tmp4
        tmp31 = tmp27 == tmp6
        tmp32 = tmp27 == tmp8
        tmp33 = tmp27 == tmp10
        tmp34 = tmp27 == tmp12
        tmp37 = tl.where(tmp34, tmp16, tmp36)
        tmp38 = tl.where(tmp33, tmp16, tmp37)
        tmp39 = tl.where(tmp32, tmp16, tmp38)
        tmp40 = tl.where(tmp31, tmp16, tmp39)
        tmp41 = tl.where(tmp30, tmp16, tmp40)
        tmp42 = tl.where(tmp29, tmp16, tmp41)
        tmp43 = tmp42 * tmp22
        tmp44 = tl.where(tmp28, tmp43, tmp24)
        tmp45 = tmp26 + tmp44
        tl.store(in_out_ptr0 + (x0), tmp45, xmask)


op30: SchedulerNode(ComputedBuffer)
op30.writes = [MemoryDep('buf30', c0, {c0: 100}, None)]
op30.unmet_dependencies = [MemoryDep('buf25', 52, {}, None), MemoryDep('buf29', c0, {c0: 100}, None)]
op30.met_dependencies = [MemoryDep('full_default', c0, {c0: 100}, None)]
op30.outputs = [
    buf30: ComputedBuffer
    buf30.layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
    buf30.users = [NodeUser(node=SchedulerNode(name='op34'), can_inplace=True, is_weak=False)]
]
op30.group.device = cuda:0
op30.group.iteration = (100, 1)
op30.sizes = ([100], [])
buf29_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf25_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
full_default_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf30_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
class op30_loop_body:
    var_ranges = {z0: 100}
    index0 = z0
    index1 = 52
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf29', get_index)
        get_index_1 = self.get_index('index0')
        index_expr = ops.index_expr(get_index_1, torch.int32)
        constant = ops.constant(52, torch.int32)
        eq = ops.eq(index_expr, constant)
        constant_1 = ops.constant(52, torch.int32)
        constant_2 = ops.constant(53, torch.int32)
        eq_1 = ops.eq(constant_1, constant_2)
        constant_3 = ops.constant(52, torch.int32)
        constant_4 = ops.constant(54, torch.int32)
        eq_2 = ops.eq(constant_3, constant_4)
        constant_5 = ops.constant(52, torch.int32)
        constant_6 = ops.constant(55, torch.int32)
        eq_3 = ops.eq(constant_5, constant_6)
        constant_7 = ops.constant(52, torch.int32)
        constant_8 = ops.constant(56, torch.int32)
        eq_4 = ops.eq(constant_7, constant_8)
        constant_9 = ops.constant(52, torch.int32)
        constant_10 = ops.constant(57, torch.int32)
        eq_5 = ops.eq(constant_9, constant_10)
        constant_11 = ops.constant(52, torch.int32)
        constant_12 = ops.constant(58, torch.int32)
        eq_6 = ops.eq(constant_11, constant_12)
        constant_13 = ops.constant(52, torch.int32)
        constant_14 = ops.constant(59, torch.int32)
        eq_7 = ops.eq(constant_13, constant_14)
        get_index_2 = self.get_index('index1')
        load_1 = ops.load('buf25', get_index_2)
        constant_15 = ops.constant(0.0, torch.float32)
        where = ops.where(eq_7, constant_15, load_1)
        constant_16 = ops.constant(0.0, torch.float32)
        where_1 = ops.where(eq_6, constant_16, where)
        constant_17 = ops.constant(0.0, torch.float32)
        where_2 = ops.where(eq_5, constant_17, where_1)
        constant_18 = ops.constant(0.0, torch.float32)
        where_3 = ops.where(eq_4, constant_18, where_2)
        constant_19 = ops.constant(0.0, torch.float32)
        where_4 = ops.where(eq_3, constant_19, where_3)
        constant_20 = ops.constant(0.0, torch.float32)
        where_5 = ops.where(eq_2, constant_20, where_4)
        constant_21 = ops.constant(0.0, torch.float32)
        where_6 = ops.where(eq_1, constant_21, where_5)
        constant_22 = ops.constant(2.0, torch.float32)
        mul = ops.mul(where_6, constant_22)
        get_index_3 = self.get_index('index0')
        load_2 = ops.load('full_default', get_index_3)
        where_7 = ops.where(eq, mul, load_2)
        add = ops.add(load, where_7)
        get_index_4 = self.get_index('index0')
        store = ops.store('buf30', get_index_4, add, None)
        return store
op30 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[128], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, multi_processor_count=20), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_out_ptr0'], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 0, 'backend_hash': '712B1D69F892A891D8FFA5075DCAB47CFF4E132D88BFC66744701CEAE226F127', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_out_ptr0, in_ptr0, in_ptr1, xnumel, XBLOCK : tl.constexpr):
        xnumel = 100
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp0 = tl.load(in_out_ptr0 + (x0), xmask)
        tmp18 = tl.load(in_ptr0 + (52))
        tmp19 = tl.broadcast_to(tmp18, [XBLOCK])
        tmp30 = tl.load(in_ptr1 + (x0), xmask)
        tmp1 = x0
        tmp2 = tl.full([1], 52, tl.int32)
        tmp3 = tmp1 == tmp2
        tmp4 = tl.full([1], 53, tl.int32)
        tmp5 = tmp2 == tmp4
        tmp6 = tl.full([1], 54, tl.int32)
        tmp7 = tmp2 == tmp6
        tmp8 = tl.full([1], 55, tl.int32)
        tmp9 = tmp2 == tmp8
        tmp10 = tl.full([1], 56, tl.int32)
        tmp11 = tmp2 == tmp10
        tmp12 = tl.full([1], 57, tl.int32)
        tmp13 = tmp2 == tmp12
        tmp14 = tl.full([1], 58, tl.int32)
        tmp15 = tmp2 == tmp14
        tmp16 = tl.full([1], 59, tl.int32)
        tmp17 = tmp2 == tmp16
        tmp20 = 0.0
        tmp21 = tl.where(tmp17, tmp20, tmp19)
        tmp22 = tl.where(tmp15, tmp20, tmp21)
        tmp23 = tl.where(tmp13, tmp20, tmp22)
        tmp24 = tl.where(tmp11, tmp20, tmp23)
        tmp25 = tl.where(tmp9, tmp20, tmp24)
        tmp26 = tl.where(tmp7, tmp20, tmp25)
        tmp27 = tl.where(tmp5, tmp20, tmp26)
        tmp28 = 2.0
        tmp29 = tmp27 * tmp28
        tmp31 = tl.where(tmp3, tmp29, tmp30)
        tmp32 = tmp0 + tmp31
        tl.store(in_out_ptr0 + (x0), tmp32, xmask)


op31: SchedulerNode(ComputedBuffer)
op31.writes = [MemoryDep('buf31', c0, {c0: 100}, None)]
op31.unmet_dependencies = [MemoryDep('buf25', 51, {}, None)]
op31.met_dependencies = [MemoryDep('full_default', c0, {c0: 100}, None)]
op31.outputs = [
    buf31: ComputedBuffer
    buf31.layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
    buf31.users = [NodeUser(node=SchedulerNode(name='op34'), can_inplace=True, is_weak=False)]
]
op31.group.device = cuda:0
op31.group.iteration = (100, 1)
op31.sizes = ([100], [])
buf25_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
full_default_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf31_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
class op31_loop_body:
    var_ranges = {z0: 100}
    index0 = z0
    index1 = 51
    def body(self, ops):
        get_index = self.get_index('index0')
        index_expr = ops.index_expr(get_index, torch.int32)
        constant = ops.constant(51, torch.int32)
        eq = ops.eq(index_expr, constant)
        constant_1 = ops.constant(51, torch.int32)
        constant_2 = ops.constant(52, torch.int32)
        eq_1 = ops.eq(constant_1, constant_2)
        constant_3 = ops.constant(51, torch.int32)
        constant_4 = ops.constant(53, torch.int32)
        eq_2 = ops.eq(constant_3, constant_4)
        constant_5 = ops.constant(51, torch.int32)
        constant_6 = ops.constant(54, torch.int32)
        eq_3 = ops.eq(constant_5, constant_6)
        constant_7 = ops.constant(51, torch.int32)
        constant_8 = ops.constant(55, torch.int32)
        eq_4 = ops.eq(constant_7, constant_8)
        constant_9 = ops.constant(51, torch.int32)
        constant_10 = ops.constant(56, torch.int32)
        eq_5 = ops.eq(constant_9, constant_10)
        constant_11 = ops.constant(51, torch.int32)
        constant_12 = ops.constant(57, torch.int32)
        eq_6 = ops.eq(constant_11, constant_12)
        constant_13 = ops.constant(51, torch.int32)
        constant_14 = ops.constant(58, torch.int32)
        eq_7 = ops.eq(constant_13, constant_14)
        constant_15 = ops.constant(51, torch.int32)
        constant_16 = ops.constant(59, torch.int32)
        eq_8 = ops.eq(constant_15, constant_16)
        get_index_1 = self.get_index('index1')
        load = ops.load('buf25', get_index_1)
        constant_17 = ops.constant(0.0, torch.float32)
        where = ops.where(eq_8, constant_17, load)
        constant_18 = ops.constant(0.0, torch.float32)
        where_1 = ops.where(eq_7, constant_18, where)
        constant_19 = ops.constant(0.0, torch.float32)
        where_2 = ops.where(eq_6, constant_19, where_1)
        constant_20 = ops.constant(0.0, torch.float32)
        where_3 = ops.where(eq_5, constant_20, where_2)
        constant_21 = ops.constant(0.0, torch.float32)
        where_4 = ops.where(eq_4, constant_21, where_3)
        constant_22 = ops.constant(0.0, torch.float32)
        where_5 = ops.where(eq_3, constant_22, where_4)
        constant_23 = ops.constant(0.0, torch.float32)
        where_6 = ops.where(eq_2, constant_23, where_5)
        constant_24 = ops.constant(0.0, torch.float32)
        where_7 = ops.where(eq_1, constant_24, where_6)
        constant_25 = ops.constant(2.0, torch.float32)
        mul = ops.mul(where_7, constant_25)
        get_index_2 = self.get_index('index0')
        load_1 = ops.load('full_default', get_index_2)
        where_8 = ops.where(eq, mul, load_1)
        get_index_3 = self.get_index('index0')
        store = ops.store('buf31', get_index_3, where_8, None)
        return store
op31 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[128], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, multi_processor_count=20), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '712B1D69F892A891D8FFA5075DCAB47CFF4E132D88BFC66744701CEAE226F127', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 100
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp19 = tl.load(in_ptr0 + (51))
        tmp20 = tl.broadcast_to(tmp19, [XBLOCK])
        tmp32 = tl.load(in_ptr1 + (x0), xmask)
        tmp0 = x0
        tmp1 = tl.full([1], 51, tl.int32)
        tmp2 = tmp0 == tmp1
        tmp3 = tl.full([1], 52, tl.int32)
        tmp4 = tmp1 == tmp3
        tmp5 = tl.full([1], 53, tl.int32)
        tmp6 = tmp1 == tmp5
        tmp7 = tl.full([1], 54, tl.int32)
        tmp8 = tmp1 == tmp7
        tmp9 = tl.full([1], 55, tl.int32)
        tmp10 = tmp1 == tmp9
        tmp11 = tl.full([1], 56, tl.int32)
        tmp12 = tmp1 == tmp11
        tmp13 = tl.full([1], 57, tl.int32)
        tmp14 = tmp1 == tmp13
        tmp15 = tl.full([1], 58, tl.int32)
        tmp16 = tmp1 == tmp15
        tmp17 = tl.full([1], 59, tl.int32)
        tmp18 = tmp1 == tmp17
        tmp21 = 0.0
        tmp22 = tl.where(tmp18, tmp21, tmp20)
        tmp23 = tl.where(tmp16, tmp21, tmp22)
        tmp24 = tl.where(tmp14, tmp21, tmp23)
        tmp25 = tl.where(tmp12, tmp21, tmp24)
        tmp26 = tl.where(tmp10, tmp21, tmp25)
        tmp27 = tl.where(tmp8, tmp21, tmp26)
        tmp28 = tl.where(tmp6, tmp21, tmp27)
        tmp29 = tl.where(tmp4, tmp21, tmp28)
        tmp30 = 2.0
        tmp31 = tmp29 * tmp30
        tmp33 = tl.where(tmp2, tmp31, tmp32)
        tl.store(out_ptr0 + (x0), tmp33, xmask)


op32: SchedulerNode(ComputedBuffer)
op32.writes = [MemoryDep('buf32', c0, {c0: 100}, None)]
op32.unmet_dependencies = [MemoryDep('buf25', c0, {c0: 100}, None)]
op32.met_dependencies = []
op32.outputs = [
    buf32: ComputedBuffer
    buf32.layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
    buf32.users = [
        NodeUser(node=SchedulerNode(name='op34'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op35'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op36'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op37'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op38'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op39'), can_inplace=True, is_weak=False),
        NodeUser(node=SchedulerNode(name='op40'), can_inplace=False, is_weak=False),
    ]
]
op32.group.device = cuda:0
op32.group.iteration = (100, 1)
op32.sizes = ([100], [])
buf25_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf32_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
class op32_loop_body:
    var_ranges = {z0: 100}
    index0 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        index_expr = ops.index_expr(get_index, torch.int32)
        constant = ops.constant(50, torch.int32)
        eq = ops.eq(index_expr, constant)
        get_index_1 = self.get_index('index0')
        index_expr_1 = ops.index_expr(get_index_1, torch.int32)
        constant_1 = ops.constant(51, torch.int32)
        eq_1 = ops.eq(index_expr_1, constant_1)
        get_index_2 = self.get_index('index0')
        index_expr_2 = ops.index_expr(get_index_2, torch.int32)
        constant_2 = ops.constant(52, torch.int32)
        eq_2 = ops.eq(index_expr_2, constant_2)
        get_index_3 = self.get_index('index0')
        index_expr_3 = ops.index_expr(get_index_3, torch.int32)
        constant_3 = ops.constant(53, torch.int32)
        eq_3 = ops.eq(index_expr_3, constant_3)
        get_index_4 = self.get_index('index0')
        index_expr_4 = ops.index_expr(get_index_4, torch.int32)
        constant_4 = ops.constant(54, torch.int32)
        eq_4 = ops.eq(index_expr_4, constant_4)
        get_index_5 = self.get_index('index0')
        index_expr_5 = ops.index_expr(get_index_5, torch.int32)
        constant_5 = ops.constant(55, torch.int32)
        eq_5 = ops.eq(index_expr_5, constant_5)
        get_index_6 = self.get_index('index0')
        index_expr_6 = ops.index_expr(get_index_6, torch.int32)
        constant_6 = ops.constant(56, torch.int32)
        eq_6 = ops.eq(index_expr_6, constant_6)
        get_index_7 = self.get_index('index0')
        index_expr_7 = ops.index_expr(get_index_7, torch.int32)
        constant_7 = ops.constant(57, torch.int32)
        eq_7 = ops.eq(index_expr_7, constant_7)
        get_index_8 = self.get_index('index0')
        index_expr_8 = ops.index_expr(get_index_8, torch.int32)
        constant_8 = ops.constant(58, torch.int32)
        eq_8 = ops.eq(index_expr_8, constant_8)
        get_index_9 = self.get_index('index0')
        index_expr_9 = ops.index_expr(get_index_9, torch.int32)
        constant_9 = ops.constant(59, torch.int32)
        eq_9 = ops.eq(index_expr_9, constant_9)
        get_index_10 = self.get_index('index0')
        load = ops.load('buf25', get_index_10)
        constant_10 = ops.constant(0.0, torch.float32)
        where = ops.where(eq_9, constant_10, load)
        constant_11 = ops.constant(0.0, torch.float32)
        where_1 = ops.where(eq_8, constant_11, where)
        constant_12 = ops.constant(0.0, torch.float32)
        where_2 = ops.where(eq_7, constant_12, where_1)
        constant_13 = ops.constant(0.0, torch.float32)
        where_3 = ops.where(eq_6, constant_13, where_2)
        constant_14 = ops.constant(0.0, torch.float32)
        where_4 = ops.where(eq_5, constant_14, where_3)
        constant_15 = ops.constant(0.0, torch.float32)
        where_5 = ops.where(eq_4, constant_15, where_4)
        constant_16 = ops.constant(0.0, torch.float32)
        where_6 = ops.where(eq_3, constant_16, where_5)
        constant_17 = ops.constant(0.0, torch.float32)
        where_7 = ops.where(eq_2, constant_17, where_6)
        constant_18 = ops.constant(0.0, torch.float32)
        where_8 = ops.where(eq_1, constant_18, where_7)
        constant_19 = ops.constant(0.0, torch.float32)
        where_9 = ops.where(eq, constant_19, where_8)
        get_index_11 = self.get_index('index0')
        store = ops.store('buf32', get_index_11, where_9, None)
        return store
op32 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[128], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, multi_processor_count=20), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '712B1D69F892A891D8FFA5075DCAB47CFF4E132D88BFC66744701CEAE226F127', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 100
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp21 = tl.load(in_ptr0 + (x0), xmask)
        tmp0 = x0
        tmp1 = tl.full([1], 50, tl.int32)
        tmp2 = tmp0 == tmp1
        tmp3 = tl.full([1], 51, tl.int32)
        tmp4 = tmp0 == tmp3
        tmp5 = tl.full([1], 52, tl.int32)
        tmp6 = tmp0 == tmp5
        tmp7 = tl.full([1], 53, tl.int32)
        tmp8 = tmp0 == tmp7
        tmp9 = tl.full([1], 54, tl.int32)
        tmp10 = tmp0 == tmp9
        tmp11 = tl.full([1], 55, tl.int32)
        tmp12 = tmp0 == tmp11
        tmp13 = tl.full([1], 56, tl.int32)
        tmp14 = tmp0 == tmp13
        tmp15 = tl.full([1], 57, tl.int32)
        tmp16 = tmp0 == tmp15
        tmp17 = tl.full([1], 58, tl.int32)
        tmp18 = tmp0 == tmp17
        tmp19 = tl.full([1], 59, tl.int32)
        tmp20 = tmp0 == tmp19
        tmp22 = 0.0
        tmp23 = tl.where(tmp20, tmp22, tmp21)
        tmp24 = tl.where(tmp18, tmp22, tmp23)
        tmp25 = tl.where(tmp16, tmp22, tmp24)
        tmp26 = tl.where(tmp14, tmp22, tmp25)
        tmp27 = tl.where(tmp12, tmp22, tmp26)
        tmp28 = tl.where(tmp10, tmp22, tmp27)
        tmp29 = tl.where(tmp8, tmp22, tmp28)
        tmp30 = tl.where(tmp6, tmp22, tmp29)
        tmp31 = tl.where(tmp4, tmp22, tmp30)
        tmp32 = tl.where(tmp2, tmp22, tmp31)
        tl.store(out_ptr0 + (x0), tmp32, xmask)


op33: SchedulerNode(ComputedBuffer)
op33.writes = [MemoryDep('buf33', 0, {}, None)]
op33.unmet_dependencies = [MemoryDep('buf25', 50, {}, None)]
op33.met_dependencies = []
op33.outputs = [
    buf33: ComputedBuffer
    buf33.layout = FixedLayout('cuda', torch.float32, size=[], stride=[])
    buf33.users = [NodeUser(node=SchedulerNode(name='op34'), can_inplace=False, is_weak=False)]
]
op33.group.device = cuda:0
op33.group.iteration = (1, 1)
op33.sizes = ([], [])
buf25_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf33_layout = FixedLayout('cuda', torch.float32, size=[], stride=[])
class op33_loop_body:
    var_ranges = {}
    index0 = 50
    index1 = 0
    def body(self, ops):
        constant = ops.constant(50, torch.int32)
        constant_1 = ops.constant(51, torch.int32)
        eq = ops.eq(constant, constant_1)
        constant_2 = ops.constant(50, torch.int32)
        constant_3 = ops.constant(52, torch.int32)
        eq_1 = ops.eq(constant_2, constant_3)
        constant_4 = ops.constant(50, torch.int32)
        constant_5 = ops.constant(53, torch.int32)
        eq_2 = ops.eq(constant_4, constant_5)
        constant_6 = ops.constant(50, torch.int32)
        constant_7 = ops.constant(54, torch.int32)
        eq_3 = ops.eq(constant_6, constant_7)
        constant_8 = ops.constant(50, torch.int32)
        constant_9 = ops.constant(55, torch.int32)
        eq_4 = ops.eq(constant_8, constant_9)
        constant_10 = ops.constant(50, torch.int32)
        constant_11 = ops.constant(56, torch.int32)
        eq_5 = ops.eq(constant_10, constant_11)
        constant_12 = ops.constant(50, torch.int32)
        constant_13 = ops.constant(57, torch.int32)
        eq_6 = ops.eq(constant_12, constant_13)
        constant_14 = ops.constant(50, torch.int32)
        constant_15 = ops.constant(58, torch.int32)
        eq_7 = ops.eq(constant_14, constant_15)
        constant_16 = ops.constant(50, torch.int32)
        constant_17 = ops.constant(59, torch.int32)
        eq_8 = ops.eq(constant_16, constant_17)
        get_index = self.get_index('index0')
        load = ops.load('buf25', get_index)
        constant_18 = ops.constant(0.0, torch.float32)
        where = ops.where(eq_8, constant_18, load)
        constant_19 = ops.constant(0.0, torch.float32)
        where_1 = ops.where(eq_7, constant_19, where)
        constant_20 = ops.constant(0.0, torch.float32)
        where_2 = ops.where(eq_6, constant_20, where_1)
        constant_21 = ops.constant(0.0, torch.float32)
        where_3 = ops.where(eq_5, constant_21, where_2)
        constant_22 = ops.constant(0.0, torch.float32)
        where_4 = ops.where(eq_4, constant_22, where_3)
        constant_23 = ops.constant(0.0, torch.float32)
        where_5 = ops.where(eq_3, constant_23, where_4)
        constant_24 = ops.constant(0.0, torch.float32)
        where_6 = ops.where(eq_2, constant_24, where_5)
        constant_25 = ops.constant(0.0, torch.float32)
        where_7 = ops.where(eq_1, constant_25, where_6)
        constant_26 = ops.constant(0.0, torch.float32)
        where_8 = ops.where(eq, constant_26, where_7)
        constant_27 = ops.constant(2.0, torch.float32)
        mul = ops.mul(where_8, constant_27)
        get_index_1 = self.get_index('index1')
        store = ops.store('buf33', get_index_1, mul, None)
        return store
op33 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[1], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, multi_processor_count=20), 'constants': {2: 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(2,))]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '712B1D69F892A891D8FFA5075DCAB47CFF4E132D88BFC66744701CEAE226F127', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 1
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = tl.full([XBLOCK], True, tl.int1)
        tmp19 = tl.load(in_ptr0 + (50))
        tmp20 = tl.broadcast_to(tmp19, [XBLOCK])
        tmp0 = tl.full([1], 50, tl.int32)
        tmp1 = tl.full([1], 51, tl.int32)
        tmp2 = tmp0 == tmp1
        tmp3 = tl.full([1], 52, tl.int32)
        tmp4 = tmp0 == tmp3
        tmp5 = tl.full([1], 53, tl.int32)
        tmp6 = tmp0 == tmp5
        tmp7 = tl.full([1], 54, tl.int32)
        tmp8 = tmp0 == tmp7
        tmp9 = tl.full([1], 55, tl.int32)
        tmp10 = tmp0 == tmp9
        tmp11 = tl.full([1], 56, tl.int32)
        tmp12 = tmp0 == tmp11
        tmp13 = tl.full([1], 57, tl.int32)
        tmp14 = tmp0 == tmp13
        tmp15 = tl.full([1], 58, tl.int32)
        tmp16 = tmp0 == tmp15
        tmp17 = tl.full([1], 59, tl.int32)
        tmp18 = tmp0 == tmp17
        tmp21 = 0.0
        tmp22 = tl.where(tmp18, tmp21, tmp20)
        tmp23 = tl.where(tmp16, tmp21, tmp22)
        tmp24 = tl.where(tmp14, tmp21, tmp23)
        tmp25 = tl.where(tmp12, tmp21, tmp24)
        tmp26 = tl.where(tmp10, tmp21, tmp25)
        tmp27 = tl.where(tmp8, tmp21, tmp26)
        tmp28 = tl.where(tmp6, tmp21, tmp27)
        tmp29 = tl.where(tmp4, tmp21, tmp28)
        tmp30 = tl.where(tmp2, tmp21, tmp29)
        tmp31 = 2.0
        tmp32 = tmp30 * tmp31
        tl.store(out_ptr0 + (tl.full([XBLOCK], 0, tl.int32)), tmp32, None)


op34: SchedulerNode(ComputedBuffer)
op34.writes = [MemoryDep('buf34', c0, {c0: 100}, None)]
op34.unmet_dependencies = 
    [   MemoryDep('buf30', c0, {c0: 100}, None),
        MemoryDep('buf31', c0, {c0: 100}, None),
        MemoryDep('buf32', 47, {}, None),
        MemoryDep('buf32', 48, {}, None),
        MemoryDep('buf32', 49, {}, None),
        MemoryDep('buf33', 0, {}, None)]
op34.met_dependencies = [MemoryDep('full_default', c0, {c0: 100}, None)]
op34.outputs = [
    buf34: ComputedBuffer
    buf34.layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
    buf34.users = [NodeUser(node=SchedulerNode(name='op35'), can_inplace=True, is_weak=False)]
]
op34.group.device = cuda:0
op34.group.iteration = (100, 1)
op34.sizes = ([100], [])
buf30_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf31_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf33_layout = FixedLayout('cuda', torch.float32, size=[], stride=[])
full_default_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf32_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf32_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf32_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf34_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
class op34_loop_body:
    var_ranges = {z0: 100}
    index0 = z0
    index1 = 0
    index2 = 49
    index3 = 48
    index4 = 47
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf30', get_index)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('buf31', get_index_1)
        add = ops.add(load, load_1)
        get_index_2 = self.get_index('index0')
        index_expr = ops.index_expr(get_index_2, torch.int32)
        constant = ops.constant(50, torch.int32)
        eq = ops.eq(index_expr, constant)
        get_index_3 = self.get_index('index1')
        load_2 = ops.load('buf33', get_index_3)
        get_index_4 = self.get_index('index0')
        load_3 = ops.load('full_default', get_index_4)
        where = ops.where(eq, load_2, load_3)
        add_1 = ops.add(add, where)
        get_index_5 = self.get_index('index0')
        index_expr_1 = ops.index_expr(get_index_5, torch.int32)
        constant_1 = ops.constant(49, torch.int32)
        eq_1 = ops.eq(index_expr_1, constant_1)
        get_index_6 = self.get_index('index2')
        load_4 = ops.load('buf32', get_index_6)
        constant_2 = ops.constant(2.0, torch.float32)
        mul = ops.mul(load_4, constant_2)
        get_index_7 = self.get_index('index0')
        load_5 = ops.load('full_default', get_index_7)
        where_1 = ops.where(eq_1, mul, load_5)
        add_2 = ops.add(add_1, where_1)
        get_index_8 = self.get_index('index0')
        index_expr_2 = ops.index_expr(get_index_8, torch.int32)
        constant_3 = ops.constant(48, torch.int32)
        eq_2 = ops.eq(index_expr_2, constant_3)
        constant_4 = ops.constant(48, torch.int32)
        constant_5 = ops.constant(49, torch.int32)
        eq_3 = ops.eq(constant_4, constant_5)
        get_index_9 = self.get_index('index3')
        load_6 = ops.load('buf32', get_index_9)
        constant_6 = ops.constant(0.0, torch.float32)
        where_2 = ops.where(eq_3, constant_6, load_6)
        constant_7 = ops.constant(2.0, torch.float32)
        mul_1 = ops.mul(where_2, constant_7)
        get_index_10 = self.get_index('index0')
        load_7 = ops.load('full_default', get_index_10)
        where_3 = ops.where(eq_2, mul_1, load_7)
        add_3 = ops.add(add_2, where_3)
        get_index_11 = self.get_index('index0')
        index_expr_3 = ops.index_expr(get_index_11, torch.int32)
        constant_8 = ops.constant(47, torch.int32)
        eq_4 = ops.eq(index_expr_3, constant_8)
        constant_9 = ops.constant(47, torch.int32)
        constant_10 = ops.constant(48, torch.int32)
        eq_5 = ops.eq(constant_9, constant_10)
        constant_11 = ops.constant(47, torch.int32)
        constant_12 = ops.constant(49, torch.int32)
        eq_6 = ops.eq(constant_11, constant_12)
        get_index_12 = self.get_index('index4')
        load_8 = ops.load('buf32', get_index_12)
        constant_13 = ops.constant(0.0, torch.float32)
        where_4 = ops.where(eq_6, constant_13, load_8)
        constant_14 = ops.constant(0.0, torch.float32)
        where_5 = ops.where(eq_5, constant_14, where_4)
        constant_15 = ops.constant(2.0, torch.float32)
        mul_2 = ops.mul(where_5, constant_15)
        get_index_13 = self.get_index('index0')
        load_9 = ops.load('full_default', get_index_13)
        where_6 = ops.where(eq_4, mul_2, load_9)
        add_4 = ops.add(add_3, where_6)
        get_index_14 = self.get_index('index0')
        store = ops.store('buf34', get_index_14, add_4, None)
        return store
op34 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[128], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, multi_processor_count=20), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_out_ptr0'], 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': '712B1D69F892A891D8FFA5075DCAB47CFF4E132D88BFC66744701CEAE226F127', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, xnumel, XBLOCK : tl.constexpr):
        xnumel = 100
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp0 = tl.load(in_out_ptr0 + (x0), xmask)
        tmp1 = tl.load(in_ptr0 + (x0), xmask)
        tmp6 = tl.load(in_ptr1 + (0))
        tmp7 = tl.broadcast_to(tmp6, [XBLOCK])
        tmp8 = tl.load(in_ptr2 + (x0), xmask)
        tmp13 = tl.load(in_ptr3 + (49))
        tmp14 = tl.broadcast_to(tmp13, [XBLOCK])
        tmp22 = tl.load(in_ptr3 + (48))
        tmp23 = tl.broadcast_to(tmp22, [XBLOCK])
        tmp33 = tl.load(in_ptr3 + (47))
        tmp34 = tl.broadcast_to(tmp33, [XBLOCK])
        tmp2 = tmp0 + tmp1
        tmp3 = x0
        tmp4 = tl.full([1], 50, tl.int32)
        tmp5 = tmp3 == tmp4
        tmp9 = tl.where(tmp5, tmp7, tmp8)
        tmp10 = tmp2 + tmp9
        tmp11 = tl.full([1], 49, tl.int32)
        tmp12 = tmp3 == tmp11
        tmp15 = 2.0
        tmp16 = tmp14 * tmp15
        tmp17 = tl.where(tmp12, tmp16, tmp8)
        tmp18 = tmp10 + tmp17
        tmp19 = tl.full([1], 48, tl.int32)
        tmp20 = tmp3 == tmp19
        tmp21 = tmp19 == tmp11
        tmp24 = 0.0
        tmp25 = tl.where(tmp21, tmp24, tmp23)
        tmp26 = tmp25 * tmp15
        tmp27 = tl.where(tmp20, tmp26, tmp8)
        tmp28 = tmp18 + tmp27
        tmp29 = tl.full([1], 47, tl.int32)
        tmp30 = tmp3 == tmp29
        tmp31 = tmp29 == tmp19
        tmp32 = tmp29 == tmp11
        tmp35 = tl.where(tmp32, tmp24, tmp34)
        tmp36 = tl.where(tmp31, tmp24, tmp35)
        tmp37 = tmp36 * tmp15
        tmp38 = tl.where(tmp30, tmp37, tmp8)
        tmp39 = tmp28 + tmp38
        tl.store(in_out_ptr0 + (x0), tmp39, xmask)


op35: SchedulerNode(ComputedBuffer)
op35.writes = [MemoryDep('buf35', c0, {c0: 100}, None)]
op35.unmet_dependencies = 
    [   MemoryDep('buf32', 45, {}, None),
        MemoryDep('buf32', 46, {}, None),
        MemoryDep('buf34', c0, {c0: 100}, None)]
op35.met_dependencies = [MemoryDep('full_default', c0, {c0: 100}, None)]
op35.outputs = [
    buf35: ComputedBuffer
    buf35.layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
    buf35.users = [NodeUser(node=SchedulerNode(name='op36'), can_inplace=True, is_weak=False)]
]
op35.group.device = cuda:0
op35.group.iteration = (100, 1)
op35.sizes = ([100], [])
buf34_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf32_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
full_default_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf32_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf35_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
class op35_loop_body:
    var_ranges = {z0: 100}
    index0 = z0
    index1 = 46
    index2 = 45
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf34', get_index)
        get_index_1 = self.get_index('index0')
        index_expr = ops.index_expr(get_index_1, torch.int32)
        constant = ops.constant(46, torch.int32)
        eq = ops.eq(index_expr, constant)
        constant_1 = ops.constant(46, torch.int32)
        constant_2 = ops.constant(47, torch.int32)
        eq_1 = ops.eq(constant_1, constant_2)
        constant_3 = ops.constant(46, torch.int32)
        constant_4 = ops.constant(48, torch.int32)
        eq_2 = ops.eq(constant_3, constant_4)
        constant_5 = ops.constant(46, torch.int32)
        constant_6 = ops.constant(49, torch.int32)
        eq_3 = ops.eq(constant_5, constant_6)
        get_index_2 = self.get_index('index1')
        load_1 = ops.load('buf32', get_index_2)
        constant_7 = ops.constant(0.0, torch.float32)
        where = ops.where(eq_3, constant_7, load_1)
        constant_8 = ops.constant(0.0, torch.float32)
        where_1 = ops.where(eq_2, constant_8, where)
        constant_9 = ops.constant(0.0, torch.float32)
        where_2 = ops.where(eq_1, constant_9, where_1)
        constant_10 = ops.constant(2.0, torch.float32)
        mul = ops.mul(where_2, constant_10)
        get_index_3 = self.get_index('index0')
        load_2 = ops.load('full_default', get_index_3)
        where_3 = ops.where(eq, mul, load_2)
        add = ops.add(load, where_3)
        get_index_4 = self.get_index('index0')
        index_expr_1 = ops.index_expr(get_index_4, torch.int32)
        constant_11 = ops.constant(45, torch.int32)
        eq_4 = ops.eq(index_expr_1, constant_11)
        constant_12 = ops.constant(45, torch.int32)
        constant_13 = ops.constant(46, torch.int32)
        eq_5 = ops.eq(constant_12, constant_13)
        constant_14 = ops.constant(45, torch.int32)
        constant_15 = ops.constant(47, torch.int32)
        eq_6 = ops.eq(constant_14, constant_15)
        constant_16 = ops.constant(45, torch.int32)
        constant_17 = ops.constant(48, torch.int32)
        eq_7 = ops.eq(constant_16, constant_17)
        constant_18 = ops.constant(45, torch.int32)
        constant_19 = ops.constant(49, torch.int32)
        eq_8 = ops.eq(constant_18, constant_19)
        get_index_5 = self.get_index('index2')
        load_3 = ops.load('buf32', get_index_5)
        constant_20 = ops.constant(0.0, torch.float32)
        where_4 = ops.where(eq_8, constant_20, load_3)
        constant_21 = ops.constant(0.0, torch.float32)
        where_5 = ops.where(eq_7, constant_21, where_4)
        constant_22 = ops.constant(0.0, torch.float32)
        where_6 = ops.where(eq_6, constant_22, where_5)
        constant_23 = ops.constant(0.0, torch.float32)
        where_7 = ops.where(eq_5, constant_23, where_6)
        constant_24 = ops.constant(2.0, torch.float32)
        mul_1 = ops.mul(where_7, constant_24)
        get_index_6 = self.get_index('index0')
        load_4 = ops.load('full_default', get_index_6)
        where_8 = ops.where(eq_4, mul_1, load_4)
        add_1 = ops.add(add, where_8)
        get_index_7 = self.get_index('index0')
        store = ops.store('buf35', get_index_7, add_1, None)
        return store
op35 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[128], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, multi_processor_count=20), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_out_ptr0'], 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': '712B1D69F892A891D8FFA5075DCAB47CFF4E132D88BFC66744701CEAE226F127', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_out_ptr0, in_ptr0, in_ptr1, xnumel, XBLOCK : tl.constexpr):
        xnumel = 100
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp0 = tl.load(in_out_ptr0 + (x0), xmask)
        tmp10 = tl.load(in_ptr0 + (46))
        tmp11 = tl.broadcast_to(tmp10, [XBLOCK])
        tmp18 = tl.load(in_ptr1 + (x0), xmask)
        tmp27 = tl.load(in_ptr0 + (45))
        tmp28 = tl.broadcast_to(tmp27, [XBLOCK])
        tmp1 = x0
        tmp2 = tl.full([1], 46, tl.int32)
        tmp3 = tmp1 == tmp2
        tmp4 = tl.full([1], 47, tl.int32)
        tmp5 = tmp2 == tmp4
        tmp6 = tl.full([1], 48, tl.int32)
        tmp7 = tmp2 == tmp6
        tmp8 = tl.full([1], 49, tl.int32)
        tmp9 = tmp2 == tmp8
        tmp12 = 0.0
        tmp13 = tl.where(tmp9, tmp12, tmp11)
        tmp14 = tl.where(tmp7, tmp12, tmp13)
        tmp15 = tl.where(tmp5, tmp12, tmp14)
        tmp16 = 2.0
        tmp17 = tmp15 * tmp16
        tmp19 = tl.where(tmp3, tmp17, tmp18)
        tmp20 = tmp0 + tmp19
        tmp21 = tl.full([1], 45, tl.int32)
        tmp22 = tmp1 == tmp21
        tmp23 = tmp21 == tmp2
        tmp24 = tmp21 == tmp4
        tmp25 = tmp21 == tmp6
        tmp26 = tmp21 == tmp8
        tmp29 = tl.where(tmp26, tmp12, tmp28)
        tmp30 = tl.where(tmp25, tmp12, tmp29)
        tmp31 = tl.where(tmp24, tmp12, tmp30)
        tmp32 = tl.where(tmp23, tmp12, tmp31)
        tmp33 = tmp32 * tmp16
        tmp34 = tl.where(tmp22, tmp33, tmp18)
        tmp35 = tmp20 + tmp34
        tl.store(in_out_ptr0 + (x0), tmp35, xmask)


op36: SchedulerNode(ComputedBuffer)
op36.writes = [MemoryDep('buf36', c0, {c0: 100}, None)]
op36.unmet_dependencies = 
    [   MemoryDep('buf32', 43, {}, None),
        MemoryDep('buf32', 44, {}, None),
        MemoryDep('buf35', c0, {c0: 100}, None)]
op36.met_dependencies = [MemoryDep('full_default', c0, {c0: 100}, None)]
op36.outputs = [
    buf36: ComputedBuffer
    buf36.layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
    buf36.users = [NodeUser(node=SchedulerNode(name='op37'), can_inplace=True, is_weak=False)]
]
op36.group.device = cuda:0
op36.group.iteration = (100, 1)
op36.sizes = ([100], [])
buf35_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf32_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
full_default_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf32_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf36_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
class op36_loop_body:
    var_ranges = {z0: 100}
    index0 = z0
    index1 = 44
    index2 = 43
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf35', get_index)
        get_index_1 = self.get_index('index0')
        index_expr = ops.index_expr(get_index_1, torch.int32)
        constant = ops.constant(44, torch.int32)
        eq = ops.eq(index_expr, constant)
        constant_1 = ops.constant(44, torch.int32)
        constant_2 = ops.constant(45, torch.int32)
        eq_1 = ops.eq(constant_1, constant_2)
        constant_3 = ops.constant(44, torch.int32)
        constant_4 = ops.constant(46, torch.int32)
        eq_2 = ops.eq(constant_3, constant_4)
        constant_5 = ops.constant(44, torch.int32)
        constant_6 = ops.constant(47, torch.int32)
        eq_3 = ops.eq(constant_5, constant_6)
        constant_7 = ops.constant(44, torch.int32)
        constant_8 = ops.constant(48, torch.int32)
        eq_4 = ops.eq(constant_7, constant_8)
        constant_9 = ops.constant(44, torch.int32)
        constant_10 = ops.constant(49, torch.int32)
        eq_5 = ops.eq(constant_9, constant_10)
        get_index_2 = self.get_index('index1')
        load_1 = ops.load('buf32', get_index_2)
        constant_11 = ops.constant(0.0, torch.float32)
        where = ops.where(eq_5, constant_11, load_1)
        constant_12 = ops.constant(0.0, torch.float32)
        where_1 = ops.where(eq_4, constant_12, where)
        constant_13 = ops.constant(0.0, torch.float32)
        where_2 = ops.where(eq_3, constant_13, where_1)
        constant_14 = ops.constant(0.0, torch.float32)
        where_3 = ops.where(eq_2, constant_14, where_2)
        constant_15 = ops.constant(0.0, torch.float32)
        where_4 = ops.where(eq_1, constant_15, where_3)
        constant_16 = ops.constant(2.0, torch.float32)
        mul = ops.mul(where_4, constant_16)
        get_index_3 = self.get_index('index0')
        load_2 = ops.load('full_default', get_index_3)
        where_5 = ops.where(eq, mul, load_2)
        add = ops.add(load, where_5)
        get_index_4 = self.get_index('index0')
        index_expr_1 = ops.index_expr(get_index_4, torch.int32)
        constant_17 = ops.constant(43, torch.int32)
        eq_6 = ops.eq(index_expr_1, constant_17)
        constant_18 = ops.constant(43, torch.int32)
        constant_19 = ops.constant(44, torch.int32)
        eq_7 = ops.eq(constant_18, constant_19)
        constant_20 = ops.constant(43, torch.int32)
        constant_21 = ops.constant(45, torch.int32)
        eq_8 = ops.eq(constant_20, constant_21)
        constant_22 = ops.constant(43, torch.int32)
        constant_23 = ops.constant(46, torch.int32)
        eq_9 = ops.eq(constant_22, constant_23)
        constant_24 = ops.constant(43, torch.int32)
        constant_25 = ops.constant(47, torch.int32)
        eq_10 = ops.eq(constant_24, constant_25)
        constant_26 = ops.constant(43, torch.int32)
        constant_27 = ops.constant(48, torch.int32)
        eq_11 = ops.eq(constant_26, constant_27)
        constant_28 = ops.constant(43, torch.int32)
        constant_29 = ops.constant(49, torch.int32)
        eq_12 = ops.eq(constant_28, constant_29)
        get_index_5 = self.get_index('index2')
        load_3 = ops.load('buf32', get_index_5)
        constant_30 = ops.constant(0.0, torch.float32)
        where_6 = ops.where(eq_12, constant_30, load_3)
        constant_31 = ops.constant(0.0, torch.float32)
        where_7 = ops.where(eq_11, constant_31, where_6)
        constant_32 = ops.constant(0.0, torch.float32)
        where_8 = ops.where(eq_10, constant_32, where_7)
        constant_33 = ops.constant(0.0, torch.float32)
        where_9 = ops.where(eq_9, constant_33, where_8)
        constant_34 = ops.constant(0.0, torch.float32)
        where_10 = ops.where(eq_8, constant_34, where_9)
        constant_35 = ops.constant(0.0, torch.float32)
        where_11 = ops.where(eq_7, constant_35, where_10)
        constant_36 = ops.constant(2.0, torch.float32)
        mul_1 = ops.mul(where_11, constant_36)
        get_index_6 = self.get_index('index0')
        load_4 = ops.load('full_default', get_index_6)
        where_12 = ops.where(eq_6, mul_1, load_4)
        add_1 = ops.add(add, where_12)
        get_index_7 = self.get_index('index0')
        store = ops.store('buf36', get_index_7, add_1, None)
        return store
op36 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[128], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, multi_processor_count=20), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_out_ptr0'], 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': '712B1D69F892A891D8FFA5075DCAB47CFF4E132D88BFC66744701CEAE226F127', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_out_ptr0, in_ptr0, in_ptr1, xnumel, XBLOCK : tl.constexpr):
        xnumel = 100
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp0 = tl.load(in_out_ptr0 + (x0), xmask)
        tmp14 = tl.load(in_ptr0 + (44))
        tmp15 = tl.broadcast_to(tmp14, [XBLOCK])
        tmp24 = tl.load(in_ptr1 + (x0), xmask)
        tmp35 = tl.load(in_ptr0 + (43))
        tmp36 = tl.broadcast_to(tmp35, [XBLOCK])
        tmp1 = x0
        tmp2 = tl.full([1], 44, tl.int32)
        tmp3 = tmp1 == tmp2
        tmp4 = tl.full([1], 45, tl.int32)
        tmp5 = tmp2 == tmp4
        tmp6 = tl.full([1], 46, tl.int32)
        tmp7 = tmp2 == tmp6
        tmp8 = tl.full([1], 47, tl.int32)
        tmp9 = tmp2 == tmp8
        tmp10 = tl.full([1], 48, tl.int32)
        tmp11 = tmp2 == tmp10
        tmp12 = tl.full([1], 49, tl.int32)
        tmp13 = tmp2 == tmp12
        tmp16 = 0.0
        tmp17 = tl.where(tmp13, tmp16, tmp15)
        tmp18 = tl.where(tmp11, tmp16, tmp17)
        tmp19 = tl.where(tmp9, tmp16, tmp18)
        tmp20 = tl.where(tmp7, tmp16, tmp19)
        tmp21 = tl.where(tmp5, tmp16, tmp20)
        tmp22 = 2.0
        tmp23 = tmp21 * tmp22
        tmp25 = tl.where(tmp3, tmp23, tmp24)
        tmp26 = tmp0 + tmp25
        tmp27 = tl.full([1], 43, tl.int32)
        tmp28 = tmp1 == tmp27
        tmp29 = tmp27 == tmp2
        tmp30 = tmp27 == tmp4
        tmp31 = tmp27 == tmp6
        tmp32 = tmp27 == tmp8
        tmp33 = tmp27 == tmp10
        tmp34 = tmp27 == tmp12
        tmp37 = tl.where(tmp34, tmp16, tmp36)
        tmp38 = tl.where(tmp33, tmp16, tmp37)
        tmp39 = tl.where(tmp32, tmp16, tmp38)
        tmp40 = tl.where(tmp31, tmp16, tmp39)
        tmp41 = tl.where(tmp30, tmp16, tmp40)
        tmp42 = tl.where(tmp29, tmp16, tmp41)
        tmp43 = tmp42 * tmp22
        tmp44 = tl.where(tmp28, tmp43, tmp24)
        tmp45 = tmp26 + tmp44
        tl.store(in_out_ptr0 + (x0), tmp45, xmask)


op37: SchedulerNode(ComputedBuffer)
op37.writes = [MemoryDep('buf37', c0, {c0: 100}, None)]
op37.unmet_dependencies = [MemoryDep('buf32', 42, {}, None), MemoryDep('buf36', c0, {c0: 100}, None)]
op37.met_dependencies = [MemoryDep('full_default', c0, {c0: 100}, None)]
op37.outputs = [
    buf37: ComputedBuffer
    buf37.layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
    buf37.users = [NodeUser(node=SchedulerNode(name='op41'), can_inplace=True, is_weak=False)]
]
op37.group.device = cuda:0
op37.group.iteration = (100, 1)
op37.sizes = ([100], [])
buf36_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf32_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
full_default_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf37_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
class op37_loop_body:
    var_ranges = {z0: 100}
    index0 = z0
    index1 = 42
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf36', get_index)
        get_index_1 = self.get_index('index0')
        index_expr = ops.index_expr(get_index_1, torch.int32)
        constant = ops.constant(42, torch.int32)
        eq = ops.eq(index_expr, constant)
        constant_1 = ops.constant(42, torch.int32)
        constant_2 = ops.constant(43, torch.int32)
        eq_1 = ops.eq(constant_1, constant_2)
        constant_3 = ops.constant(42, torch.int32)
        constant_4 = ops.constant(44, torch.int32)
        eq_2 = ops.eq(constant_3, constant_4)
        constant_5 = ops.constant(42, torch.int32)
        constant_6 = ops.constant(45, torch.int32)
        eq_3 = ops.eq(constant_5, constant_6)
        constant_7 = ops.constant(42, torch.int32)
        constant_8 = ops.constant(46, torch.int32)
        eq_4 = ops.eq(constant_7, constant_8)
        constant_9 = ops.constant(42, torch.int32)
        constant_10 = ops.constant(47, torch.int32)
        eq_5 = ops.eq(constant_9, constant_10)
        constant_11 = ops.constant(42, torch.int32)
        constant_12 = ops.constant(48, torch.int32)
        eq_6 = ops.eq(constant_11, constant_12)
        constant_13 = ops.constant(42, torch.int32)
        constant_14 = ops.constant(49, torch.int32)
        eq_7 = ops.eq(constant_13, constant_14)
        get_index_2 = self.get_index('index1')
        load_1 = ops.load('buf32', get_index_2)
        constant_15 = ops.constant(0.0, torch.float32)
        where = ops.where(eq_7, constant_15, load_1)
        constant_16 = ops.constant(0.0, torch.float32)
        where_1 = ops.where(eq_6, constant_16, where)
        constant_17 = ops.constant(0.0, torch.float32)
        where_2 = ops.where(eq_5, constant_17, where_1)
        constant_18 = ops.constant(0.0, torch.float32)
        where_3 = ops.where(eq_4, constant_18, where_2)
        constant_19 = ops.constant(0.0, torch.float32)
        where_4 = ops.where(eq_3, constant_19, where_3)
        constant_20 = ops.constant(0.0, torch.float32)
        where_5 = ops.where(eq_2, constant_20, where_4)
        constant_21 = ops.constant(0.0, torch.float32)
        where_6 = ops.where(eq_1, constant_21, where_5)
        constant_22 = ops.constant(2.0, torch.float32)
        mul = ops.mul(where_6, constant_22)
        get_index_3 = self.get_index('index0')
        load_2 = ops.load('full_default', get_index_3)
        where_7 = ops.where(eq, mul, load_2)
        add = ops.add(load, where_7)
        get_index_4 = self.get_index('index0')
        store = ops.store('buf37', get_index_4, add, None)
        return store
op37 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[128], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, multi_processor_count=20), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_out_ptr0'], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 0, 'backend_hash': '712B1D69F892A891D8FFA5075DCAB47CFF4E132D88BFC66744701CEAE226F127', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_out_ptr0, in_ptr0, in_ptr1, xnumel, XBLOCK : tl.constexpr):
        xnumel = 100
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp0 = tl.load(in_out_ptr0 + (x0), xmask)
        tmp18 = tl.load(in_ptr0 + (42))
        tmp19 = tl.broadcast_to(tmp18, [XBLOCK])
        tmp30 = tl.load(in_ptr1 + (x0), xmask)
        tmp1 = x0
        tmp2 = tl.full([1], 42, tl.int32)
        tmp3 = tmp1 == tmp2
        tmp4 = tl.full([1], 43, tl.int32)
        tmp5 = tmp2 == tmp4
        tmp6 = tl.full([1], 44, tl.int32)
        tmp7 = tmp2 == tmp6
        tmp8 = tl.full([1], 45, tl.int32)
        tmp9 = tmp2 == tmp8
        tmp10 = tl.full([1], 46, tl.int32)
        tmp11 = tmp2 == tmp10
        tmp12 = tl.full([1], 47, tl.int32)
        tmp13 = tmp2 == tmp12
        tmp14 = tl.full([1], 48, tl.int32)
        tmp15 = tmp2 == tmp14
        tmp16 = tl.full([1], 49, tl.int32)
        tmp17 = tmp2 == tmp16
        tmp20 = 0.0
        tmp21 = tl.where(tmp17, tmp20, tmp19)
        tmp22 = tl.where(tmp15, tmp20, tmp21)
        tmp23 = tl.where(tmp13, tmp20, tmp22)
        tmp24 = tl.where(tmp11, tmp20, tmp23)
        tmp25 = tl.where(tmp9, tmp20, tmp24)
        tmp26 = tl.where(tmp7, tmp20, tmp25)
        tmp27 = tl.where(tmp5, tmp20, tmp26)
        tmp28 = 2.0
        tmp29 = tmp27 * tmp28
        tmp31 = tl.where(tmp3, tmp29, tmp30)
        tmp32 = tmp0 + tmp31
        tl.store(in_out_ptr0 + (x0), tmp32, xmask)


op38: SchedulerNode(ComputedBuffer)
op38.writes = [MemoryDep('buf38', c0, {c0: 100}, None)]
op38.unmet_dependencies = [MemoryDep('buf32', 41, {}, None)]
op38.met_dependencies = [MemoryDep('full_default', c0, {c0: 100}, None)]
op38.outputs = [
    buf38: ComputedBuffer
    buf38.layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
    buf38.users = [NodeUser(node=SchedulerNode(name='op41'), can_inplace=True, is_weak=False)]
]
op38.group.device = cuda:0
op38.group.iteration = (100, 1)
op38.sizes = ([100], [])
buf32_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
full_default_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf38_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
class op38_loop_body:
    var_ranges = {z0: 100}
    index0 = z0
    index1 = 41
    def body(self, ops):
        get_index = self.get_index('index0')
        index_expr = ops.index_expr(get_index, torch.int32)
        constant = ops.constant(41, torch.int32)
        eq = ops.eq(index_expr, constant)
        constant_1 = ops.constant(41, torch.int32)
        constant_2 = ops.constant(42, torch.int32)
        eq_1 = ops.eq(constant_1, constant_2)
        constant_3 = ops.constant(41, torch.int32)
        constant_4 = ops.constant(43, torch.int32)
        eq_2 = ops.eq(constant_3, constant_4)
        constant_5 = ops.constant(41, torch.int32)
        constant_6 = ops.constant(44, torch.int32)
        eq_3 = ops.eq(constant_5, constant_6)
        constant_7 = ops.constant(41, torch.int32)
        constant_8 = ops.constant(45, torch.int32)
        eq_4 = ops.eq(constant_7, constant_8)
        constant_9 = ops.constant(41, torch.int32)
        constant_10 = ops.constant(46, torch.int32)
        eq_5 = ops.eq(constant_9, constant_10)
        constant_11 = ops.constant(41, torch.int32)
        constant_12 = ops.constant(47, torch.int32)
        eq_6 = ops.eq(constant_11, constant_12)
        constant_13 = ops.constant(41, torch.int32)
        constant_14 = ops.constant(48, torch.int32)
        eq_7 = ops.eq(constant_13, constant_14)
        constant_15 = ops.constant(41, torch.int32)
        constant_16 = ops.constant(49, torch.int32)
        eq_8 = ops.eq(constant_15, constant_16)
        get_index_1 = self.get_index('index1')
        load = ops.load('buf32', get_index_1)
        constant_17 = ops.constant(0.0, torch.float32)
        where = ops.where(eq_8, constant_17, load)
        constant_18 = ops.constant(0.0, torch.float32)
        where_1 = ops.where(eq_7, constant_18, where)
        constant_19 = ops.constant(0.0, torch.float32)
        where_2 = ops.where(eq_6, constant_19, where_1)
        constant_20 = ops.constant(0.0, torch.float32)
        where_3 = ops.where(eq_5, constant_20, where_2)
        constant_21 = ops.constant(0.0, torch.float32)
        where_4 = ops.where(eq_4, constant_21, where_3)
        constant_22 = ops.constant(0.0, torch.float32)
        where_5 = ops.where(eq_3, constant_22, where_4)
        constant_23 = ops.constant(0.0, torch.float32)
        where_6 = ops.where(eq_2, constant_23, where_5)
        constant_24 = ops.constant(0.0, torch.float32)
        where_7 = ops.where(eq_1, constant_24, where_6)
        constant_25 = ops.constant(2.0, torch.float32)
        mul = ops.mul(where_7, constant_25)
        get_index_2 = self.get_index('index0')
        load_1 = ops.load('full_default', get_index_2)
        where_8 = ops.where(eq, mul, load_1)
        get_index_3 = self.get_index('index0')
        store = ops.store('buf38', get_index_3, where_8, None)
        return store
op38 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[128], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, multi_processor_count=20), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '712B1D69F892A891D8FFA5075DCAB47CFF4E132D88BFC66744701CEAE226F127', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 100
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp19 = tl.load(in_ptr0 + (41))
        tmp20 = tl.broadcast_to(tmp19, [XBLOCK])
        tmp32 = tl.load(in_ptr1 + (x0), xmask)
        tmp0 = x0
        tmp1 = tl.full([1], 41, tl.int32)
        tmp2 = tmp0 == tmp1
        tmp3 = tl.full([1], 42, tl.int32)
        tmp4 = tmp1 == tmp3
        tmp5 = tl.full([1], 43, tl.int32)
        tmp6 = tmp1 == tmp5
        tmp7 = tl.full([1], 44, tl.int32)
        tmp8 = tmp1 == tmp7
        tmp9 = tl.full([1], 45, tl.int32)
        tmp10 = tmp1 == tmp9
        tmp11 = tl.full([1], 46, tl.int32)
        tmp12 = tmp1 == tmp11
        tmp13 = tl.full([1], 47, tl.int32)
        tmp14 = tmp1 == tmp13
        tmp15 = tl.full([1], 48, tl.int32)
        tmp16 = tmp1 == tmp15
        tmp17 = tl.full([1], 49, tl.int32)
        tmp18 = tmp1 == tmp17
        tmp21 = 0.0
        tmp22 = tl.where(tmp18, tmp21, tmp20)
        tmp23 = tl.where(tmp16, tmp21, tmp22)
        tmp24 = tl.where(tmp14, tmp21, tmp23)
        tmp25 = tl.where(tmp12, tmp21, tmp24)
        tmp26 = tl.where(tmp10, tmp21, tmp25)
        tmp27 = tl.where(tmp8, tmp21, tmp26)
        tmp28 = tl.where(tmp6, tmp21, tmp27)
        tmp29 = tl.where(tmp4, tmp21, tmp28)
        tmp30 = 2.0
        tmp31 = tmp29 * tmp30
        tmp33 = tl.where(tmp2, tmp31, tmp32)
        tl.store(out_ptr0 + (x0), tmp33, xmask)


op39: SchedulerNode(ComputedBuffer)
op39.writes = [MemoryDep('buf39', c0, {c0: 100}, None)]
op39.unmet_dependencies = [MemoryDep('buf32', c0, {c0: 100}, None)]
op39.met_dependencies = []
op39.outputs = [
    buf39: ComputedBuffer
    buf39.layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
    buf39.users = [
        NodeUser(node=SchedulerNode(name='op41'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op42'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op43'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op44'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op45'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op46'), can_inplace=True, is_weak=False),
        NodeUser(node=SchedulerNode(name='op47'), can_inplace=False, is_weak=False),
    ]
]
op39.group.device = cuda:0
op39.group.iteration = (100, 1)
op39.sizes = ([100], [])
buf32_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf39_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
class op39_loop_body:
    var_ranges = {z0: 100}
    index0 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        index_expr = ops.index_expr(get_index, torch.int32)
        constant = ops.constant(40, torch.int32)
        eq = ops.eq(index_expr, constant)
        get_index_1 = self.get_index('index0')
        index_expr_1 = ops.index_expr(get_index_1, torch.int32)
        constant_1 = ops.constant(41, torch.int32)
        eq_1 = ops.eq(index_expr_1, constant_1)
        get_index_2 = self.get_index('index0')
        index_expr_2 = ops.index_expr(get_index_2, torch.int32)
        constant_2 = ops.constant(42, torch.int32)
        eq_2 = ops.eq(index_expr_2, constant_2)
        get_index_3 = self.get_index('index0')
        index_expr_3 = ops.index_expr(get_index_3, torch.int32)
        constant_3 = ops.constant(43, torch.int32)
        eq_3 = ops.eq(index_expr_3, constant_3)
        get_index_4 = self.get_index('index0')
        index_expr_4 = ops.index_expr(get_index_4, torch.int32)
        constant_4 = ops.constant(44, torch.int32)
        eq_4 = ops.eq(index_expr_4, constant_4)
        get_index_5 = self.get_index('index0')
        index_expr_5 = ops.index_expr(get_index_5, torch.int32)
        constant_5 = ops.constant(45, torch.int32)
        eq_5 = ops.eq(index_expr_5, constant_5)
        get_index_6 = self.get_index('index0')
        index_expr_6 = ops.index_expr(get_index_6, torch.int32)
        constant_6 = ops.constant(46, torch.int32)
        eq_6 = ops.eq(index_expr_6, constant_6)
        get_index_7 = self.get_index('index0')
        index_expr_7 = ops.index_expr(get_index_7, torch.int32)
        constant_7 = ops.constant(47, torch.int32)
        eq_7 = ops.eq(index_expr_7, constant_7)
        get_index_8 = self.get_index('index0')
        index_expr_8 = ops.index_expr(get_index_8, torch.int32)
        constant_8 = ops.constant(48, torch.int32)
        eq_8 = ops.eq(index_expr_8, constant_8)
        get_index_9 = self.get_index('index0')
        index_expr_9 = ops.index_expr(get_index_9, torch.int32)
        constant_9 = ops.constant(49, torch.int32)
        eq_9 = ops.eq(index_expr_9, constant_9)
        get_index_10 = self.get_index('index0')
        load = ops.load('buf32', get_index_10)
        constant_10 = ops.constant(0.0, torch.float32)
        where = ops.where(eq_9, constant_10, load)
        constant_11 = ops.constant(0.0, torch.float32)
        where_1 = ops.where(eq_8, constant_11, where)
        constant_12 = ops.constant(0.0, torch.float32)
        where_2 = ops.where(eq_7, constant_12, where_1)
        constant_13 = ops.constant(0.0, torch.float32)
        where_3 = ops.where(eq_6, constant_13, where_2)
        constant_14 = ops.constant(0.0, torch.float32)
        where_4 = ops.where(eq_5, constant_14, where_3)
        constant_15 = ops.constant(0.0, torch.float32)
        where_5 = ops.where(eq_4, constant_15, where_4)
        constant_16 = ops.constant(0.0, torch.float32)
        where_6 = ops.where(eq_3, constant_16, where_5)
        constant_17 = ops.constant(0.0, torch.float32)
        where_7 = ops.where(eq_2, constant_17, where_6)
        constant_18 = ops.constant(0.0, torch.float32)
        where_8 = ops.where(eq_1, constant_18, where_7)
        constant_19 = ops.constant(0.0, torch.float32)
        where_9 = ops.where(eq, constant_19, where_8)
        get_index_11 = self.get_index('index0')
        store = ops.store('buf39', get_index_11, where_9, None)
        return store
op39 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[128], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, multi_processor_count=20), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '712B1D69F892A891D8FFA5075DCAB47CFF4E132D88BFC66744701CEAE226F127', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 100
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp21 = tl.load(in_ptr0 + (x0), xmask)
        tmp0 = x0
        tmp1 = tl.full([1], 40, tl.int32)
        tmp2 = tmp0 == tmp1
        tmp3 = tl.full([1], 41, tl.int32)
        tmp4 = tmp0 == tmp3
        tmp5 = tl.full([1], 42, tl.int32)
        tmp6 = tmp0 == tmp5
        tmp7 = tl.full([1], 43, tl.int32)
        tmp8 = tmp0 == tmp7
        tmp9 = tl.full([1], 44, tl.int32)
        tmp10 = tmp0 == tmp9
        tmp11 = tl.full([1], 45, tl.int32)
        tmp12 = tmp0 == tmp11
        tmp13 = tl.full([1], 46, tl.int32)
        tmp14 = tmp0 == tmp13
        tmp15 = tl.full([1], 47, tl.int32)
        tmp16 = tmp0 == tmp15
        tmp17 = tl.full([1], 48, tl.int32)
        tmp18 = tmp0 == tmp17
        tmp19 = tl.full([1], 49, tl.int32)
        tmp20 = tmp0 == tmp19
        tmp22 = 0.0
        tmp23 = tl.where(tmp20, tmp22, tmp21)
        tmp24 = tl.where(tmp18, tmp22, tmp23)
        tmp25 = tl.where(tmp16, tmp22, tmp24)
        tmp26 = tl.where(tmp14, tmp22, tmp25)
        tmp27 = tl.where(tmp12, tmp22, tmp26)
        tmp28 = tl.where(tmp10, tmp22, tmp27)
        tmp29 = tl.where(tmp8, tmp22, tmp28)
        tmp30 = tl.where(tmp6, tmp22, tmp29)
        tmp31 = tl.where(tmp4, tmp22, tmp30)
        tmp32 = tl.where(tmp2, tmp22, tmp31)
        tl.store(out_ptr0 + (x0), tmp32, xmask)


op40: SchedulerNode(ComputedBuffer)
op40.writes = [MemoryDep('buf40', 0, {}, None)]
op40.unmet_dependencies = [MemoryDep('buf32', 40, {}, None)]
op40.met_dependencies = []
op40.outputs = [
    buf40: ComputedBuffer
    buf40.layout = FixedLayout('cuda', torch.float32, size=[], stride=[])
    buf40.users = [NodeUser(node=SchedulerNode(name='op41'), can_inplace=False, is_weak=False)]
]
op40.group.device = cuda:0
op40.group.iteration = (1, 1)
op40.sizes = ([], [])
buf32_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf40_layout = FixedLayout('cuda', torch.float32, size=[], stride=[])
class op40_loop_body:
    var_ranges = {}
    index0 = 40
    index1 = 0
    def body(self, ops):
        constant = ops.constant(40, torch.int32)
        constant_1 = ops.constant(41, torch.int32)
        eq = ops.eq(constant, constant_1)
        constant_2 = ops.constant(40, torch.int32)
        constant_3 = ops.constant(42, torch.int32)
        eq_1 = ops.eq(constant_2, constant_3)
        constant_4 = ops.constant(40, torch.int32)
        constant_5 = ops.constant(43, torch.int32)
        eq_2 = ops.eq(constant_4, constant_5)
        constant_6 = ops.constant(40, torch.int32)
        constant_7 = ops.constant(44, torch.int32)
        eq_3 = ops.eq(constant_6, constant_7)
        constant_8 = ops.constant(40, torch.int32)
        constant_9 = ops.constant(45, torch.int32)
        eq_4 = ops.eq(constant_8, constant_9)
        constant_10 = ops.constant(40, torch.int32)
        constant_11 = ops.constant(46, torch.int32)
        eq_5 = ops.eq(constant_10, constant_11)
        constant_12 = ops.constant(40, torch.int32)
        constant_13 = ops.constant(47, torch.int32)
        eq_6 = ops.eq(constant_12, constant_13)
        constant_14 = ops.constant(40, torch.int32)
        constant_15 = ops.constant(48, torch.int32)
        eq_7 = ops.eq(constant_14, constant_15)
        constant_16 = ops.constant(40, torch.int32)
        constant_17 = ops.constant(49, torch.int32)
        eq_8 = ops.eq(constant_16, constant_17)
        get_index = self.get_index('index0')
        load = ops.load('buf32', get_index)
        constant_18 = ops.constant(0.0, torch.float32)
        where = ops.where(eq_8, constant_18, load)
        constant_19 = ops.constant(0.0, torch.float32)
        where_1 = ops.where(eq_7, constant_19, where)
        constant_20 = ops.constant(0.0, torch.float32)
        where_2 = ops.where(eq_6, constant_20, where_1)
        constant_21 = ops.constant(0.0, torch.float32)
        where_3 = ops.where(eq_5, constant_21, where_2)
        constant_22 = ops.constant(0.0, torch.float32)
        where_4 = ops.where(eq_4, constant_22, where_3)
        constant_23 = ops.constant(0.0, torch.float32)
        where_5 = ops.where(eq_3, constant_23, where_4)
        constant_24 = ops.constant(0.0, torch.float32)
        where_6 = ops.where(eq_2, constant_24, where_5)
        constant_25 = ops.constant(0.0, torch.float32)
        where_7 = ops.where(eq_1, constant_25, where_6)
        constant_26 = ops.constant(0.0, torch.float32)
        where_8 = ops.where(eq, constant_26, where_7)
        constant_27 = ops.constant(2.0, torch.float32)
        mul = ops.mul(where_8, constant_27)
        get_index_1 = self.get_index('index1')
        store = ops.store('buf40', get_index_1, mul, None)
        return store
op40 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[1], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, multi_processor_count=20), 'constants': {2: 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(2,))]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '712B1D69F892A891D8FFA5075DCAB47CFF4E132D88BFC66744701CEAE226F127', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 1
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = tl.full([XBLOCK], True, tl.int1)
        tmp19 = tl.load(in_ptr0 + (40))
        tmp20 = tl.broadcast_to(tmp19, [XBLOCK])
        tmp0 = tl.full([1], 40, tl.int32)
        tmp1 = tl.full([1], 41, tl.int32)
        tmp2 = tmp0 == tmp1
        tmp3 = tl.full([1], 42, tl.int32)
        tmp4 = tmp0 == tmp3
        tmp5 = tl.full([1], 43, tl.int32)
        tmp6 = tmp0 == tmp5
        tmp7 = tl.full([1], 44, tl.int32)
        tmp8 = tmp0 == tmp7
        tmp9 = tl.full([1], 45, tl.int32)
        tmp10 = tmp0 == tmp9
        tmp11 = tl.full([1], 46, tl.int32)
        tmp12 = tmp0 == tmp11
        tmp13 = tl.full([1], 47, tl.int32)
        tmp14 = tmp0 == tmp13
        tmp15 = tl.full([1], 48, tl.int32)
        tmp16 = tmp0 == tmp15
        tmp17 = tl.full([1], 49, tl.int32)
        tmp18 = tmp0 == tmp17
        tmp21 = 0.0
        tmp22 = tl.where(tmp18, tmp21, tmp20)
        tmp23 = tl.where(tmp16, tmp21, tmp22)
        tmp24 = tl.where(tmp14, tmp21, tmp23)
        tmp25 = tl.where(tmp12, tmp21, tmp24)
        tmp26 = tl.where(tmp10, tmp21, tmp25)
        tmp27 = tl.where(tmp8, tmp21, tmp26)
        tmp28 = tl.where(tmp6, tmp21, tmp27)
        tmp29 = tl.where(tmp4, tmp21, tmp28)
        tmp30 = tl.where(tmp2, tmp21, tmp29)
        tmp31 = 2.0
        tmp32 = tmp30 * tmp31
        tl.store(out_ptr0 + (tl.full([XBLOCK], 0, tl.int32)), tmp32, None)


op41: SchedulerNode(ComputedBuffer)
op41.writes = [MemoryDep('buf41', c0, {c0: 100}, None)]
op41.unmet_dependencies = 
    [   MemoryDep('buf37', c0, {c0: 100}, None),
        MemoryDep('buf38', c0, {c0: 100}, None),
        MemoryDep('buf39', 37, {}, None),
        MemoryDep('buf39', 38, {}, None),
        MemoryDep('buf39', 39, {}, None),
        MemoryDep('buf40', 0, {}, None)]
op41.met_dependencies = [MemoryDep('full_default', c0, {c0: 100}, None)]
op41.outputs = [
    buf41: ComputedBuffer
    buf41.layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
    buf41.users = [NodeUser(node=SchedulerNode(name='op42'), can_inplace=True, is_weak=False)]
]
op41.group.device = cuda:0
op41.group.iteration = (100, 1)
op41.sizes = ([100], [])
buf37_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf38_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf40_layout = FixedLayout('cuda', torch.float32, size=[], stride=[])
full_default_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf39_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf39_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf39_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf41_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
class op41_loop_body:
    var_ranges = {z0: 100}
    index0 = z0
    index1 = 0
    index2 = 39
    index3 = 38
    index4 = 37
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf37', get_index)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('buf38', get_index_1)
        add = ops.add(load, load_1)
        get_index_2 = self.get_index('index0')
        index_expr = ops.index_expr(get_index_2, torch.int32)
        constant = ops.constant(40, torch.int32)
        eq = ops.eq(index_expr, constant)
        get_index_3 = self.get_index('index1')
        load_2 = ops.load('buf40', get_index_3)
        get_index_4 = self.get_index('index0')
        load_3 = ops.load('full_default', get_index_4)
        where = ops.where(eq, load_2, load_3)
        add_1 = ops.add(add, where)
        get_index_5 = self.get_index('index0')
        index_expr_1 = ops.index_expr(get_index_5, torch.int32)
        constant_1 = ops.constant(39, torch.int32)
        eq_1 = ops.eq(index_expr_1, constant_1)
        get_index_6 = self.get_index('index2')
        load_4 = ops.load('buf39', get_index_6)
        constant_2 = ops.constant(2.0, torch.float32)
        mul = ops.mul(load_4, constant_2)
        get_index_7 = self.get_index('index0')
        load_5 = ops.load('full_default', get_index_7)
        where_1 = ops.where(eq_1, mul, load_5)
        add_2 = ops.add(add_1, where_1)
        get_index_8 = self.get_index('index0')
        index_expr_2 = ops.index_expr(get_index_8, torch.int32)
        constant_3 = ops.constant(38, torch.int32)
        eq_2 = ops.eq(index_expr_2, constant_3)
        constant_4 = ops.constant(38, torch.int32)
        constant_5 = ops.constant(39, torch.int32)
        eq_3 = ops.eq(constant_4, constant_5)
        get_index_9 = self.get_index('index3')
        load_6 = ops.load('buf39', get_index_9)
        constant_6 = ops.constant(0.0, torch.float32)
        where_2 = ops.where(eq_3, constant_6, load_6)
        constant_7 = ops.constant(2.0, torch.float32)
        mul_1 = ops.mul(where_2, constant_7)
        get_index_10 = self.get_index('index0')
        load_7 = ops.load('full_default', get_index_10)
        where_3 = ops.where(eq_2, mul_1, load_7)
        add_3 = ops.add(add_2, where_3)
        get_index_11 = self.get_index('index0')
        index_expr_3 = ops.index_expr(get_index_11, torch.int32)
        constant_8 = ops.constant(37, torch.int32)
        eq_4 = ops.eq(index_expr_3, constant_8)
        constant_9 = ops.constant(37, torch.int32)
        constant_10 = ops.constant(38, torch.int32)
        eq_5 = ops.eq(constant_9, constant_10)
        constant_11 = ops.constant(37, torch.int32)
        constant_12 = ops.constant(39, torch.int32)
        eq_6 = ops.eq(constant_11, constant_12)
        get_index_12 = self.get_index('index4')
        load_8 = ops.load('buf39', get_index_12)
        constant_13 = ops.constant(0.0, torch.float32)
        where_4 = ops.where(eq_6, constant_13, load_8)
        constant_14 = ops.constant(0.0, torch.float32)
        where_5 = ops.where(eq_5, constant_14, where_4)
        constant_15 = ops.constant(2.0, torch.float32)
        mul_2 = ops.mul(where_5, constant_15)
        get_index_13 = self.get_index('index0')
        load_9 = ops.load('full_default', get_index_13)
        where_6 = ops.where(eq_4, mul_2, load_9)
        add_4 = ops.add(add_3, where_6)
        get_index_14 = self.get_index('index0')
        store = ops.store('buf41', get_index_14, add_4, None)
        return store
op41 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[128], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, multi_processor_count=20), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_out_ptr0'], 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': '712B1D69F892A891D8FFA5075DCAB47CFF4E132D88BFC66744701CEAE226F127', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, xnumel, XBLOCK : tl.constexpr):
        xnumel = 100
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp0 = tl.load(in_out_ptr0 + (x0), xmask)
        tmp1 = tl.load(in_ptr0 + (x0), xmask)
        tmp6 = tl.load(in_ptr1 + (0))
        tmp7 = tl.broadcast_to(tmp6, [XBLOCK])
        tmp8 = tl.load(in_ptr2 + (x0), xmask)
        tmp13 = tl.load(in_ptr3 + (39))
        tmp14 = tl.broadcast_to(tmp13, [XBLOCK])
        tmp22 = tl.load(in_ptr3 + (38))
        tmp23 = tl.broadcast_to(tmp22, [XBLOCK])
        tmp33 = tl.load(in_ptr3 + (37))
        tmp34 = tl.broadcast_to(tmp33, [XBLOCK])
        tmp2 = tmp0 + tmp1
        tmp3 = x0
        tmp4 = tl.full([1], 40, tl.int32)
        tmp5 = tmp3 == tmp4
        tmp9 = tl.where(tmp5, tmp7, tmp8)
        tmp10 = tmp2 + tmp9
        tmp11 = tl.full([1], 39, tl.int32)
        tmp12 = tmp3 == tmp11
        tmp15 = 2.0
        tmp16 = tmp14 * tmp15
        tmp17 = tl.where(tmp12, tmp16, tmp8)
        tmp18 = tmp10 + tmp17
        tmp19 = tl.full([1], 38, tl.int32)
        tmp20 = tmp3 == tmp19
        tmp21 = tmp19 == tmp11
        tmp24 = 0.0
        tmp25 = tl.where(tmp21, tmp24, tmp23)
        tmp26 = tmp25 * tmp15
        tmp27 = tl.where(tmp20, tmp26, tmp8)
        tmp28 = tmp18 + tmp27
        tmp29 = tl.full([1], 37, tl.int32)
        tmp30 = tmp3 == tmp29
        tmp31 = tmp29 == tmp19
        tmp32 = tmp29 == tmp11
        tmp35 = tl.where(tmp32, tmp24, tmp34)
        tmp36 = tl.where(tmp31, tmp24, tmp35)
        tmp37 = tmp36 * tmp15
        tmp38 = tl.where(tmp30, tmp37, tmp8)
        tmp39 = tmp28 + tmp38
        tl.store(in_out_ptr0 + (x0), tmp39, xmask)


op42: SchedulerNode(ComputedBuffer)
op42.writes = [MemoryDep('buf42', c0, {c0: 100}, None)]
op42.unmet_dependencies = 
    [   MemoryDep('buf39', 35, {}, None),
        MemoryDep('buf39', 36, {}, None),
        MemoryDep('buf41', c0, {c0: 100}, None)]
op42.met_dependencies = [MemoryDep('full_default', c0, {c0: 100}, None)]
op42.outputs = [
    buf42: ComputedBuffer
    buf42.layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
    buf42.users = [NodeUser(node=SchedulerNode(name='op43'), can_inplace=True, is_weak=False)]
]
op42.group.device = cuda:0
op42.group.iteration = (100, 1)
op42.sizes = ([100], [])
buf41_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf39_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
full_default_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf39_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf42_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
class op42_loop_body:
    var_ranges = {z0: 100}
    index0 = z0
    index1 = 36
    index2 = 35
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf41', get_index)
        get_index_1 = self.get_index('index0')
        index_expr = ops.index_expr(get_index_1, torch.int32)
        constant = ops.constant(36, torch.int32)
        eq = ops.eq(index_expr, constant)
        constant_1 = ops.constant(36, torch.int32)
        constant_2 = ops.constant(37, torch.int32)
        eq_1 = ops.eq(constant_1, constant_2)
        constant_3 = ops.constant(36, torch.int32)
        constant_4 = ops.constant(38, torch.int32)
        eq_2 = ops.eq(constant_3, constant_4)
        constant_5 = ops.constant(36, torch.int32)
        constant_6 = ops.constant(39, torch.int32)
        eq_3 = ops.eq(constant_5, constant_6)
        get_index_2 = self.get_index('index1')
        load_1 = ops.load('buf39', get_index_2)
        constant_7 = ops.constant(0.0, torch.float32)
        where = ops.where(eq_3, constant_7, load_1)
        constant_8 = ops.constant(0.0, torch.float32)
        where_1 = ops.where(eq_2, constant_8, where)
        constant_9 = ops.constant(0.0, torch.float32)
        where_2 = ops.where(eq_1, constant_9, where_1)
        constant_10 = ops.constant(2.0, torch.float32)
        mul = ops.mul(where_2, constant_10)
        get_index_3 = self.get_index('index0')
        load_2 = ops.load('full_default', get_index_3)
        where_3 = ops.where(eq, mul, load_2)
        add = ops.add(load, where_3)
        get_index_4 = self.get_index('index0')
        index_expr_1 = ops.index_expr(get_index_4, torch.int32)
        constant_11 = ops.constant(35, torch.int32)
        eq_4 = ops.eq(index_expr_1, constant_11)
        constant_12 = ops.constant(35, torch.int32)
        constant_13 = ops.constant(36, torch.int32)
        eq_5 = ops.eq(constant_12, constant_13)
        constant_14 = ops.constant(35, torch.int32)
        constant_15 = ops.constant(37, torch.int32)
        eq_6 = ops.eq(constant_14, constant_15)
        constant_16 = ops.constant(35, torch.int32)
        constant_17 = ops.constant(38, torch.int32)
        eq_7 = ops.eq(constant_16, constant_17)
        constant_18 = ops.constant(35, torch.int32)
        constant_19 = ops.constant(39, torch.int32)
        eq_8 = ops.eq(constant_18, constant_19)
        get_index_5 = self.get_index('index2')
        load_3 = ops.load('buf39', get_index_5)
        constant_20 = ops.constant(0.0, torch.float32)
        where_4 = ops.where(eq_8, constant_20, load_3)
        constant_21 = ops.constant(0.0, torch.float32)
        where_5 = ops.where(eq_7, constant_21, where_4)
        constant_22 = ops.constant(0.0, torch.float32)
        where_6 = ops.where(eq_6, constant_22, where_5)
        constant_23 = ops.constant(0.0, torch.float32)
        where_7 = ops.where(eq_5, constant_23, where_6)
        constant_24 = ops.constant(2.0, torch.float32)
        mul_1 = ops.mul(where_7, constant_24)
        get_index_6 = self.get_index('index0')
        load_4 = ops.load('full_default', get_index_6)
        where_8 = ops.where(eq_4, mul_1, load_4)
        add_1 = ops.add(add, where_8)
        get_index_7 = self.get_index('index0')
        store = ops.store('buf42', get_index_7, add_1, None)
        return store
op42 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[128], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, multi_processor_count=20), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_out_ptr0'], 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': '712B1D69F892A891D8FFA5075DCAB47CFF4E132D88BFC66744701CEAE226F127', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_out_ptr0, in_ptr0, in_ptr1, xnumel, XBLOCK : tl.constexpr):
        xnumel = 100
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp0 = tl.load(in_out_ptr0 + (x0), xmask)
        tmp10 = tl.load(in_ptr0 + (36))
        tmp11 = tl.broadcast_to(tmp10, [XBLOCK])
        tmp18 = tl.load(in_ptr1 + (x0), xmask)
        tmp27 = tl.load(in_ptr0 + (35))
        tmp28 = tl.broadcast_to(tmp27, [XBLOCK])
        tmp1 = x0
        tmp2 = tl.full([1], 36, tl.int32)
        tmp3 = tmp1 == tmp2
        tmp4 = tl.full([1], 37, tl.int32)
        tmp5 = tmp2 == tmp4
        tmp6 = tl.full([1], 38, tl.int32)
        tmp7 = tmp2 == tmp6
        tmp8 = tl.full([1], 39, tl.int32)
        tmp9 = tmp2 == tmp8
        tmp12 = 0.0
        tmp13 = tl.where(tmp9, tmp12, tmp11)
        tmp14 = tl.where(tmp7, tmp12, tmp13)
        tmp15 = tl.where(tmp5, tmp12, tmp14)
        tmp16 = 2.0
        tmp17 = tmp15 * tmp16
        tmp19 = tl.where(tmp3, tmp17, tmp18)
        tmp20 = tmp0 + tmp19
        tmp21 = tl.full([1], 35, tl.int32)
        tmp22 = tmp1 == tmp21
        tmp23 = tmp21 == tmp2
        tmp24 = tmp21 == tmp4
        tmp25 = tmp21 == tmp6
        tmp26 = tmp21 == tmp8
        tmp29 = tl.where(tmp26, tmp12, tmp28)
        tmp30 = tl.where(tmp25, tmp12, tmp29)
        tmp31 = tl.where(tmp24, tmp12, tmp30)
        tmp32 = tl.where(tmp23, tmp12, tmp31)
        tmp33 = tmp32 * tmp16
        tmp34 = tl.where(tmp22, tmp33, tmp18)
        tmp35 = tmp20 + tmp34
        tl.store(in_out_ptr0 + (x0), tmp35, xmask)


op43: SchedulerNode(ComputedBuffer)
op43.writes = [MemoryDep('buf43', c0, {c0: 100}, None)]
op43.unmet_dependencies = 
    [   MemoryDep('buf39', 33, {}, None),
        MemoryDep('buf39', 34, {}, None),
        MemoryDep('buf42', c0, {c0: 100}, None)]
op43.met_dependencies = [MemoryDep('full_default', c0, {c0: 100}, None)]
op43.outputs = [
    buf43: ComputedBuffer
    buf43.layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
    buf43.users = [NodeUser(node=SchedulerNode(name='op44'), can_inplace=True, is_weak=False)]
]
op43.group.device = cuda:0
op43.group.iteration = (100, 1)
op43.sizes = ([100], [])
buf42_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf39_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
full_default_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf39_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf43_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
class op43_loop_body:
    var_ranges = {z0: 100}
    index0 = z0
    index1 = 34
    index2 = 33
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf42', get_index)
        get_index_1 = self.get_index('index0')
        index_expr = ops.index_expr(get_index_1, torch.int32)
        constant = ops.constant(34, torch.int32)
        eq = ops.eq(index_expr, constant)
        constant_1 = ops.constant(34, torch.int32)
        constant_2 = ops.constant(35, torch.int32)
        eq_1 = ops.eq(constant_1, constant_2)
        constant_3 = ops.constant(34, torch.int32)
        constant_4 = ops.constant(36, torch.int32)
        eq_2 = ops.eq(constant_3, constant_4)
        constant_5 = ops.constant(34, torch.int32)
        constant_6 = ops.constant(37, torch.int32)
        eq_3 = ops.eq(constant_5, constant_6)
        constant_7 = ops.constant(34, torch.int32)
        constant_8 = ops.constant(38, torch.int32)
        eq_4 = ops.eq(constant_7, constant_8)
        constant_9 = ops.constant(34, torch.int32)
        constant_10 = ops.constant(39, torch.int32)
        eq_5 = ops.eq(constant_9, constant_10)
        get_index_2 = self.get_index('index1')
        load_1 = ops.load('buf39', get_index_2)
        constant_11 = ops.constant(0.0, torch.float32)
        where = ops.where(eq_5, constant_11, load_1)
        constant_12 = ops.constant(0.0, torch.float32)
        where_1 = ops.where(eq_4, constant_12, where)
        constant_13 = ops.constant(0.0, torch.float32)
        where_2 = ops.where(eq_3, constant_13, where_1)
        constant_14 = ops.constant(0.0, torch.float32)
        where_3 = ops.where(eq_2, constant_14, where_2)
        constant_15 = ops.constant(0.0, torch.float32)
        where_4 = ops.where(eq_1, constant_15, where_3)
        constant_16 = ops.constant(2.0, torch.float32)
        mul = ops.mul(where_4, constant_16)
        get_index_3 = self.get_index('index0')
        load_2 = ops.load('full_default', get_index_3)
        where_5 = ops.where(eq, mul, load_2)
        add = ops.add(load, where_5)
        get_index_4 = self.get_index('index0')
        index_expr_1 = ops.index_expr(get_index_4, torch.int32)
        constant_17 = ops.constant(33, torch.int32)
        eq_6 = ops.eq(index_expr_1, constant_17)
        constant_18 = ops.constant(33, torch.int32)
        constant_19 = ops.constant(34, torch.int32)
        eq_7 = ops.eq(constant_18, constant_19)
        constant_20 = ops.constant(33, torch.int32)
        constant_21 = ops.constant(35, torch.int32)
        eq_8 = ops.eq(constant_20, constant_21)
        constant_22 = ops.constant(33, torch.int32)
        constant_23 = ops.constant(36, torch.int32)
        eq_9 = ops.eq(constant_22, constant_23)
        constant_24 = ops.constant(33, torch.int32)
        constant_25 = ops.constant(37, torch.int32)
        eq_10 = ops.eq(constant_24, constant_25)
        constant_26 = ops.constant(33, torch.int32)
        constant_27 = ops.constant(38, torch.int32)
        eq_11 = ops.eq(constant_26, constant_27)
        constant_28 = ops.constant(33, torch.int32)
        constant_29 = ops.constant(39, torch.int32)
        eq_12 = ops.eq(constant_28, constant_29)
        get_index_5 = self.get_index('index2')
        load_3 = ops.load('buf39', get_index_5)
        constant_30 = ops.constant(0.0, torch.float32)
        where_6 = ops.where(eq_12, constant_30, load_3)
        constant_31 = ops.constant(0.0, torch.float32)
        where_7 = ops.where(eq_11, constant_31, where_6)
        constant_32 = ops.constant(0.0, torch.float32)
        where_8 = ops.where(eq_10, constant_32, where_7)
        constant_33 = ops.constant(0.0, torch.float32)
        where_9 = ops.where(eq_9, constant_33, where_8)
        constant_34 = ops.constant(0.0, torch.float32)
        where_10 = ops.where(eq_8, constant_34, where_9)
        constant_35 = ops.constant(0.0, torch.float32)
        where_11 = ops.where(eq_7, constant_35, where_10)
        constant_36 = ops.constant(2.0, torch.float32)
        mul_1 = ops.mul(where_11, constant_36)
        get_index_6 = self.get_index('index0')
        load_4 = ops.load('full_default', get_index_6)
        where_12 = ops.where(eq_6, mul_1, load_4)
        add_1 = ops.add(add, where_12)
        get_index_7 = self.get_index('index0')
        store = ops.store('buf43', get_index_7, add_1, None)
        return store
op43 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[128], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, multi_processor_count=20), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_out_ptr0'], 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': '712B1D69F892A891D8FFA5075DCAB47CFF4E132D88BFC66744701CEAE226F127', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_out_ptr0, in_ptr0, in_ptr1, xnumel, XBLOCK : tl.constexpr):
        xnumel = 100
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp0 = tl.load(in_out_ptr0 + (x0), xmask)
        tmp14 = tl.load(in_ptr0 + (34))
        tmp15 = tl.broadcast_to(tmp14, [XBLOCK])
        tmp24 = tl.load(in_ptr1 + (x0), xmask)
        tmp35 = tl.load(in_ptr0 + (33))
        tmp36 = tl.broadcast_to(tmp35, [XBLOCK])
        tmp1 = x0
        tmp2 = tl.full([1], 34, tl.int32)
        tmp3 = tmp1 == tmp2
        tmp4 = tl.full([1], 35, tl.int32)
        tmp5 = tmp2 == tmp4
        tmp6 = tl.full([1], 36, tl.int32)
        tmp7 = tmp2 == tmp6
        tmp8 = tl.full([1], 37, tl.int32)
        tmp9 = tmp2 == tmp8
        tmp10 = tl.full([1], 38, tl.int32)
        tmp11 = tmp2 == tmp10
        tmp12 = tl.full([1], 39, tl.int32)
        tmp13 = tmp2 == tmp12
        tmp16 = 0.0
        tmp17 = tl.where(tmp13, tmp16, tmp15)
        tmp18 = tl.where(tmp11, tmp16, tmp17)
        tmp19 = tl.where(tmp9, tmp16, tmp18)
        tmp20 = tl.where(tmp7, tmp16, tmp19)
        tmp21 = tl.where(tmp5, tmp16, tmp20)
        tmp22 = 2.0
        tmp23 = tmp21 * tmp22
        tmp25 = tl.where(tmp3, tmp23, tmp24)
        tmp26 = tmp0 + tmp25
        tmp27 = tl.full([1], 33, tl.int32)
        tmp28 = tmp1 == tmp27
        tmp29 = tmp27 == tmp2
        tmp30 = tmp27 == tmp4
        tmp31 = tmp27 == tmp6
        tmp32 = tmp27 == tmp8
        tmp33 = tmp27 == tmp10
        tmp34 = tmp27 == tmp12
        tmp37 = tl.where(tmp34, tmp16, tmp36)
        tmp38 = tl.where(tmp33, tmp16, tmp37)
        tmp39 = tl.where(tmp32, tmp16, tmp38)
        tmp40 = tl.where(tmp31, tmp16, tmp39)
        tmp41 = tl.where(tmp30, tmp16, tmp40)
        tmp42 = tl.where(tmp29, tmp16, tmp41)
        tmp43 = tmp42 * tmp22
        tmp44 = tl.where(tmp28, tmp43, tmp24)
        tmp45 = tmp26 + tmp44
        tl.store(in_out_ptr0 + (x0), tmp45, xmask)


op44: SchedulerNode(ComputedBuffer)
op44.writes = [MemoryDep('buf44', c0, {c0: 100}, None)]
op44.unmet_dependencies = [MemoryDep('buf39', 32, {}, None), MemoryDep('buf43', c0, {c0: 100}, None)]
op44.met_dependencies = [MemoryDep('full_default', c0, {c0: 100}, None)]
op44.outputs = [
    buf44: ComputedBuffer
    buf44.layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
    buf44.users = [NodeUser(node=SchedulerNode(name='op48'), can_inplace=True, is_weak=False)]
]
op44.group.device = cuda:0
op44.group.iteration = (100, 1)
op44.sizes = ([100], [])
buf43_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf39_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
full_default_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf44_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
class op44_loop_body:
    var_ranges = {z0: 100}
    index0 = z0
    index1 = 32
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf43', get_index)
        get_index_1 = self.get_index('index0')
        index_expr = ops.index_expr(get_index_1, torch.int32)
        constant = ops.constant(32, torch.int32)
        eq = ops.eq(index_expr, constant)
        constant_1 = ops.constant(32, torch.int32)
        constant_2 = ops.constant(33, torch.int32)
        eq_1 = ops.eq(constant_1, constant_2)
        constant_3 = ops.constant(32, torch.int32)
        constant_4 = ops.constant(34, torch.int32)
        eq_2 = ops.eq(constant_3, constant_4)
        constant_5 = ops.constant(32, torch.int32)
        constant_6 = ops.constant(35, torch.int32)
        eq_3 = ops.eq(constant_5, constant_6)
        constant_7 = ops.constant(32, torch.int32)
        constant_8 = ops.constant(36, torch.int32)
        eq_4 = ops.eq(constant_7, constant_8)
        constant_9 = ops.constant(32, torch.int32)
        constant_10 = ops.constant(37, torch.int32)
        eq_5 = ops.eq(constant_9, constant_10)
        constant_11 = ops.constant(32, torch.int32)
        constant_12 = ops.constant(38, torch.int32)
        eq_6 = ops.eq(constant_11, constant_12)
        constant_13 = ops.constant(32, torch.int32)
        constant_14 = ops.constant(39, torch.int32)
        eq_7 = ops.eq(constant_13, constant_14)
        get_index_2 = self.get_index('index1')
        load_1 = ops.load('buf39', get_index_2)
        constant_15 = ops.constant(0.0, torch.float32)
        where = ops.where(eq_7, constant_15, load_1)
        constant_16 = ops.constant(0.0, torch.float32)
        where_1 = ops.where(eq_6, constant_16, where)
        constant_17 = ops.constant(0.0, torch.float32)
        where_2 = ops.where(eq_5, constant_17, where_1)
        constant_18 = ops.constant(0.0, torch.float32)
        where_3 = ops.where(eq_4, constant_18, where_2)
        constant_19 = ops.constant(0.0, torch.float32)
        where_4 = ops.where(eq_3, constant_19, where_3)
        constant_20 = ops.constant(0.0, torch.float32)
        where_5 = ops.where(eq_2, constant_20, where_4)
        constant_21 = ops.constant(0.0, torch.float32)
        where_6 = ops.where(eq_1, constant_21, where_5)
        constant_22 = ops.constant(2.0, torch.float32)
        mul = ops.mul(where_6, constant_22)
        get_index_3 = self.get_index('index0')
        load_2 = ops.load('full_default', get_index_3)
        where_7 = ops.where(eq, mul, load_2)
        add = ops.add(load, where_7)
        get_index_4 = self.get_index('index0')
        store = ops.store('buf44', get_index_4, add, None)
        return store
op44 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[128], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, multi_processor_count=20), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_out_ptr0'], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 0, 'backend_hash': '712B1D69F892A891D8FFA5075DCAB47CFF4E132D88BFC66744701CEAE226F127', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_out_ptr0, in_ptr0, in_ptr1, xnumel, XBLOCK : tl.constexpr):
        xnumel = 100
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp0 = tl.load(in_out_ptr0 + (x0), xmask)
        tmp18 = tl.load(in_ptr0 + (32))
        tmp19 = tl.broadcast_to(tmp18, [XBLOCK])
        tmp30 = tl.load(in_ptr1 + (x0), xmask)
        tmp1 = x0
        tmp2 = tl.full([1], 32, tl.int32)
        tmp3 = tmp1 == tmp2
        tmp4 = tl.full([1], 33, tl.int32)
        tmp5 = tmp2 == tmp4
        tmp6 = tl.full([1], 34, tl.int32)
        tmp7 = tmp2 == tmp6
        tmp8 = tl.full([1], 35, tl.int32)
        tmp9 = tmp2 == tmp8
        tmp10 = tl.full([1], 36, tl.int32)
        tmp11 = tmp2 == tmp10
        tmp12 = tl.full([1], 37, tl.int32)
        tmp13 = tmp2 == tmp12
        tmp14 = tl.full([1], 38, tl.int32)
        tmp15 = tmp2 == tmp14
        tmp16 = tl.full([1], 39, tl.int32)
        tmp17 = tmp2 == tmp16
        tmp20 = 0.0
        tmp21 = tl.where(tmp17, tmp20, tmp19)
        tmp22 = tl.where(tmp15, tmp20, tmp21)
        tmp23 = tl.where(tmp13, tmp20, tmp22)
        tmp24 = tl.where(tmp11, tmp20, tmp23)
        tmp25 = tl.where(tmp9, tmp20, tmp24)
        tmp26 = tl.where(tmp7, tmp20, tmp25)
        tmp27 = tl.where(tmp5, tmp20, tmp26)
        tmp28 = 2.0
        tmp29 = tmp27 * tmp28
        tmp31 = tl.where(tmp3, tmp29, tmp30)
        tmp32 = tmp0 + tmp31
        tl.store(in_out_ptr0 + (x0), tmp32, xmask)


op45: SchedulerNode(ComputedBuffer)
op45.writes = [MemoryDep('buf45', c0, {c0: 100}, None)]
op45.unmet_dependencies = [MemoryDep('buf39', 31, {}, None)]
op45.met_dependencies = [MemoryDep('full_default', c0, {c0: 100}, None)]
op45.outputs = [
    buf45: ComputedBuffer
    buf45.layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
    buf45.users = [NodeUser(node=SchedulerNode(name='op48'), can_inplace=True, is_weak=False)]
]
op45.group.device = cuda:0
op45.group.iteration = (100, 1)
op45.sizes = ([100], [])
buf39_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
full_default_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf45_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
class op45_loop_body:
    var_ranges = {z0: 100}
    index0 = z0
    index1 = 31
    def body(self, ops):
        get_index = self.get_index('index0')
        index_expr = ops.index_expr(get_index, torch.int32)
        constant = ops.constant(31, torch.int32)
        eq = ops.eq(index_expr, constant)
        constant_1 = ops.constant(31, torch.int32)
        constant_2 = ops.constant(32, torch.int32)
        eq_1 = ops.eq(constant_1, constant_2)
        constant_3 = ops.constant(31, torch.int32)
        constant_4 = ops.constant(33, torch.int32)
        eq_2 = ops.eq(constant_3, constant_4)
        constant_5 = ops.constant(31, torch.int32)
        constant_6 = ops.constant(34, torch.int32)
        eq_3 = ops.eq(constant_5, constant_6)
        constant_7 = ops.constant(31, torch.int32)
        constant_8 = ops.constant(35, torch.int32)
        eq_4 = ops.eq(constant_7, constant_8)
        constant_9 = ops.constant(31, torch.int32)
        constant_10 = ops.constant(36, torch.int32)
        eq_5 = ops.eq(constant_9, constant_10)
        constant_11 = ops.constant(31, torch.int32)
        constant_12 = ops.constant(37, torch.int32)
        eq_6 = ops.eq(constant_11, constant_12)
        constant_13 = ops.constant(31, torch.int32)
        constant_14 = ops.constant(38, torch.int32)
        eq_7 = ops.eq(constant_13, constant_14)
        constant_15 = ops.constant(31, torch.int32)
        constant_16 = ops.constant(39, torch.int32)
        eq_8 = ops.eq(constant_15, constant_16)
        get_index_1 = self.get_index('index1')
        load = ops.load('buf39', get_index_1)
        constant_17 = ops.constant(0.0, torch.float32)
        where = ops.where(eq_8, constant_17, load)
        constant_18 = ops.constant(0.0, torch.float32)
        where_1 = ops.where(eq_7, constant_18, where)
        constant_19 = ops.constant(0.0, torch.float32)
        where_2 = ops.where(eq_6, constant_19, where_1)
        constant_20 = ops.constant(0.0, torch.float32)
        where_3 = ops.where(eq_5, constant_20, where_2)
        constant_21 = ops.constant(0.0, torch.float32)
        where_4 = ops.where(eq_4, constant_21, where_3)
        constant_22 = ops.constant(0.0, torch.float32)
        where_5 = ops.where(eq_3, constant_22, where_4)
        constant_23 = ops.constant(0.0, torch.float32)
        where_6 = ops.where(eq_2, constant_23, where_5)
        constant_24 = ops.constant(0.0, torch.float32)
        where_7 = ops.where(eq_1, constant_24, where_6)
        constant_25 = ops.constant(2.0, torch.float32)
        mul = ops.mul(where_7, constant_25)
        get_index_2 = self.get_index('index0')
        load_1 = ops.load('full_default', get_index_2)
        where_8 = ops.where(eq, mul, load_1)
        get_index_3 = self.get_index('index0')
        store = ops.store('buf45', get_index_3, where_8, None)
        return store
op45 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[128], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, multi_processor_count=20), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '712B1D69F892A891D8FFA5075DCAB47CFF4E132D88BFC66744701CEAE226F127', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 100
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp19 = tl.load(in_ptr0 + (31))
        tmp20 = tl.broadcast_to(tmp19, [XBLOCK])
        tmp32 = tl.load(in_ptr1 + (x0), xmask)
        tmp0 = x0
        tmp1 = tl.full([1], 31, tl.int32)
        tmp2 = tmp0 == tmp1
        tmp3 = tl.full([1], 32, tl.int32)
        tmp4 = tmp1 == tmp3
        tmp5 = tl.full([1], 33, tl.int32)
        tmp6 = tmp1 == tmp5
        tmp7 = tl.full([1], 34, tl.int32)
        tmp8 = tmp1 == tmp7
        tmp9 = tl.full([1], 35, tl.int32)
        tmp10 = tmp1 == tmp9
        tmp11 = tl.full([1], 36, tl.int32)
        tmp12 = tmp1 == tmp11
        tmp13 = tl.full([1], 37, tl.int32)
        tmp14 = tmp1 == tmp13
        tmp15 = tl.full([1], 38, tl.int32)
        tmp16 = tmp1 == tmp15
        tmp17 = tl.full([1], 39, tl.int32)
        tmp18 = tmp1 == tmp17
        tmp21 = 0.0
        tmp22 = tl.where(tmp18, tmp21, tmp20)
        tmp23 = tl.where(tmp16, tmp21, tmp22)
        tmp24 = tl.where(tmp14, tmp21, tmp23)
        tmp25 = tl.where(tmp12, tmp21, tmp24)
        tmp26 = tl.where(tmp10, tmp21, tmp25)
        tmp27 = tl.where(tmp8, tmp21, tmp26)
        tmp28 = tl.where(tmp6, tmp21, tmp27)
        tmp29 = tl.where(tmp4, tmp21, tmp28)
        tmp30 = 2.0
        tmp31 = tmp29 * tmp30
        tmp33 = tl.where(tmp2, tmp31, tmp32)
        tl.store(out_ptr0 + (x0), tmp33, xmask)


op46: SchedulerNode(ComputedBuffer)
op46.writes = [MemoryDep('buf46', c0, {c0: 100}, None)]
op46.unmet_dependencies = [MemoryDep('buf39', c0, {c0: 100}, None)]
op46.met_dependencies = []
op46.outputs = [
    buf46: ComputedBuffer
    buf46.layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
    buf46.users = [
        NodeUser(node=SchedulerNode(name='op48'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op49'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op50'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op51'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op52'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op53'), can_inplace=True, is_weak=False),
        NodeUser(node=SchedulerNode(name='op54'), can_inplace=False, is_weak=False),
    ]
]
op46.group.device = cuda:0
op46.group.iteration = (100, 1)
op46.sizes = ([100], [])
buf39_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf46_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
class op46_loop_body:
    var_ranges = {z0: 100}
    index0 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        index_expr = ops.index_expr(get_index, torch.int32)
        constant = ops.constant(30, torch.int32)
        eq = ops.eq(index_expr, constant)
        get_index_1 = self.get_index('index0')
        index_expr_1 = ops.index_expr(get_index_1, torch.int32)
        constant_1 = ops.constant(31, torch.int32)
        eq_1 = ops.eq(index_expr_1, constant_1)
        get_index_2 = self.get_index('index0')
        index_expr_2 = ops.index_expr(get_index_2, torch.int32)
        constant_2 = ops.constant(32, torch.int32)
        eq_2 = ops.eq(index_expr_2, constant_2)
        get_index_3 = self.get_index('index0')
        index_expr_3 = ops.index_expr(get_index_3, torch.int32)
        constant_3 = ops.constant(33, torch.int32)
        eq_3 = ops.eq(index_expr_3, constant_3)
        get_index_4 = self.get_index('index0')
        index_expr_4 = ops.index_expr(get_index_4, torch.int32)
        constant_4 = ops.constant(34, torch.int32)
        eq_4 = ops.eq(index_expr_4, constant_4)
        get_index_5 = self.get_index('index0')
        index_expr_5 = ops.index_expr(get_index_5, torch.int32)
        constant_5 = ops.constant(35, torch.int32)
        eq_5 = ops.eq(index_expr_5, constant_5)
        get_index_6 = self.get_index('index0')
        index_expr_6 = ops.index_expr(get_index_6, torch.int32)
        constant_6 = ops.constant(36, torch.int32)
        eq_6 = ops.eq(index_expr_6, constant_6)
        get_index_7 = self.get_index('index0')
        index_expr_7 = ops.index_expr(get_index_7, torch.int32)
        constant_7 = ops.constant(37, torch.int32)
        eq_7 = ops.eq(index_expr_7, constant_7)
        get_index_8 = self.get_index('index0')
        index_expr_8 = ops.index_expr(get_index_8, torch.int32)
        constant_8 = ops.constant(38, torch.int32)
        eq_8 = ops.eq(index_expr_8, constant_8)
        get_index_9 = self.get_index('index0')
        index_expr_9 = ops.index_expr(get_index_9, torch.int32)
        constant_9 = ops.constant(39, torch.int32)
        eq_9 = ops.eq(index_expr_9, constant_9)
        get_index_10 = self.get_index('index0')
        load = ops.load('buf39', get_index_10)
        constant_10 = ops.constant(0.0, torch.float32)
        where = ops.where(eq_9, constant_10, load)
        constant_11 = ops.constant(0.0, torch.float32)
        where_1 = ops.where(eq_8, constant_11, where)
        constant_12 = ops.constant(0.0, torch.float32)
        where_2 = ops.where(eq_7, constant_12, where_1)
        constant_13 = ops.constant(0.0, torch.float32)
        where_3 = ops.where(eq_6, constant_13, where_2)
        constant_14 = ops.constant(0.0, torch.float32)
        where_4 = ops.where(eq_5, constant_14, where_3)
        constant_15 = ops.constant(0.0, torch.float32)
        where_5 = ops.where(eq_4, constant_15, where_4)
        constant_16 = ops.constant(0.0, torch.float32)
        where_6 = ops.where(eq_3, constant_16, where_5)
        constant_17 = ops.constant(0.0, torch.float32)
        where_7 = ops.where(eq_2, constant_17, where_6)
        constant_18 = ops.constant(0.0, torch.float32)
        where_8 = ops.where(eq_1, constant_18, where_7)
        constant_19 = ops.constant(0.0, torch.float32)
        where_9 = ops.where(eq, constant_19, where_8)
        get_index_11 = self.get_index('index0')
        store = ops.store('buf46', get_index_11, where_9, None)
        return store
op46 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[128], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, multi_processor_count=20), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '712B1D69F892A891D8FFA5075DCAB47CFF4E132D88BFC66744701CEAE226F127', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 100
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp21 = tl.load(in_ptr0 + (x0), xmask)
        tmp0 = x0
        tmp1 = tl.full([1], 30, tl.int32)
        tmp2 = tmp0 == tmp1
        tmp3 = tl.full([1], 31, tl.int32)
        tmp4 = tmp0 == tmp3
        tmp5 = tl.full([1], 32, tl.int32)
        tmp6 = tmp0 == tmp5
        tmp7 = tl.full([1], 33, tl.int32)
        tmp8 = tmp0 == tmp7
        tmp9 = tl.full([1], 34, tl.int32)
        tmp10 = tmp0 == tmp9
        tmp11 = tl.full([1], 35, tl.int32)
        tmp12 = tmp0 == tmp11
        tmp13 = tl.full([1], 36, tl.int32)
        tmp14 = tmp0 == tmp13
        tmp15 = tl.full([1], 37, tl.int32)
        tmp16 = tmp0 == tmp15
        tmp17 = tl.full([1], 38, tl.int32)
        tmp18 = tmp0 == tmp17
        tmp19 = tl.full([1], 39, tl.int32)
        tmp20 = tmp0 == tmp19
        tmp22 = 0.0
        tmp23 = tl.where(tmp20, tmp22, tmp21)
        tmp24 = tl.where(tmp18, tmp22, tmp23)
        tmp25 = tl.where(tmp16, tmp22, tmp24)
        tmp26 = tl.where(tmp14, tmp22, tmp25)
        tmp27 = tl.where(tmp12, tmp22, tmp26)
        tmp28 = tl.where(tmp10, tmp22, tmp27)
        tmp29 = tl.where(tmp8, tmp22, tmp28)
        tmp30 = tl.where(tmp6, tmp22, tmp29)
        tmp31 = tl.where(tmp4, tmp22, tmp30)
        tmp32 = tl.where(tmp2, tmp22, tmp31)
        tl.store(out_ptr0 + (x0), tmp32, xmask)


op47: SchedulerNode(ComputedBuffer)
op47.writes = [MemoryDep('buf47', 0, {}, None)]
op47.unmet_dependencies = [MemoryDep('buf39', 30, {}, None)]
op47.met_dependencies = []
op47.outputs = [
    buf47: ComputedBuffer
    buf47.layout = FixedLayout('cuda', torch.float32, size=[], stride=[])
    buf47.users = [NodeUser(node=SchedulerNode(name='op48'), can_inplace=False, is_weak=False)]
]
op47.group.device = cuda:0
op47.group.iteration = (1, 1)
op47.sizes = ([], [])
buf39_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf47_layout = FixedLayout('cuda', torch.float32, size=[], stride=[])
class op47_loop_body:
    var_ranges = {}
    index0 = 30
    index1 = 0
    def body(self, ops):
        constant = ops.constant(30, torch.int32)
        constant_1 = ops.constant(31, torch.int32)
        eq = ops.eq(constant, constant_1)
        constant_2 = ops.constant(30, torch.int32)
        constant_3 = ops.constant(32, torch.int32)
        eq_1 = ops.eq(constant_2, constant_3)
        constant_4 = ops.constant(30, torch.int32)
        constant_5 = ops.constant(33, torch.int32)
        eq_2 = ops.eq(constant_4, constant_5)
        constant_6 = ops.constant(30, torch.int32)
        constant_7 = ops.constant(34, torch.int32)
        eq_3 = ops.eq(constant_6, constant_7)
        constant_8 = ops.constant(30, torch.int32)
        constant_9 = ops.constant(35, torch.int32)
        eq_4 = ops.eq(constant_8, constant_9)
        constant_10 = ops.constant(30, torch.int32)
        constant_11 = ops.constant(36, torch.int32)
        eq_5 = ops.eq(constant_10, constant_11)
        constant_12 = ops.constant(30, torch.int32)
        constant_13 = ops.constant(37, torch.int32)
        eq_6 = ops.eq(constant_12, constant_13)
        constant_14 = ops.constant(30, torch.int32)
        constant_15 = ops.constant(38, torch.int32)
        eq_7 = ops.eq(constant_14, constant_15)
        constant_16 = ops.constant(30, torch.int32)
        constant_17 = ops.constant(39, torch.int32)
        eq_8 = ops.eq(constant_16, constant_17)
        get_index = self.get_index('index0')
        load = ops.load('buf39', get_index)
        constant_18 = ops.constant(0.0, torch.float32)
        where = ops.where(eq_8, constant_18, load)
        constant_19 = ops.constant(0.0, torch.float32)
        where_1 = ops.where(eq_7, constant_19, where)
        constant_20 = ops.constant(0.0, torch.float32)
        where_2 = ops.where(eq_6, constant_20, where_1)
        constant_21 = ops.constant(0.0, torch.float32)
        where_3 = ops.where(eq_5, constant_21, where_2)
        constant_22 = ops.constant(0.0, torch.float32)
        where_4 = ops.where(eq_4, constant_22, where_3)
        constant_23 = ops.constant(0.0, torch.float32)
        where_5 = ops.where(eq_3, constant_23, where_4)
        constant_24 = ops.constant(0.0, torch.float32)
        where_6 = ops.where(eq_2, constant_24, where_5)
        constant_25 = ops.constant(0.0, torch.float32)
        where_7 = ops.where(eq_1, constant_25, where_6)
        constant_26 = ops.constant(0.0, torch.float32)
        where_8 = ops.where(eq, constant_26, where_7)
        constant_27 = ops.constant(2.0, torch.float32)
        mul = ops.mul(where_8, constant_27)
        get_index_1 = self.get_index('index1')
        store = ops.store('buf47', get_index_1, mul, None)
        return store
op47 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[1], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, multi_processor_count=20), 'constants': {2: 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(2,))]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '712B1D69F892A891D8FFA5075DCAB47CFF4E132D88BFC66744701CEAE226F127', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 1
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = tl.full([XBLOCK], True, tl.int1)
        tmp19 = tl.load(in_ptr0 + (30))
        tmp20 = tl.broadcast_to(tmp19, [XBLOCK])
        tmp0 = tl.full([1], 30, tl.int32)
        tmp1 = tl.full([1], 31, tl.int32)
        tmp2 = tmp0 == tmp1
        tmp3 = tl.full([1], 32, tl.int32)
        tmp4 = tmp0 == tmp3
        tmp5 = tl.full([1], 33, tl.int32)
        tmp6 = tmp0 == tmp5
        tmp7 = tl.full([1], 34, tl.int32)
        tmp8 = tmp0 == tmp7
        tmp9 = tl.full([1], 35, tl.int32)
        tmp10 = tmp0 == tmp9
        tmp11 = tl.full([1], 36, tl.int32)
        tmp12 = tmp0 == tmp11
        tmp13 = tl.full([1], 37, tl.int32)
        tmp14 = tmp0 == tmp13
        tmp15 = tl.full([1], 38, tl.int32)
        tmp16 = tmp0 == tmp15
        tmp17 = tl.full([1], 39, tl.int32)
        tmp18 = tmp0 == tmp17
        tmp21 = 0.0
        tmp22 = tl.where(tmp18, tmp21, tmp20)
        tmp23 = tl.where(tmp16, tmp21, tmp22)
        tmp24 = tl.where(tmp14, tmp21, tmp23)
        tmp25 = tl.where(tmp12, tmp21, tmp24)
        tmp26 = tl.where(tmp10, tmp21, tmp25)
        tmp27 = tl.where(tmp8, tmp21, tmp26)
        tmp28 = tl.where(tmp6, tmp21, tmp27)
        tmp29 = tl.where(tmp4, tmp21, tmp28)
        tmp30 = tl.where(tmp2, tmp21, tmp29)
        tmp31 = 2.0
        tmp32 = tmp30 * tmp31
        tl.store(out_ptr0 + (tl.full([XBLOCK], 0, tl.int32)), tmp32, None)


op48: SchedulerNode(ComputedBuffer)
op48.writes = [MemoryDep('buf48', c0, {c0: 100}, None)]
op48.unmet_dependencies = 
    [   MemoryDep('buf44', c0, {c0: 100}, None),
        MemoryDep('buf45', c0, {c0: 100}, None),
        MemoryDep('buf46', 27, {}, None),
        MemoryDep('buf46', 28, {}, None),
        MemoryDep('buf46', 29, {}, None),
        MemoryDep('buf47', 0, {}, None)]
op48.met_dependencies = [MemoryDep('full_default', c0, {c0: 100}, None)]
op48.outputs = [
    buf48: ComputedBuffer
    buf48.layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
    buf48.users = [NodeUser(node=SchedulerNode(name='op49'), can_inplace=True, is_weak=False)]
]
op48.group.device = cuda:0
op48.group.iteration = (100, 1)
op48.sizes = ([100], [])
buf44_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf45_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf47_layout = FixedLayout('cuda', torch.float32, size=[], stride=[])
full_default_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf46_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf46_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf46_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf48_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
class op48_loop_body:
    var_ranges = {z0: 100}
    index0 = z0
    index1 = 0
    index2 = 29
    index3 = 28
    index4 = 27
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf44', get_index)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('buf45', get_index_1)
        add = ops.add(load, load_1)
        get_index_2 = self.get_index('index0')
        index_expr = ops.index_expr(get_index_2, torch.int32)
        constant = ops.constant(30, torch.int32)
        eq = ops.eq(index_expr, constant)
        get_index_3 = self.get_index('index1')
        load_2 = ops.load('buf47', get_index_3)
        get_index_4 = self.get_index('index0')
        load_3 = ops.load('full_default', get_index_4)
        where = ops.where(eq, load_2, load_3)
        add_1 = ops.add(add, where)
        get_index_5 = self.get_index('index0')
        index_expr_1 = ops.index_expr(get_index_5, torch.int32)
        constant_1 = ops.constant(29, torch.int32)
        eq_1 = ops.eq(index_expr_1, constant_1)
        get_index_6 = self.get_index('index2')
        load_4 = ops.load('buf46', get_index_6)
        constant_2 = ops.constant(2.0, torch.float32)
        mul = ops.mul(load_4, constant_2)
        get_index_7 = self.get_index('index0')
        load_5 = ops.load('full_default', get_index_7)
        where_1 = ops.where(eq_1, mul, load_5)
        add_2 = ops.add(add_1, where_1)
        get_index_8 = self.get_index('index0')
        index_expr_2 = ops.index_expr(get_index_8, torch.int32)
        constant_3 = ops.constant(28, torch.int32)
        eq_2 = ops.eq(index_expr_2, constant_3)
        constant_4 = ops.constant(28, torch.int32)
        constant_5 = ops.constant(29, torch.int32)
        eq_3 = ops.eq(constant_4, constant_5)
        get_index_9 = self.get_index('index3')
        load_6 = ops.load('buf46', get_index_9)
        constant_6 = ops.constant(0.0, torch.float32)
        where_2 = ops.where(eq_3, constant_6, load_6)
        constant_7 = ops.constant(2.0, torch.float32)
        mul_1 = ops.mul(where_2, constant_7)
        get_index_10 = self.get_index('index0')
        load_7 = ops.load('full_default', get_index_10)
        where_3 = ops.where(eq_2, mul_1, load_7)
        add_3 = ops.add(add_2, where_3)
        get_index_11 = self.get_index('index0')
        index_expr_3 = ops.index_expr(get_index_11, torch.int32)
        constant_8 = ops.constant(27, torch.int32)
        eq_4 = ops.eq(index_expr_3, constant_8)
        constant_9 = ops.constant(27, torch.int32)
        constant_10 = ops.constant(28, torch.int32)
        eq_5 = ops.eq(constant_9, constant_10)
        constant_11 = ops.constant(27, torch.int32)
        constant_12 = ops.constant(29, torch.int32)
        eq_6 = ops.eq(constant_11, constant_12)
        get_index_12 = self.get_index('index4')
        load_8 = ops.load('buf46', get_index_12)
        constant_13 = ops.constant(0.0, torch.float32)
        where_4 = ops.where(eq_6, constant_13, load_8)
        constant_14 = ops.constant(0.0, torch.float32)
        where_5 = ops.where(eq_5, constant_14, where_4)
        constant_15 = ops.constant(2.0, torch.float32)
        mul_2 = ops.mul(where_5, constant_15)
        get_index_13 = self.get_index('index0')
        load_9 = ops.load('full_default', get_index_13)
        where_6 = ops.where(eq_4, mul_2, load_9)
        add_4 = ops.add(add_3, where_6)
        get_index_14 = self.get_index('index0')
        store = ops.store('buf48', get_index_14, add_4, None)
        return store
op48 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[128], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, multi_processor_count=20), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_out_ptr0'], 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': '712B1D69F892A891D8FFA5075DCAB47CFF4E132D88BFC66744701CEAE226F127', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, xnumel, XBLOCK : tl.constexpr):
        xnumel = 100
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp0 = tl.load(in_out_ptr0 + (x0), xmask)
        tmp1 = tl.load(in_ptr0 + (x0), xmask)
        tmp6 = tl.load(in_ptr1 + (0))
        tmp7 = tl.broadcast_to(tmp6, [XBLOCK])
        tmp8 = tl.load(in_ptr2 + (x0), xmask)
        tmp13 = tl.load(in_ptr3 + (29))
        tmp14 = tl.broadcast_to(tmp13, [XBLOCK])
        tmp22 = tl.load(in_ptr3 + (28))
        tmp23 = tl.broadcast_to(tmp22, [XBLOCK])
        tmp33 = tl.load(in_ptr3 + (27))
        tmp34 = tl.broadcast_to(tmp33, [XBLOCK])
        tmp2 = tmp0 + tmp1
        tmp3 = x0
        tmp4 = tl.full([1], 30, tl.int32)
        tmp5 = tmp3 == tmp4
        tmp9 = tl.where(tmp5, tmp7, tmp8)
        tmp10 = tmp2 + tmp9
        tmp11 = tl.full([1], 29, tl.int32)
        tmp12 = tmp3 == tmp11
        tmp15 = 2.0
        tmp16 = tmp14 * tmp15
        tmp17 = tl.where(tmp12, tmp16, tmp8)
        tmp18 = tmp10 + tmp17
        tmp19 = tl.full([1], 28, tl.int32)
        tmp20 = tmp3 == tmp19
        tmp21 = tmp19 == tmp11
        tmp24 = 0.0
        tmp25 = tl.where(tmp21, tmp24, tmp23)
        tmp26 = tmp25 * tmp15
        tmp27 = tl.where(tmp20, tmp26, tmp8)
        tmp28 = tmp18 + tmp27
        tmp29 = tl.full([1], 27, tl.int32)
        tmp30 = tmp3 == tmp29
        tmp31 = tmp29 == tmp19
        tmp32 = tmp29 == tmp11
        tmp35 = tl.where(tmp32, tmp24, tmp34)
        tmp36 = tl.where(tmp31, tmp24, tmp35)
        tmp37 = tmp36 * tmp15
        tmp38 = tl.where(tmp30, tmp37, tmp8)
        tmp39 = tmp28 + tmp38
        tl.store(in_out_ptr0 + (x0), tmp39, xmask)


op49: SchedulerNode(ComputedBuffer)
op49.writes = [MemoryDep('buf49', c0, {c0: 100}, None)]
op49.unmet_dependencies = 
    [   MemoryDep('buf46', 25, {}, None),
        MemoryDep('buf46', 26, {}, None),
        MemoryDep('buf48', c0, {c0: 100}, None)]
op49.met_dependencies = [MemoryDep('full_default', c0, {c0: 100}, None)]
op49.outputs = [
    buf49: ComputedBuffer
    buf49.layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
    buf49.users = [NodeUser(node=SchedulerNode(name='op50'), can_inplace=True, is_weak=False)]
]
op49.group.device = cuda:0
op49.group.iteration = (100, 1)
op49.sizes = ([100], [])
buf48_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf46_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
full_default_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf46_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf49_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
class op49_loop_body:
    var_ranges = {z0: 100}
    index0 = z0
    index1 = 26
    index2 = 25
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf48', get_index)
        get_index_1 = self.get_index('index0')
        index_expr = ops.index_expr(get_index_1, torch.int32)
        constant = ops.constant(26, torch.int32)
        eq = ops.eq(index_expr, constant)
        constant_1 = ops.constant(26, torch.int32)
        constant_2 = ops.constant(27, torch.int32)
        eq_1 = ops.eq(constant_1, constant_2)
        constant_3 = ops.constant(26, torch.int32)
        constant_4 = ops.constant(28, torch.int32)
        eq_2 = ops.eq(constant_3, constant_4)
        constant_5 = ops.constant(26, torch.int32)
        constant_6 = ops.constant(29, torch.int32)
        eq_3 = ops.eq(constant_5, constant_6)
        get_index_2 = self.get_index('index1')
        load_1 = ops.load('buf46', get_index_2)
        constant_7 = ops.constant(0.0, torch.float32)
        where = ops.where(eq_3, constant_7, load_1)
        constant_8 = ops.constant(0.0, torch.float32)
        where_1 = ops.where(eq_2, constant_8, where)
        constant_9 = ops.constant(0.0, torch.float32)
        where_2 = ops.where(eq_1, constant_9, where_1)
        constant_10 = ops.constant(2.0, torch.float32)
        mul = ops.mul(where_2, constant_10)
        get_index_3 = self.get_index('index0')
        load_2 = ops.load('full_default', get_index_3)
        where_3 = ops.where(eq, mul, load_2)
        add = ops.add(load, where_3)
        get_index_4 = self.get_index('index0')
        index_expr_1 = ops.index_expr(get_index_4, torch.int32)
        constant_11 = ops.constant(25, torch.int32)
        eq_4 = ops.eq(index_expr_1, constant_11)
        constant_12 = ops.constant(25, torch.int32)
        constant_13 = ops.constant(26, torch.int32)
        eq_5 = ops.eq(constant_12, constant_13)
        constant_14 = ops.constant(25, torch.int32)
        constant_15 = ops.constant(27, torch.int32)
        eq_6 = ops.eq(constant_14, constant_15)
        constant_16 = ops.constant(25, torch.int32)
        constant_17 = ops.constant(28, torch.int32)
        eq_7 = ops.eq(constant_16, constant_17)
        constant_18 = ops.constant(25, torch.int32)
        constant_19 = ops.constant(29, torch.int32)
        eq_8 = ops.eq(constant_18, constant_19)
        get_index_5 = self.get_index('index2')
        load_3 = ops.load('buf46', get_index_5)
        constant_20 = ops.constant(0.0, torch.float32)
        where_4 = ops.where(eq_8, constant_20, load_3)
        constant_21 = ops.constant(0.0, torch.float32)
        where_5 = ops.where(eq_7, constant_21, where_4)
        constant_22 = ops.constant(0.0, torch.float32)
        where_6 = ops.where(eq_6, constant_22, where_5)
        constant_23 = ops.constant(0.0, torch.float32)
        where_7 = ops.where(eq_5, constant_23, where_6)
        constant_24 = ops.constant(2.0, torch.float32)
        mul_1 = ops.mul(where_7, constant_24)
        get_index_6 = self.get_index('index0')
        load_4 = ops.load('full_default', get_index_6)
        where_8 = ops.where(eq_4, mul_1, load_4)
        add_1 = ops.add(add, where_8)
        get_index_7 = self.get_index('index0')
        store = ops.store('buf49', get_index_7, add_1, None)
        return store
op49 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[128], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, multi_processor_count=20), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_out_ptr0'], 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': '712B1D69F892A891D8FFA5075DCAB47CFF4E132D88BFC66744701CEAE226F127', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_out_ptr0, in_ptr0, in_ptr1, xnumel, XBLOCK : tl.constexpr):
        xnumel = 100
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp0 = tl.load(in_out_ptr0 + (x0), xmask)
        tmp10 = tl.load(in_ptr0 + (26))
        tmp11 = tl.broadcast_to(tmp10, [XBLOCK])
        tmp18 = tl.load(in_ptr1 + (x0), xmask)
        tmp27 = tl.load(in_ptr0 + (25))
        tmp28 = tl.broadcast_to(tmp27, [XBLOCK])
        tmp1 = x0
        tmp2 = tl.full([1], 26, tl.int32)
        tmp3 = tmp1 == tmp2
        tmp4 = tl.full([1], 27, tl.int32)
        tmp5 = tmp2 == tmp4
        tmp6 = tl.full([1], 28, tl.int32)
        tmp7 = tmp2 == tmp6
        tmp8 = tl.full([1], 29, tl.int32)
        tmp9 = tmp2 == tmp8
        tmp12 = 0.0
        tmp13 = tl.where(tmp9, tmp12, tmp11)
        tmp14 = tl.where(tmp7, tmp12, tmp13)
        tmp15 = tl.where(tmp5, tmp12, tmp14)
        tmp16 = 2.0
        tmp17 = tmp15 * tmp16
        tmp19 = tl.where(tmp3, tmp17, tmp18)
        tmp20 = tmp0 + tmp19
        tmp21 = tl.full([1], 25, tl.int32)
        tmp22 = tmp1 == tmp21
        tmp23 = tmp21 == tmp2
        tmp24 = tmp21 == tmp4
        tmp25 = tmp21 == tmp6
        tmp26 = tmp21 == tmp8
        tmp29 = tl.where(tmp26, tmp12, tmp28)
        tmp30 = tl.where(tmp25, tmp12, tmp29)
        tmp31 = tl.where(tmp24, tmp12, tmp30)
        tmp32 = tl.where(tmp23, tmp12, tmp31)
        tmp33 = tmp32 * tmp16
        tmp34 = tl.where(tmp22, tmp33, tmp18)
        tmp35 = tmp20 + tmp34
        tl.store(in_out_ptr0 + (x0), tmp35, xmask)


op50: SchedulerNode(ComputedBuffer)
op50.writes = [MemoryDep('buf50', c0, {c0: 100}, None)]
op50.unmet_dependencies = 
    [   MemoryDep('buf46', 23, {}, None),
        MemoryDep('buf46', 24, {}, None),
        MemoryDep('buf49', c0, {c0: 100}, None)]
op50.met_dependencies = [MemoryDep('full_default', c0, {c0: 100}, None)]
op50.outputs = [
    buf50: ComputedBuffer
    buf50.layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
    buf50.users = [NodeUser(node=SchedulerNode(name='op51'), can_inplace=True, is_weak=False)]
]
op50.group.device = cuda:0
op50.group.iteration = (100, 1)
op50.sizes = ([100], [])
buf49_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf46_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
full_default_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf46_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf50_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
class op50_loop_body:
    var_ranges = {z0: 100}
    index0 = z0
    index1 = 24
    index2 = 23
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf49', get_index)
        get_index_1 = self.get_index('index0')
        index_expr = ops.index_expr(get_index_1, torch.int32)
        constant = ops.constant(24, torch.int32)
        eq = ops.eq(index_expr, constant)
        constant_1 = ops.constant(24, torch.int32)
        constant_2 = ops.constant(25, torch.int32)
        eq_1 = ops.eq(constant_1, constant_2)
        constant_3 = ops.constant(24, torch.int32)
        constant_4 = ops.constant(26, torch.int32)
        eq_2 = ops.eq(constant_3, constant_4)
        constant_5 = ops.constant(24, torch.int32)
        constant_6 = ops.constant(27, torch.int32)
        eq_3 = ops.eq(constant_5, constant_6)
        constant_7 = ops.constant(24, torch.int32)
        constant_8 = ops.constant(28, torch.int32)
        eq_4 = ops.eq(constant_7, constant_8)
        constant_9 = ops.constant(24, torch.int32)
        constant_10 = ops.constant(29, torch.int32)
        eq_5 = ops.eq(constant_9, constant_10)
        get_index_2 = self.get_index('index1')
        load_1 = ops.load('buf46', get_index_2)
        constant_11 = ops.constant(0.0, torch.float32)
        where = ops.where(eq_5, constant_11, load_1)
        constant_12 = ops.constant(0.0, torch.float32)
        where_1 = ops.where(eq_4, constant_12, where)
        constant_13 = ops.constant(0.0, torch.float32)
        where_2 = ops.where(eq_3, constant_13, where_1)
        constant_14 = ops.constant(0.0, torch.float32)
        where_3 = ops.where(eq_2, constant_14, where_2)
        constant_15 = ops.constant(0.0, torch.float32)
        where_4 = ops.where(eq_1, constant_15, where_3)
        constant_16 = ops.constant(2.0, torch.float32)
        mul = ops.mul(where_4, constant_16)
        get_index_3 = self.get_index('index0')
        load_2 = ops.load('full_default', get_index_3)
        where_5 = ops.where(eq, mul, load_2)
        add = ops.add(load, where_5)
        get_index_4 = self.get_index('index0')
        index_expr_1 = ops.index_expr(get_index_4, torch.int32)
        constant_17 = ops.constant(23, torch.int32)
        eq_6 = ops.eq(index_expr_1, constant_17)
        constant_18 = ops.constant(23, torch.int32)
        constant_19 = ops.constant(24, torch.int32)
        eq_7 = ops.eq(constant_18, constant_19)
        constant_20 = ops.constant(23, torch.int32)
        constant_21 = ops.constant(25, torch.int32)
        eq_8 = ops.eq(constant_20, constant_21)
        constant_22 = ops.constant(23, torch.int32)
        constant_23 = ops.constant(26, torch.int32)
        eq_9 = ops.eq(constant_22, constant_23)
        constant_24 = ops.constant(23, torch.int32)
        constant_25 = ops.constant(27, torch.int32)
        eq_10 = ops.eq(constant_24, constant_25)
        constant_26 = ops.constant(23, torch.int32)
        constant_27 = ops.constant(28, torch.int32)
        eq_11 = ops.eq(constant_26, constant_27)
        constant_28 = ops.constant(23, torch.int32)
        constant_29 = ops.constant(29, torch.int32)
        eq_12 = ops.eq(constant_28, constant_29)
        get_index_5 = self.get_index('index2')
        load_3 = ops.load('buf46', get_index_5)
        constant_30 = ops.constant(0.0, torch.float32)
        where_6 = ops.where(eq_12, constant_30, load_3)
        constant_31 = ops.constant(0.0, torch.float32)
        where_7 = ops.where(eq_11, constant_31, where_6)
        constant_32 = ops.constant(0.0, torch.float32)
        where_8 = ops.where(eq_10, constant_32, where_7)
        constant_33 = ops.constant(0.0, torch.float32)
        where_9 = ops.where(eq_9, constant_33, where_8)
        constant_34 = ops.constant(0.0, torch.float32)
        where_10 = ops.where(eq_8, constant_34, where_9)
        constant_35 = ops.constant(0.0, torch.float32)
        where_11 = ops.where(eq_7, constant_35, where_10)
        constant_36 = ops.constant(2.0, torch.float32)
        mul_1 = ops.mul(where_11, constant_36)
        get_index_6 = self.get_index('index0')
        load_4 = ops.load('full_default', get_index_6)
        where_12 = ops.where(eq_6, mul_1, load_4)
        add_1 = ops.add(add, where_12)
        get_index_7 = self.get_index('index0')
        store = ops.store('buf50', get_index_7, add_1, None)
        return store
op50 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[128], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, multi_processor_count=20), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_out_ptr0'], 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': '712B1D69F892A891D8FFA5075DCAB47CFF4E132D88BFC66744701CEAE226F127', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_out_ptr0, in_ptr0, in_ptr1, xnumel, XBLOCK : tl.constexpr):
        xnumel = 100
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp0 = tl.load(in_out_ptr0 + (x0), xmask)
        tmp14 = tl.load(in_ptr0 + (24))
        tmp15 = tl.broadcast_to(tmp14, [XBLOCK])
        tmp24 = tl.load(in_ptr1 + (x0), xmask)
        tmp35 = tl.load(in_ptr0 + (23))
        tmp36 = tl.broadcast_to(tmp35, [XBLOCK])
        tmp1 = x0
        tmp2 = tl.full([1], 24, tl.int32)
        tmp3 = tmp1 == tmp2
        tmp4 = tl.full([1], 25, tl.int32)
        tmp5 = tmp2 == tmp4
        tmp6 = tl.full([1], 26, tl.int32)
        tmp7 = tmp2 == tmp6
        tmp8 = tl.full([1], 27, tl.int32)
        tmp9 = tmp2 == tmp8
        tmp10 = tl.full([1], 28, tl.int32)
        tmp11 = tmp2 == tmp10
        tmp12 = tl.full([1], 29, tl.int32)
        tmp13 = tmp2 == tmp12
        tmp16 = 0.0
        tmp17 = tl.where(tmp13, tmp16, tmp15)
        tmp18 = tl.where(tmp11, tmp16, tmp17)
        tmp19 = tl.where(tmp9, tmp16, tmp18)
        tmp20 = tl.where(tmp7, tmp16, tmp19)
        tmp21 = tl.where(tmp5, tmp16, tmp20)
        tmp22 = 2.0
        tmp23 = tmp21 * tmp22
        tmp25 = tl.where(tmp3, tmp23, tmp24)
        tmp26 = tmp0 + tmp25
        tmp27 = tl.full([1], 23, tl.int32)
        tmp28 = tmp1 == tmp27
        tmp29 = tmp27 == tmp2
        tmp30 = tmp27 == tmp4
        tmp31 = tmp27 == tmp6
        tmp32 = tmp27 == tmp8
        tmp33 = tmp27 == tmp10
        tmp34 = tmp27 == tmp12
        tmp37 = tl.where(tmp34, tmp16, tmp36)
        tmp38 = tl.where(tmp33, tmp16, tmp37)
        tmp39 = tl.where(tmp32, tmp16, tmp38)
        tmp40 = tl.where(tmp31, tmp16, tmp39)
        tmp41 = tl.where(tmp30, tmp16, tmp40)
        tmp42 = tl.where(tmp29, tmp16, tmp41)
        tmp43 = tmp42 * tmp22
        tmp44 = tl.where(tmp28, tmp43, tmp24)
        tmp45 = tmp26 + tmp44
        tl.store(in_out_ptr0 + (x0), tmp45, xmask)


op51: SchedulerNode(ComputedBuffer)
op51.writes = [MemoryDep('buf51', c0, {c0: 100}, None)]
op51.unmet_dependencies = [MemoryDep('buf46', 22, {}, None), MemoryDep('buf50', c0, {c0: 100}, None)]
op51.met_dependencies = [MemoryDep('full_default', c0, {c0: 100}, None)]
op51.outputs = [
    buf51: ComputedBuffer
    buf51.layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
    buf51.users = [NodeUser(node=SchedulerNode(name='op55'), can_inplace=True, is_weak=False)]
]
op51.group.device = cuda:0
op51.group.iteration = (100, 1)
op51.sizes = ([100], [])
buf50_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf46_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
full_default_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf51_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
class op51_loop_body:
    var_ranges = {z0: 100}
    index0 = z0
    index1 = 22
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf50', get_index)
        get_index_1 = self.get_index('index0')
        index_expr = ops.index_expr(get_index_1, torch.int32)
        constant = ops.constant(22, torch.int32)
        eq = ops.eq(index_expr, constant)
        constant_1 = ops.constant(22, torch.int32)
        constant_2 = ops.constant(23, torch.int32)
        eq_1 = ops.eq(constant_1, constant_2)
        constant_3 = ops.constant(22, torch.int32)
        constant_4 = ops.constant(24, torch.int32)
        eq_2 = ops.eq(constant_3, constant_4)
        constant_5 = ops.constant(22, torch.int32)
        constant_6 = ops.constant(25, torch.int32)
        eq_3 = ops.eq(constant_5, constant_6)
        constant_7 = ops.constant(22, torch.int32)
        constant_8 = ops.constant(26, torch.int32)
        eq_4 = ops.eq(constant_7, constant_8)
        constant_9 = ops.constant(22, torch.int32)
        constant_10 = ops.constant(27, torch.int32)
        eq_5 = ops.eq(constant_9, constant_10)
        constant_11 = ops.constant(22, torch.int32)
        constant_12 = ops.constant(28, torch.int32)
        eq_6 = ops.eq(constant_11, constant_12)
        constant_13 = ops.constant(22, torch.int32)
        constant_14 = ops.constant(29, torch.int32)
        eq_7 = ops.eq(constant_13, constant_14)
        get_index_2 = self.get_index('index1')
        load_1 = ops.load('buf46', get_index_2)
        constant_15 = ops.constant(0.0, torch.float32)
        where = ops.where(eq_7, constant_15, load_1)
        constant_16 = ops.constant(0.0, torch.float32)
        where_1 = ops.where(eq_6, constant_16, where)
        constant_17 = ops.constant(0.0, torch.float32)
        where_2 = ops.where(eq_5, constant_17, where_1)
        constant_18 = ops.constant(0.0, torch.float32)
        where_3 = ops.where(eq_4, constant_18, where_2)
        constant_19 = ops.constant(0.0, torch.float32)
        where_4 = ops.where(eq_3, constant_19, where_3)
        constant_20 = ops.constant(0.0, torch.float32)
        where_5 = ops.where(eq_2, constant_20, where_4)
        constant_21 = ops.constant(0.0, torch.float32)
        where_6 = ops.where(eq_1, constant_21, where_5)
        constant_22 = ops.constant(2.0, torch.float32)
        mul = ops.mul(where_6, constant_22)
        get_index_3 = self.get_index('index0')
        load_2 = ops.load('full_default', get_index_3)
        where_7 = ops.where(eq, mul, load_2)
        add = ops.add(load, where_7)
        get_index_4 = self.get_index('index0')
        store = ops.store('buf51', get_index_4, add, None)
        return store
op51 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[128], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, multi_processor_count=20), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_out_ptr0'], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 0, 'backend_hash': '712B1D69F892A891D8FFA5075DCAB47CFF4E132D88BFC66744701CEAE226F127', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_out_ptr0, in_ptr0, in_ptr1, xnumel, XBLOCK : tl.constexpr):
        xnumel = 100
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp0 = tl.load(in_out_ptr0 + (x0), xmask)
        tmp18 = tl.load(in_ptr0 + (22))
        tmp19 = tl.broadcast_to(tmp18, [XBLOCK])
        tmp30 = tl.load(in_ptr1 + (x0), xmask)
        tmp1 = x0
        tmp2 = tl.full([1], 22, tl.int32)
        tmp3 = tmp1 == tmp2
        tmp4 = tl.full([1], 23, tl.int32)
        tmp5 = tmp2 == tmp4
        tmp6 = tl.full([1], 24, tl.int32)
        tmp7 = tmp2 == tmp6
        tmp8 = tl.full([1], 25, tl.int32)
        tmp9 = tmp2 == tmp8
        tmp10 = tl.full([1], 26, tl.int32)
        tmp11 = tmp2 == tmp10
        tmp12 = tl.full([1], 27, tl.int32)
        tmp13 = tmp2 == tmp12
        tmp14 = tl.full([1], 28, tl.int32)
        tmp15 = tmp2 == tmp14
        tmp16 = tl.full([1], 29, tl.int32)
        tmp17 = tmp2 == tmp16
        tmp20 = 0.0
        tmp21 = tl.where(tmp17, tmp20, tmp19)
        tmp22 = tl.where(tmp15, tmp20, tmp21)
        tmp23 = tl.where(tmp13, tmp20, tmp22)
        tmp24 = tl.where(tmp11, tmp20, tmp23)
        tmp25 = tl.where(tmp9, tmp20, tmp24)
        tmp26 = tl.where(tmp7, tmp20, tmp25)
        tmp27 = tl.where(tmp5, tmp20, tmp26)
        tmp28 = 2.0
        tmp29 = tmp27 * tmp28
        tmp31 = tl.where(tmp3, tmp29, tmp30)
        tmp32 = tmp0 + tmp31
        tl.store(in_out_ptr0 + (x0), tmp32, xmask)


op52: SchedulerNode(ComputedBuffer)
op52.writes = [MemoryDep('buf52', c0, {c0: 100}, None)]
op52.unmet_dependencies = [MemoryDep('buf46', 21, {}, None)]
op52.met_dependencies = [MemoryDep('full_default', c0, {c0: 100}, None)]
op52.outputs = [
    buf52: ComputedBuffer
    buf52.layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
    buf52.users = [NodeUser(node=SchedulerNode(name='op55'), can_inplace=True, is_weak=False)]
]
op52.group.device = cuda:0
op52.group.iteration = (100, 1)
op52.sizes = ([100], [])
buf46_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
full_default_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf52_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
class op52_loop_body:
    var_ranges = {z0: 100}
    index0 = z0
    index1 = 21
    def body(self, ops):
        get_index = self.get_index('index0')
        index_expr = ops.index_expr(get_index, torch.int32)
        constant = ops.constant(21, torch.int32)
        eq = ops.eq(index_expr, constant)
        constant_1 = ops.constant(21, torch.int32)
        constant_2 = ops.constant(22, torch.int32)
        eq_1 = ops.eq(constant_1, constant_2)
        constant_3 = ops.constant(21, torch.int32)
        constant_4 = ops.constant(23, torch.int32)
        eq_2 = ops.eq(constant_3, constant_4)
        constant_5 = ops.constant(21, torch.int32)
        constant_6 = ops.constant(24, torch.int32)
        eq_3 = ops.eq(constant_5, constant_6)
        constant_7 = ops.constant(21, torch.int32)
        constant_8 = ops.constant(25, torch.int32)
        eq_4 = ops.eq(constant_7, constant_8)
        constant_9 = ops.constant(21, torch.int32)
        constant_10 = ops.constant(26, torch.int32)
        eq_5 = ops.eq(constant_9, constant_10)
        constant_11 = ops.constant(21, torch.int32)
        constant_12 = ops.constant(27, torch.int32)
        eq_6 = ops.eq(constant_11, constant_12)
        constant_13 = ops.constant(21, torch.int32)
        constant_14 = ops.constant(28, torch.int32)
        eq_7 = ops.eq(constant_13, constant_14)
        constant_15 = ops.constant(21, torch.int32)
        constant_16 = ops.constant(29, torch.int32)
        eq_8 = ops.eq(constant_15, constant_16)
        get_index_1 = self.get_index('index1')
        load = ops.load('buf46', get_index_1)
        constant_17 = ops.constant(0.0, torch.float32)
        where = ops.where(eq_8, constant_17, load)
        constant_18 = ops.constant(0.0, torch.float32)
        where_1 = ops.where(eq_7, constant_18, where)
        constant_19 = ops.constant(0.0, torch.float32)
        where_2 = ops.where(eq_6, constant_19, where_1)
        constant_20 = ops.constant(0.0, torch.float32)
        where_3 = ops.where(eq_5, constant_20, where_2)
        constant_21 = ops.constant(0.0, torch.float32)
        where_4 = ops.where(eq_4, constant_21, where_3)
        constant_22 = ops.constant(0.0, torch.float32)
        where_5 = ops.where(eq_3, constant_22, where_4)
        constant_23 = ops.constant(0.0, torch.float32)
        where_6 = ops.where(eq_2, constant_23, where_5)
        constant_24 = ops.constant(0.0, torch.float32)
        where_7 = ops.where(eq_1, constant_24, where_6)
        constant_25 = ops.constant(2.0, torch.float32)
        mul = ops.mul(where_7, constant_25)
        get_index_2 = self.get_index('index0')
        load_1 = ops.load('full_default', get_index_2)
        where_8 = ops.where(eq, mul, load_1)
        get_index_3 = self.get_index('index0')
        store = ops.store('buf52', get_index_3, where_8, None)
        return store
op52 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[128], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, multi_processor_count=20), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '712B1D69F892A891D8FFA5075DCAB47CFF4E132D88BFC66744701CEAE226F127', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 100
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp19 = tl.load(in_ptr0 + (21))
        tmp20 = tl.broadcast_to(tmp19, [XBLOCK])
        tmp32 = tl.load(in_ptr1 + (x0), xmask)
        tmp0 = x0
        tmp1 = tl.full([1], 21, tl.int32)
        tmp2 = tmp0 == tmp1
        tmp3 = tl.full([1], 22, tl.int32)
        tmp4 = tmp1 == tmp3
        tmp5 = tl.full([1], 23, tl.int32)
        tmp6 = tmp1 == tmp5
        tmp7 = tl.full([1], 24, tl.int32)
        tmp8 = tmp1 == tmp7
        tmp9 = tl.full([1], 25, tl.int32)
        tmp10 = tmp1 == tmp9
        tmp11 = tl.full([1], 26, tl.int32)
        tmp12 = tmp1 == tmp11
        tmp13 = tl.full([1], 27, tl.int32)
        tmp14 = tmp1 == tmp13
        tmp15 = tl.full([1], 28, tl.int32)
        tmp16 = tmp1 == tmp15
        tmp17 = tl.full([1], 29, tl.int32)
        tmp18 = tmp1 == tmp17
        tmp21 = 0.0
        tmp22 = tl.where(tmp18, tmp21, tmp20)
        tmp23 = tl.where(tmp16, tmp21, tmp22)
        tmp24 = tl.where(tmp14, tmp21, tmp23)
        tmp25 = tl.where(tmp12, tmp21, tmp24)
        tmp26 = tl.where(tmp10, tmp21, tmp25)
        tmp27 = tl.where(tmp8, tmp21, tmp26)
        tmp28 = tl.where(tmp6, tmp21, tmp27)
        tmp29 = tl.where(tmp4, tmp21, tmp28)
        tmp30 = 2.0
        tmp31 = tmp29 * tmp30
        tmp33 = tl.where(tmp2, tmp31, tmp32)
        tl.store(out_ptr0 + (x0), tmp33, xmask)


op53: SchedulerNode(ComputedBuffer)
op53.writes = [MemoryDep('buf53', c0, {c0: 100}, None)]
op53.unmet_dependencies = [MemoryDep('buf46', c0, {c0: 100}, None)]
op53.met_dependencies = []
op53.outputs = [
    buf53: ComputedBuffer
    buf53.layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
    buf53.users = [
        NodeUser(node=SchedulerNode(name='op55'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op56'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op57'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op58'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op59'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op60'), can_inplace=True, is_weak=False),
        NodeUser(node=SchedulerNode(name='op61'), can_inplace=False, is_weak=False),
    ]
]
op53.group.device = cuda:0
op53.group.iteration = (100, 1)
op53.sizes = ([100], [])
buf46_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf53_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
class op53_loop_body:
    var_ranges = {z0: 100}
    index0 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        index_expr = ops.index_expr(get_index, torch.int32)
        constant = ops.constant(20, torch.int32)
        eq = ops.eq(index_expr, constant)
        get_index_1 = self.get_index('index0')
        index_expr_1 = ops.index_expr(get_index_1, torch.int32)
        constant_1 = ops.constant(21, torch.int32)
        eq_1 = ops.eq(index_expr_1, constant_1)
        get_index_2 = self.get_index('index0')
        index_expr_2 = ops.index_expr(get_index_2, torch.int32)
        constant_2 = ops.constant(22, torch.int32)
        eq_2 = ops.eq(index_expr_2, constant_2)
        get_index_3 = self.get_index('index0')
        index_expr_3 = ops.index_expr(get_index_3, torch.int32)
        constant_3 = ops.constant(23, torch.int32)
        eq_3 = ops.eq(index_expr_3, constant_3)
        get_index_4 = self.get_index('index0')
        index_expr_4 = ops.index_expr(get_index_4, torch.int32)
        constant_4 = ops.constant(24, torch.int32)
        eq_4 = ops.eq(index_expr_4, constant_4)
        get_index_5 = self.get_index('index0')
        index_expr_5 = ops.index_expr(get_index_5, torch.int32)
        constant_5 = ops.constant(25, torch.int32)
        eq_5 = ops.eq(index_expr_5, constant_5)
        get_index_6 = self.get_index('index0')
        index_expr_6 = ops.index_expr(get_index_6, torch.int32)
        constant_6 = ops.constant(26, torch.int32)
        eq_6 = ops.eq(index_expr_6, constant_6)
        get_index_7 = self.get_index('index0')
        index_expr_7 = ops.index_expr(get_index_7, torch.int32)
        constant_7 = ops.constant(27, torch.int32)
        eq_7 = ops.eq(index_expr_7, constant_7)
        get_index_8 = self.get_index('index0')
        index_expr_8 = ops.index_expr(get_index_8, torch.int32)
        constant_8 = ops.constant(28, torch.int32)
        eq_8 = ops.eq(index_expr_8, constant_8)
        get_index_9 = self.get_index('index0')
        index_expr_9 = ops.index_expr(get_index_9, torch.int32)
        constant_9 = ops.constant(29, torch.int32)
        eq_9 = ops.eq(index_expr_9, constant_9)
        get_index_10 = self.get_index('index0')
        load = ops.load('buf46', get_index_10)
        constant_10 = ops.constant(0.0, torch.float32)
        where = ops.where(eq_9, constant_10, load)
        constant_11 = ops.constant(0.0, torch.float32)
        where_1 = ops.where(eq_8, constant_11, where)
        constant_12 = ops.constant(0.0, torch.float32)
        where_2 = ops.where(eq_7, constant_12, where_1)
        constant_13 = ops.constant(0.0, torch.float32)
        where_3 = ops.where(eq_6, constant_13, where_2)
        constant_14 = ops.constant(0.0, torch.float32)
        where_4 = ops.where(eq_5, constant_14, where_3)
        constant_15 = ops.constant(0.0, torch.float32)
        where_5 = ops.where(eq_4, constant_15, where_4)
        constant_16 = ops.constant(0.0, torch.float32)
        where_6 = ops.where(eq_3, constant_16, where_5)
        constant_17 = ops.constant(0.0, torch.float32)
        where_7 = ops.where(eq_2, constant_17, where_6)
        constant_18 = ops.constant(0.0, torch.float32)
        where_8 = ops.where(eq_1, constant_18, where_7)
        constant_19 = ops.constant(0.0, torch.float32)
        where_9 = ops.where(eq, constant_19, where_8)
        get_index_11 = self.get_index('index0')
        store = ops.store('buf53', get_index_11, where_9, None)
        return store
op53 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[128], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, multi_processor_count=20), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '712B1D69F892A891D8FFA5075DCAB47CFF4E132D88BFC66744701CEAE226F127', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 100
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp21 = tl.load(in_ptr0 + (x0), xmask)
        tmp0 = x0
        tmp1 = tl.full([1], 20, tl.int32)
        tmp2 = tmp0 == tmp1
        tmp3 = tl.full([1], 21, tl.int32)
        tmp4 = tmp0 == tmp3
        tmp5 = tl.full([1], 22, tl.int32)
        tmp6 = tmp0 == tmp5
        tmp7 = tl.full([1], 23, tl.int32)
        tmp8 = tmp0 == tmp7
        tmp9 = tl.full([1], 24, tl.int32)
        tmp10 = tmp0 == tmp9
        tmp11 = tl.full([1], 25, tl.int32)
        tmp12 = tmp0 == tmp11
        tmp13 = tl.full([1], 26, tl.int32)
        tmp14 = tmp0 == tmp13
        tmp15 = tl.full([1], 27, tl.int32)
        tmp16 = tmp0 == tmp15
        tmp17 = tl.full([1], 28, tl.int32)
        tmp18 = tmp0 == tmp17
        tmp19 = tl.full([1], 29, tl.int32)
        tmp20 = tmp0 == tmp19
        tmp22 = 0.0
        tmp23 = tl.where(tmp20, tmp22, tmp21)
        tmp24 = tl.where(tmp18, tmp22, tmp23)
        tmp25 = tl.where(tmp16, tmp22, tmp24)
        tmp26 = tl.where(tmp14, tmp22, tmp25)
        tmp27 = tl.where(tmp12, tmp22, tmp26)
        tmp28 = tl.where(tmp10, tmp22, tmp27)
        tmp29 = tl.where(tmp8, tmp22, tmp28)
        tmp30 = tl.where(tmp6, tmp22, tmp29)
        tmp31 = tl.where(tmp4, tmp22, tmp30)
        tmp32 = tl.where(tmp2, tmp22, tmp31)
        tl.store(out_ptr0 + (x0), tmp32, xmask)


op54: SchedulerNode(ComputedBuffer)
op54.writes = [MemoryDep('buf54', 0, {}, None)]
op54.unmet_dependencies = [MemoryDep('buf46', 20, {}, None)]
op54.met_dependencies = []
op54.outputs = [
    buf54: ComputedBuffer
    buf54.layout = FixedLayout('cuda', torch.float32, size=[], stride=[])
    buf54.users = [NodeUser(node=SchedulerNode(name='op55'), can_inplace=False, is_weak=False)]
]
op54.group.device = cuda:0
op54.group.iteration = (1, 1)
op54.sizes = ([], [])
buf46_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf54_layout = FixedLayout('cuda', torch.float32, size=[], stride=[])
class op54_loop_body:
    var_ranges = {}
    index0 = 20
    index1 = 0
    def body(self, ops):
        constant = ops.constant(20, torch.int32)
        constant_1 = ops.constant(21, torch.int32)
        eq = ops.eq(constant, constant_1)
        constant_2 = ops.constant(20, torch.int32)
        constant_3 = ops.constant(22, torch.int32)
        eq_1 = ops.eq(constant_2, constant_3)
        constant_4 = ops.constant(20, torch.int32)
        constant_5 = ops.constant(23, torch.int32)
        eq_2 = ops.eq(constant_4, constant_5)
        constant_6 = ops.constant(20, torch.int32)
        constant_7 = ops.constant(24, torch.int32)
        eq_3 = ops.eq(constant_6, constant_7)
        constant_8 = ops.constant(20, torch.int32)
        constant_9 = ops.constant(25, torch.int32)
        eq_4 = ops.eq(constant_8, constant_9)
        constant_10 = ops.constant(20, torch.int32)
        constant_11 = ops.constant(26, torch.int32)
        eq_5 = ops.eq(constant_10, constant_11)
        constant_12 = ops.constant(20, torch.int32)
        constant_13 = ops.constant(27, torch.int32)
        eq_6 = ops.eq(constant_12, constant_13)
        constant_14 = ops.constant(20, torch.int32)
        constant_15 = ops.constant(28, torch.int32)
        eq_7 = ops.eq(constant_14, constant_15)
        constant_16 = ops.constant(20, torch.int32)
        constant_17 = ops.constant(29, torch.int32)
        eq_8 = ops.eq(constant_16, constant_17)
        get_index = self.get_index('index0')
        load = ops.load('buf46', get_index)
        constant_18 = ops.constant(0.0, torch.float32)
        where = ops.where(eq_8, constant_18, load)
        constant_19 = ops.constant(0.0, torch.float32)
        where_1 = ops.where(eq_7, constant_19, where)
        constant_20 = ops.constant(0.0, torch.float32)
        where_2 = ops.where(eq_6, constant_20, where_1)
        constant_21 = ops.constant(0.0, torch.float32)
        where_3 = ops.where(eq_5, constant_21, where_2)
        constant_22 = ops.constant(0.0, torch.float32)
        where_4 = ops.where(eq_4, constant_22, where_3)
        constant_23 = ops.constant(0.0, torch.float32)
        where_5 = ops.where(eq_3, constant_23, where_4)
        constant_24 = ops.constant(0.0, torch.float32)
        where_6 = ops.where(eq_2, constant_24, where_5)
        constant_25 = ops.constant(0.0, torch.float32)
        where_7 = ops.where(eq_1, constant_25, where_6)
        constant_26 = ops.constant(0.0, torch.float32)
        where_8 = ops.where(eq, constant_26, where_7)
        constant_27 = ops.constant(2.0, torch.float32)
        mul = ops.mul(where_8, constant_27)
        get_index_1 = self.get_index('index1')
        store = ops.store('buf54', get_index_1, mul, None)
        return store
op54 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[1], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, multi_processor_count=20), 'constants': {2: 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(2,))]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '712B1D69F892A891D8FFA5075DCAB47CFF4E132D88BFC66744701CEAE226F127', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 1
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = tl.full([XBLOCK], True, tl.int1)
        tmp19 = tl.load(in_ptr0 + (20))
        tmp20 = tl.broadcast_to(tmp19, [XBLOCK])
        tmp0 = tl.full([1], 20, tl.int32)
        tmp1 = tl.full([1], 21, tl.int32)
        tmp2 = tmp0 == tmp1
        tmp3 = tl.full([1], 22, tl.int32)
        tmp4 = tmp0 == tmp3
        tmp5 = tl.full([1], 23, tl.int32)
        tmp6 = tmp0 == tmp5
        tmp7 = tl.full([1], 24, tl.int32)
        tmp8 = tmp0 == tmp7
        tmp9 = tl.full([1], 25, tl.int32)
        tmp10 = tmp0 == tmp9
        tmp11 = tl.full([1], 26, tl.int32)
        tmp12 = tmp0 == tmp11
        tmp13 = tl.full([1], 27, tl.int32)
        tmp14 = tmp0 == tmp13
        tmp15 = tl.full([1], 28, tl.int32)
        tmp16 = tmp0 == tmp15
        tmp17 = tl.full([1], 29, tl.int32)
        tmp18 = tmp0 == tmp17
        tmp21 = 0.0
        tmp22 = tl.where(tmp18, tmp21, tmp20)
        tmp23 = tl.where(tmp16, tmp21, tmp22)
        tmp24 = tl.where(tmp14, tmp21, tmp23)
        tmp25 = tl.where(tmp12, tmp21, tmp24)
        tmp26 = tl.where(tmp10, tmp21, tmp25)
        tmp27 = tl.where(tmp8, tmp21, tmp26)
        tmp28 = tl.where(tmp6, tmp21, tmp27)
        tmp29 = tl.where(tmp4, tmp21, tmp28)
        tmp30 = tl.where(tmp2, tmp21, tmp29)
        tmp31 = 2.0
        tmp32 = tmp30 * tmp31
        tl.store(out_ptr0 + (tl.full([XBLOCK], 0, tl.int32)), tmp32, None)


op55: SchedulerNode(ComputedBuffer)
op55.writes = [MemoryDep('buf55', c0, {c0: 100}, None)]
op55.unmet_dependencies = 
    [   MemoryDep('buf51', c0, {c0: 100}, None),
        MemoryDep('buf52', c0, {c0: 100}, None),
        MemoryDep('buf53', 17, {}, None),
        MemoryDep('buf53', 18, {}, None),
        MemoryDep('buf53', 19, {}, None),
        MemoryDep('buf54', 0, {}, None)]
op55.met_dependencies = [MemoryDep('full_default', c0, {c0: 100}, None)]
op55.outputs = [
    buf55: ComputedBuffer
    buf55.layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
    buf55.users = [NodeUser(node=SchedulerNode(name='op56'), can_inplace=True, is_weak=False)]
]
op55.group.device = cuda:0
op55.group.iteration = (100, 1)
op55.sizes = ([100], [])
buf51_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf52_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf54_layout = FixedLayout('cuda', torch.float32, size=[], stride=[])
full_default_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf53_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf53_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf53_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf55_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
class op55_loop_body:
    var_ranges = {z0: 100}
    index0 = z0
    index1 = 0
    index2 = 19
    index3 = 18
    index4 = 17
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf51', get_index)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('buf52', get_index_1)
        add = ops.add(load, load_1)
        get_index_2 = self.get_index('index0')
        index_expr = ops.index_expr(get_index_2, torch.int32)
        constant = ops.constant(20, torch.int32)
        eq = ops.eq(index_expr, constant)
        get_index_3 = self.get_index('index1')
        load_2 = ops.load('buf54', get_index_3)
        get_index_4 = self.get_index('index0')
        load_3 = ops.load('full_default', get_index_4)
        where = ops.where(eq, load_2, load_3)
        add_1 = ops.add(add, where)
        get_index_5 = self.get_index('index0')
        index_expr_1 = ops.index_expr(get_index_5, torch.int32)
        constant_1 = ops.constant(19, torch.int32)
        eq_1 = ops.eq(index_expr_1, constant_1)
        get_index_6 = self.get_index('index2')
        load_4 = ops.load('buf53', get_index_6)
        constant_2 = ops.constant(2.0, torch.float32)
        mul = ops.mul(load_4, constant_2)
        get_index_7 = self.get_index('index0')
        load_5 = ops.load('full_default', get_index_7)
        where_1 = ops.where(eq_1, mul, load_5)
        add_2 = ops.add(add_1, where_1)
        get_index_8 = self.get_index('index0')
        index_expr_2 = ops.index_expr(get_index_8, torch.int32)
        constant_3 = ops.constant(18, torch.int32)
        eq_2 = ops.eq(index_expr_2, constant_3)
        constant_4 = ops.constant(18, torch.int32)
        constant_5 = ops.constant(19, torch.int32)
        eq_3 = ops.eq(constant_4, constant_5)
        get_index_9 = self.get_index('index3')
        load_6 = ops.load('buf53', get_index_9)
        constant_6 = ops.constant(0.0, torch.float32)
        where_2 = ops.where(eq_3, constant_6, load_6)
        constant_7 = ops.constant(2.0, torch.float32)
        mul_1 = ops.mul(where_2, constant_7)
        get_index_10 = self.get_index('index0')
        load_7 = ops.load('full_default', get_index_10)
        where_3 = ops.where(eq_2, mul_1, load_7)
        add_3 = ops.add(add_2, where_3)
        get_index_11 = self.get_index('index0')
        index_expr_3 = ops.index_expr(get_index_11, torch.int32)
        constant_8 = ops.constant(17, torch.int32)
        eq_4 = ops.eq(index_expr_3, constant_8)
        constant_9 = ops.constant(17, torch.int32)
        constant_10 = ops.constant(18, torch.int32)
        eq_5 = ops.eq(constant_9, constant_10)
        constant_11 = ops.constant(17, torch.int32)
        constant_12 = ops.constant(19, torch.int32)
        eq_6 = ops.eq(constant_11, constant_12)
        get_index_12 = self.get_index('index4')
        load_8 = ops.load('buf53', get_index_12)
        constant_13 = ops.constant(0.0, torch.float32)
        where_4 = ops.where(eq_6, constant_13, load_8)
        constant_14 = ops.constant(0.0, torch.float32)
        where_5 = ops.where(eq_5, constant_14, where_4)
        constant_15 = ops.constant(2.0, torch.float32)
        mul_2 = ops.mul(where_5, constant_15)
        get_index_13 = self.get_index('index0')
        load_9 = ops.load('full_default', get_index_13)
        where_6 = ops.where(eq_4, mul_2, load_9)
        add_4 = ops.add(add_3, where_6)
        get_index_14 = self.get_index('index0')
        store = ops.store('buf55', get_index_14, add_4, None)
        return store
op55 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[128], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, multi_processor_count=20), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_out_ptr0'], 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': '712B1D69F892A891D8FFA5075DCAB47CFF4E132D88BFC66744701CEAE226F127', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, xnumel, XBLOCK : tl.constexpr):
        xnumel = 100
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp0 = tl.load(in_out_ptr0 + (x0), xmask)
        tmp1 = tl.load(in_ptr0 + (x0), xmask)
        tmp6 = tl.load(in_ptr1 + (0))
        tmp7 = tl.broadcast_to(tmp6, [XBLOCK])
        tmp8 = tl.load(in_ptr2 + (x0), xmask)
        tmp13 = tl.load(in_ptr3 + (19))
        tmp14 = tl.broadcast_to(tmp13, [XBLOCK])
        tmp22 = tl.load(in_ptr3 + (18))
        tmp23 = tl.broadcast_to(tmp22, [XBLOCK])
        tmp33 = tl.load(in_ptr3 + (17))
        tmp34 = tl.broadcast_to(tmp33, [XBLOCK])
        tmp2 = tmp0 + tmp1
        tmp3 = x0
        tmp4 = tl.full([1], 20, tl.int32)
        tmp5 = tmp3 == tmp4
        tmp9 = tl.where(tmp5, tmp7, tmp8)
        tmp10 = tmp2 + tmp9
        tmp11 = tl.full([1], 19, tl.int32)
        tmp12 = tmp3 == tmp11
        tmp15 = 2.0
        tmp16 = tmp14 * tmp15
        tmp17 = tl.where(tmp12, tmp16, tmp8)
        tmp18 = tmp10 + tmp17
        tmp19 = tl.full([1], 18, tl.int32)
        tmp20 = tmp3 == tmp19
        tmp21 = tmp19 == tmp11
        tmp24 = 0.0
        tmp25 = tl.where(tmp21, tmp24, tmp23)
        tmp26 = tmp25 * tmp15
        tmp27 = tl.where(tmp20, tmp26, tmp8)
        tmp28 = tmp18 + tmp27
        tmp29 = tl.full([1], 17, tl.int32)
        tmp30 = tmp3 == tmp29
        tmp31 = tmp29 == tmp19
        tmp32 = tmp29 == tmp11
        tmp35 = tl.where(tmp32, tmp24, tmp34)
        tmp36 = tl.where(tmp31, tmp24, tmp35)
        tmp37 = tmp36 * tmp15
        tmp38 = tl.where(tmp30, tmp37, tmp8)
        tmp39 = tmp28 + tmp38
        tl.store(in_out_ptr0 + (x0), tmp39, xmask)


op56: SchedulerNode(ComputedBuffer)
op56.writes = [MemoryDep('buf56', c0, {c0: 100}, None)]
op56.unmet_dependencies = 
    [   MemoryDep('buf53', 15, {}, None),
        MemoryDep('buf53', 16, {}, None),
        MemoryDep('buf55', c0, {c0: 100}, None)]
op56.met_dependencies = [MemoryDep('full_default', c0, {c0: 100}, None)]
op56.outputs = [
    buf56: ComputedBuffer
    buf56.layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
    buf56.users = [NodeUser(node=SchedulerNode(name='op57'), can_inplace=True, is_weak=False)]
]
op56.group.device = cuda:0
op56.group.iteration = (100, 1)
op56.sizes = ([100], [])
buf55_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf53_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
full_default_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf53_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf56_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
class op56_loop_body:
    var_ranges = {z0: 100}
    index0 = z0
    index1 = 16
    index2 = 15
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf55', get_index)
        get_index_1 = self.get_index('index0')
        index_expr = ops.index_expr(get_index_1, torch.int32)
        constant = ops.constant(16, torch.int32)
        eq = ops.eq(index_expr, constant)
        constant_1 = ops.constant(16, torch.int32)
        constant_2 = ops.constant(17, torch.int32)
        eq_1 = ops.eq(constant_1, constant_2)
        constant_3 = ops.constant(16, torch.int32)
        constant_4 = ops.constant(18, torch.int32)
        eq_2 = ops.eq(constant_3, constant_4)
        constant_5 = ops.constant(16, torch.int32)
        constant_6 = ops.constant(19, torch.int32)
        eq_3 = ops.eq(constant_5, constant_6)
        get_index_2 = self.get_index('index1')
        load_1 = ops.load('buf53', get_index_2)
        constant_7 = ops.constant(0.0, torch.float32)
        where = ops.where(eq_3, constant_7, load_1)
        constant_8 = ops.constant(0.0, torch.float32)
        where_1 = ops.where(eq_2, constant_8, where)
        constant_9 = ops.constant(0.0, torch.float32)
        where_2 = ops.where(eq_1, constant_9, where_1)
        constant_10 = ops.constant(2.0, torch.float32)
        mul = ops.mul(where_2, constant_10)
        get_index_3 = self.get_index('index0')
        load_2 = ops.load('full_default', get_index_3)
        where_3 = ops.where(eq, mul, load_2)
        add = ops.add(load, where_3)
        get_index_4 = self.get_index('index0')
        index_expr_1 = ops.index_expr(get_index_4, torch.int32)
        constant_11 = ops.constant(15, torch.int32)
        eq_4 = ops.eq(index_expr_1, constant_11)
        constant_12 = ops.constant(15, torch.int32)
        constant_13 = ops.constant(16, torch.int32)
        eq_5 = ops.eq(constant_12, constant_13)
        constant_14 = ops.constant(15, torch.int32)
        constant_15 = ops.constant(17, torch.int32)
        eq_6 = ops.eq(constant_14, constant_15)
        constant_16 = ops.constant(15, torch.int32)
        constant_17 = ops.constant(18, torch.int32)
        eq_7 = ops.eq(constant_16, constant_17)
        constant_18 = ops.constant(15, torch.int32)
        constant_19 = ops.constant(19, torch.int32)
        eq_8 = ops.eq(constant_18, constant_19)
        get_index_5 = self.get_index('index2')
        load_3 = ops.load('buf53', get_index_5)
        constant_20 = ops.constant(0.0, torch.float32)
        where_4 = ops.where(eq_8, constant_20, load_3)
        constant_21 = ops.constant(0.0, torch.float32)
        where_5 = ops.where(eq_7, constant_21, where_4)
        constant_22 = ops.constant(0.0, torch.float32)
        where_6 = ops.where(eq_6, constant_22, where_5)
        constant_23 = ops.constant(0.0, torch.float32)
        where_7 = ops.where(eq_5, constant_23, where_6)
        constant_24 = ops.constant(2.0, torch.float32)
        mul_1 = ops.mul(where_7, constant_24)
        get_index_6 = self.get_index('index0')
        load_4 = ops.load('full_default', get_index_6)
        where_8 = ops.where(eq_4, mul_1, load_4)
        add_1 = ops.add(add, where_8)
        get_index_7 = self.get_index('index0')
        store = ops.store('buf56', get_index_7, add_1, None)
        return store
op56 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[128], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, multi_processor_count=20), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_out_ptr0'], 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': '712B1D69F892A891D8FFA5075DCAB47CFF4E132D88BFC66744701CEAE226F127', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_out_ptr0, in_ptr0, in_ptr1, xnumel, XBLOCK : tl.constexpr):
        xnumel = 100
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp0 = tl.load(in_out_ptr0 + (x0), xmask)
        tmp10 = tl.load(in_ptr0 + (16))
        tmp11 = tl.broadcast_to(tmp10, [XBLOCK])
        tmp18 = tl.load(in_ptr1 + (x0), xmask)
        tmp27 = tl.load(in_ptr0 + (15))
        tmp28 = tl.broadcast_to(tmp27, [XBLOCK])
        tmp1 = x0
        tmp2 = tl.full([1], 16, tl.int32)
        tmp3 = tmp1 == tmp2
        tmp4 = tl.full([1], 17, tl.int32)
        tmp5 = tmp2 == tmp4
        tmp6 = tl.full([1], 18, tl.int32)
        tmp7 = tmp2 == tmp6
        tmp8 = tl.full([1], 19, tl.int32)
        tmp9 = tmp2 == tmp8
        tmp12 = 0.0
        tmp13 = tl.where(tmp9, tmp12, tmp11)
        tmp14 = tl.where(tmp7, tmp12, tmp13)
        tmp15 = tl.where(tmp5, tmp12, tmp14)
        tmp16 = 2.0
        tmp17 = tmp15 * tmp16
        tmp19 = tl.where(tmp3, tmp17, tmp18)
        tmp20 = tmp0 + tmp19
        tmp21 = tl.full([1], 15, tl.int32)
        tmp22 = tmp1 == tmp21
        tmp23 = tmp21 == tmp2
        tmp24 = tmp21 == tmp4
        tmp25 = tmp21 == tmp6
        tmp26 = tmp21 == tmp8
        tmp29 = tl.where(tmp26, tmp12, tmp28)
        tmp30 = tl.where(tmp25, tmp12, tmp29)
        tmp31 = tl.where(tmp24, tmp12, tmp30)
        tmp32 = tl.where(tmp23, tmp12, tmp31)
        tmp33 = tmp32 * tmp16
        tmp34 = tl.where(tmp22, tmp33, tmp18)
        tmp35 = tmp20 + tmp34
        tl.store(in_out_ptr0 + (x0), tmp35, xmask)


op57: SchedulerNode(ComputedBuffer)
op57.writes = [MemoryDep('buf57', c0, {c0: 100}, None)]
op57.unmet_dependencies = 
    [   MemoryDep('buf53', 13, {}, None),
        MemoryDep('buf53', 14, {}, None),
        MemoryDep('buf56', c0, {c0: 100}, None)]
op57.met_dependencies = [MemoryDep('full_default', c0, {c0: 100}, None)]
op57.outputs = [
    buf57: ComputedBuffer
    buf57.layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
    buf57.users = [NodeUser(node=SchedulerNode(name='op58'), can_inplace=True, is_weak=False)]
]
op57.group.device = cuda:0
op57.group.iteration = (100, 1)
op57.sizes = ([100], [])
buf56_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf53_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
full_default_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf53_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf57_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
class op57_loop_body:
    var_ranges = {z0: 100}
    index0 = z0
    index1 = 14
    index2 = 13
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf56', get_index)
        get_index_1 = self.get_index('index0')
        index_expr = ops.index_expr(get_index_1, torch.int32)
        constant = ops.constant(14, torch.int32)
        eq = ops.eq(index_expr, constant)
        constant_1 = ops.constant(14, torch.int32)
        constant_2 = ops.constant(15, torch.int32)
        eq_1 = ops.eq(constant_1, constant_2)
        constant_3 = ops.constant(14, torch.int32)
        constant_4 = ops.constant(16, torch.int32)
        eq_2 = ops.eq(constant_3, constant_4)
        constant_5 = ops.constant(14, torch.int32)
        constant_6 = ops.constant(17, torch.int32)
        eq_3 = ops.eq(constant_5, constant_6)
        constant_7 = ops.constant(14, torch.int32)
        constant_8 = ops.constant(18, torch.int32)
        eq_4 = ops.eq(constant_7, constant_8)
        constant_9 = ops.constant(14, torch.int32)
        constant_10 = ops.constant(19, torch.int32)
        eq_5 = ops.eq(constant_9, constant_10)
        get_index_2 = self.get_index('index1')
        load_1 = ops.load('buf53', get_index_2)
        constant_11 = ops.constant(0.0, torch.float32)
        where = ops.where(eq_5, constant_11, load_1)
        constant_12 = ops.constant(0.0, torch.float32)
        where_1 = ops.where(eq_4, constant_12, where)
        constant_13 = ops.constant(0.0, torch.float32)
        where_2 = ops.where(eq_3, constant_13, where_1)
        constant_14 = ops.constant(0.0, torch.float32)
        where_3 = ops.where(eq_2, constant_14, where_2)
        constant_15 = ops.constant(0.0, torch.float32)
        where_4 = ops.where(eq_1, constant_15, where_3)
        constant_16 = ops.constant(2.0, torch.float32)
        mul = ops.mul(where_4, constant_16)
        get_index_3 = self.get_index('index0')
        load_2 = ops.load('full_default', get_index_3)
        where_5 = ops.where(eq, mul, load_2)
        add = ops.add(load, where_5)
        get_index_4 = self.get_index('index0')
        index_expr_1 = ops.index_expr(get_index_4, torch.int32)
        constant_17 = ops.constant(13, torch.int32)
        eq_6 = ops.eq(index_expr_1, constant_17)
        constant_18 = ops.constant(13, torch.int32)
        constant_19 = ops.constant(14, torch.int32)
        eq_7 = ops.eq(constant_18, constant_19)
        constant_20 = ops.constant(13, torch.int32)
        constant_21 = ops.constant(15, torch.int32)
        eq_8 = ops.eq(constant_20, constant_21)
        constant_22 = ops.constant(13, torch.int32)
        constant_23 = ops.constant(16, torch.int32)
        eq_9 = ops.eq(constant_22, constant_23)
        constant_24 = ops.constant(13, torch.int32)
        constant_25 = ops.constant(17, torch.int32)
        eq_10 = ops.eq(constant_24, constant_25)
        constant_26 = ops.constant(13, torch.int32)
        constant_27 = ops.constant(18, torch.int32)
        eq_11 = ops.eq(constant_26, constant_27)
        constant_28 = ops.constant(13, torch.int32)
        constant_29 = ops.constant(19, torch.int32)
        eq_12 = ops.eq(constant_28, constant_29)
        get_index_5 = self.get_index('index2')
        load_3 = ops.load('buf53', get_index_5)
        constant_30 = ops.constant(0.0, torch.float32)
        where_6 = ops.where(eq_12, constant_30, load_3)
        constant_31 = ops.constant(0.0, torch.float32)
        where_7 = ops.where(eq_11, constant_31, where_6)
        constant_32 = ops.constant(0.0, torch.float32)
        where_8 = ops.where(eq_10, constant_32, where_7)
        constant_33 = ops.constant(0.0, torch.float32)
        where_9 = ops.where(eq_9, constant_33, where_8)
        constant_34 = ops.constant(0.0, torch.float32)
        where_10 = ops.where(eq_8, constant_34, where_9)
        constant_35 = ops.constant(0.0, torch.float32)
        where_11 = ops.where(eq_7, constant_35, where_10)
        constant_36 = ops.constant(2.0, torch.float32)
        mul_1 = ops.mul(where_11, constant_36)
        get_index_6 = self.get_index('index0')
        load_4 = ops.load('full_default', get_index_6)
        where_12 = ops.where(eq_6, mul_1, load_4)
        add_1 = ops.add(add, where_12)
        get_index_7 = self.get_index('index0')
        store = ops.store('buf57', get_index_7, add_1, None)
        return store
op57 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[128], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, multi_processor_count=20), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_out_ptr0'], 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': '712B1D69F892A891D8FFA5075DCAB47CFF4E132D88BFC66744701CEAE226F127', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_out_ptr0, in_ptr0, in_ptr1, xnumel, XBLOCK : tl.constexpr):
        xnumel = 100
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp0 = tl.load(in_out_ptr0 + (x0), xmask)
        tmp14 = tl.load(in_ptr0 + (14))
        tmp15 = tl.broadcast_to(tmp14, [XBLOCK])
        tmp24 = tl.load(in_ptr1 + (x0), xmask)
        tmp35 = tl.load(in_ptr0 + (13))
        tmp36 = tl.broadcast_to(tmp35, [XBLOCK])
        tmp1 = x0
        tmp2 = tl.full([1], 14, tl.int32)
        tmp3 = tmp1 == tmp2
        tmp4 = tl.full([1], 15, tl.int32)
        tmp5 = tmp2 == tmp4
        tmp6 = tl.full([1], 16, tl.int32)
        tmp7 = tmp2 == tmp6
        tmp8 = tl.full([1], 17, tl.int32)
        tmp9 = tmp2 == tmp8
        tmp10 = tl.full([1], 18, tl.int32)
        tmp11 = tmp2 == tmp10
        tmp12 = tl.full([1], 19, tl.int32)
        tmp13 = tmp2 == tmp12
        tmp16 = 0.0
        tmp17 = tl.where(tmp13, tmp16, tmp15)
        tmp18 = tl.where(tmp11, tmp16, tmp17)
        tmp19 = tl.where(tmp9, tmp16, tmp18)
        tmp20 = tl.where(tmp7, tmp16, tmp19)
        tmp21 = tl.where(tmp5, tmp16, tmp20)
        tmp22 = 2.0
        tmp23 = tmp21 * tmp22
        tmp25 = tl.where(tmp3, tmp23, tmp24)
        tmp26 = tmp0 + tmp25
        tmp27 = tl.full([1], 13, tl.int32)
        tmp28 = tmp1 == tmp27
        tmp29 = tmp27 == tmp2
        tmp30 = tmp27 == tmp4
        tmp31 = tmp27 == tmp6
        tmp32 = tmp27 == tmp8
        tmp33 = tmp27 == tmp10
        tmp34 = tmp27 == tmp12
        tmp37 = tl.where(tmp34, tmp16, tmp36)
        tmp38 = tl.where(tmp33, tmp16, tmp37)
        tmp39 = tl.where(tmp32, tmp16, tmp38)
        tmp40 = tl.where(tmp31, tmp16, tmp39)
        tmp41 = tl.where(tmp30, tmp16, tmp40)
        tmp42 = tl.where(tmp29, tmp16, tmp41)
        tmp43 = tmp42 * tmp22
        tmp44 = tl.where(tmp28, tmp43, tmp24)
        tmp45 = tmp26 + tmp44
        tl.store(in_out_ptr0 + (x0), tmp45, xmask)


op58: SchedulerNode(ComputedBuffer)
op58.writes = [MemoryDep('buf58', c0, {c0: 100}, None)]
op58.unmet_dependencies = [MemoryDep('buf53', 12, {}, None), MemoryDep('buf57', c0, {c0: 100}, None)]
op58.met_dependencies = [MemoryDep('full_default', c0, {c0: 100}, None)]
op58.outputs = [
    buf58: ComputedBuffer
    buf58.layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
    buf58.users = [NodeUser(node=SchedulerNode(name='op62'), can_inplace=True, is_weak=False)]
]
op58.group.device = cuda:0
op58.group.iteration = (100, 1)
op58.sizes = ([100], [])
buf57_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf53_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
full_default_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf58_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
class op58_loop_body:
    var_ranges = {z0: 100}
    index0 = z0
    index1 = 12
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf57', get_index)
        get_index_1 = self.get_index('index0')
        index_expr = ops.index_expr(get_index_1, torch.int32)
        constant = ops.constant(12, torch.int32)
        eq = ops.eq(index_expr, constant)
        constant_1 = ops.constant(12, torch.int32)
        constant_2 = ops.constant(13, torch.int32)
        eq_1 = ops.eq(constant_1, constant_2)
        constant_3 = ops.constant(12, torch.int32)
        constant_4 = ops.constant(14, torch.int32)
        eq_2 = ops.eq(constant_3, constant_4)
        constant_5 = ops.constant(12, torch.int32)
        constant_6 = ops.constant(15, torch.int32)
        eq_3 = ops.eq(constant_5, constant_6)
        constant_7 = ops.constant(12, torch.int32)
        constant_8 = ops.constant(16, torch.int32)
        eq_4 = ops.eq(constant_7, constant_8)
        constant_9 = ops.constant(12, torch.int32)
        constant_10 = ops.constant(17, torch.int32)
        eq_5 = ops.eq(constant_9, constant_10)
        constant_11 = ops.constant(12, torch.int32)
        constant_12 = ops.constant(18, torch.int32)
        eq_6 = ops.eq(constant_11, constant_12)
        constant_13 = ops.constant(12, torch.int32)
        constant_14 = ops.constant(19, torch.int32)
        eq_7 = ops.eq(constant_13, constant_14)
        get_index_2 = self.get_index('index1')
        load_1 = ops.load('buf53', get_index_2)
        constant_15 = ops.constant(0.0, torch.float32)
        where = ops.where(eq_7, constant_15, load_1)
        constant_16 = ops.constant(0.0, torch.float32)
        where_1 = ops.where(eq_6, constant_16, where)
        constant_17 = ops.constant(0.0, torch.float32)
        where_2 = ops.where(eq_5, constant_17, where_1)
        constant_18 = ops.constant(0.0, torch.float32)
        where_3 = ops.where(eq_4, constant_18, where_2)
        constant_19 = ops.constant(0.0, torch.float32)
        where_4 = ops.where(eq_3, constant_19, where_3)
        constant_20 = ops.constant(0.0, torch.float32)
        where_5 = ops.where(eq_2, constant_20, where_4)
        constant_21 = ops.constant(0.0, torch.float32)
        where_6 = ops.where(eq_1, constant_21, where_5)
        constant_22 = ops.constant(2.0, torch.float32)
        mul = ops.mul(where_6, constant_22)
        get_index_3 = self.get_index('index0')
        load_2 = ops.load('full_default', get_index_3)
        where_7 = ops.where(eq, mul, load_2)
        add = ops.add(load, where_7)
        get_index_4 = self.get_index('index0')
        store = ops.store('buf58', get_index_4, add, None)
        return store
op58 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[128], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, multi_processor_count=20), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_out_ptr0'], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 0, 'backend_hash': '712B1D69F892A891D8FFA5075DCAB47CFF4E132D88BFC66744701CEAE226F127', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_out_ptr0, in_ptr0, in_ptr1, xnumel, XBLOCK : tl.constexpr):
        xnumel = 100
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp0 = tl.load(in_out_ptr0 + (x0), xmask)
        tmp18 = tl.load(in_ptr0 + (12))
        tmp19 = tl.broadcast_to(tmp18, [XBLOCK])
        tmp30 = tl.load(in_ptr1 + (x0), xmask)
        tmp1 = x0
        tmp2 = tl.full([1], 12, tl.int32)
        tmp3 = tmp1 == tmp2
        tmp4 = tl.full([1], 13, tl.int32)
        tmp5 = tmp2 == tmp4
        tmp6 = tl.full([1], 14, tl.int32)
        tmp7 = tmp2 == tmp6
        tmp8 = tl.full([1], 15, tl.int32)
        tmp9 = tmp2 == tmp8
        tmp10 = tl.full([1], 16, tl.int32)
        tmp11 = tmp2 == tmp10
        tmp12 = tl.full([1], 17, tl.int32)
        tmp13 = tmp2 == tmp12
        tmp14 = tl.full([1], 18, tl.int32)
        tmp15 = tmp2 == tmp14
        tmp16 = tl.full([1], 19, tl.int32)
        tmp17 = tmp2 == tmp16
        tmp20 = 0.0
        tmp21 = tl.where(tmp17, tmp20, tmp19)
        tmp22 = tl.where(tmp15, tmp20, tmp21)
        tmp23 = tl.where(tmp13, tmp20, tmp22)
        tmp24 = tl.where(tmp11, tmp20, tmp23)
        tmp25 = tl.where(tmp9, tmp20, tmp24)
        tmp26 = tl.where(tmp7, tmp20, tmp25)
        tmp27 = tl.where(tmp5, tmp20, tmp26)
        tmp28 = 2.0
        tmp29 = tmp27 * tmp28
        tmp31 = tl.where(tmp3, tmp29, tmp30)
        tmp32 = tmp0 + tmp31
        tl.store(in_out_ptr0 + (x0), tmp32, xmask)


op59: SchedulerNode(ComputedBuffer)
op59.writes = [MemoryDep('buf59', c0, {c0: 100}, None)]
op59.unmet_dependencies = [MemoryDep('buf53', 11, {}, None)]
op59.met_dependencies = [MemoryDep('full_default', c0, {c0: 100}, None)]
op59.outputs = [
    buf59: ComputedBuffer
    buf59.layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
    buf59.users = [NodeUser(node=SchedulerNode(name='op62'), can_inplace=True, is_weak=False)]
]
op59.group.device = cuda:0
op59.group.iteration = (100, 1)
op59.sizes = ([100], [])
buf53_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
full_default_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf59_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
class op59_loop_body:
    var_ranges = {z0: 100}
    index0 = z0
    index1 = 11
    def body(self, ops):
        get_index = self.get_index('index0')
        index_expr = ops.index_expr(get_index, torch.int32)
        constant = ops.constant(11, torch.int32)
        eq = ops.eq(index_expr, constant)
        constant_1 = ops.constant(11, torch.int32)
        constant_2 = ops.constant(12, torch.int32)
        eq_1 = ops.eq(constant_1, constant_2)
        constant_3 = ops.constant(11, torch.int32)
        constant_4 = ops.constant(13, torch.int32)
        eq_2 = ops.eq(constant_3, constant_4)
        constant_5 = ops.constant(11, torch.int32)
        constant_6 = ops.constant(14, torch.int32)
        eq_3 = ops.eq(constant_5, constant_6)
        constant_7 = ops.constant(11, torch.int32)
        constant_8 = ops.constant(15, torch.int32)
        eq_4 = ops.eq(constant_7, constant_8)
        constant_9 = ops.constant(11, torch.int32)
        constant_10 = ops.constant(16, torch.int32)
        eq_5 = ops.eq(constant_9, constant_10)
        constant_11 = ops.constant(11, torch.int32)
        constant_12 = ops.constant(17, torch.int32)
        eq_6 = ops.eq(constant_11, constant_12)
        constant_13 = ops.constant(11, torch.int32)
        constant_14 = ops.constant(18, torch.int32)
        eq_7 = ops.eq(constant_13, constant_14)
        constant_15 = ops.constant(11, torch.int32)
        constant_16 = ops.constant(19, torch.int32)
        eq_8 = ops.eq(constant_15, constant_16)
        get_index_1 = self.get_index('index1')
        load = ops.load('buf53', get_index_1)
        constant_17 = ops.constant(0.0, torch.float32)
        where = ops.where(eq_8, constant_17, load)
        constant_18 = ops.constant(0.0, torch.float32)
        where_1 = ops.where(eq_7, constant_18, where)
        constant_19 = ops.constant(0.0, torch.float32)
        where_2 = ops.where(eq_6, constant_19, where_1)
        constant_20 = ops.constant(0.0, torch.float32)
        where_3 = ops.where(eq_5, constant_20, where_2)
        constant_21 = ops.constant(0.0, torch.float32)
        where_4 = ops.where(eq_4, constant_21, where_3)
        constant_22 = ops.constant(0.0, torch.float32)
        where_5 = ops.where(eq_3, constant_22, where_4)
        constant_23 = ops.constant(0.0, torch.float32)
        where_6 = ops.where(eq_2, constant_23, where_5)
        constant_24 = ops.constant(0.0, torch.float32)
        where_7 = ops.where(eq_1, constant_24, where_6)
        constant_25 = ops.constant(2.0, torch.float32)
        mul = ops.mul(where_7, constant_25)
        get_index_2 = self.get_index('index0')
        load_1 = ops.load('full_default', get_index_2)
        where_8 = ops.where(eq, mul, load_1)
        get_index_3 = self.get_index('index0')
        store = ops.store('buf59', get_index_3, where_8, None)
        return store
op59 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[128], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, multi_processor_count=20), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '712B1D69F892A891D8FFA5075DCAB47CFF4E132D88BFC66744701CEAE226F127', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 100
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp19 = tl.load(in_ptr0 + (11))
        tmp20 = tl.broadcast_to(tmp19, [XBLOCK])
        tmp32 = tl.load(in_ptr1 + (x0), xmask)
        tmp0 = x0
        tmp1 = tl.full([1], 11, tl.int32)
        tmp2 = tmp0 == tmp1
        tmp3 = tl.full([1], 12, tl.int32)
        tmp4 = tmp1 == tmp3
        tmp5 = tl.full([1], 13, tl.int32)
        tmp6 = tmp1 == tmp5
        tmp7 = tl.full([1], 14, tl.int32)
        tmp8 = tmp1 == tmp7
        tmp9 = tl.full([1], 15, tl.int32)
        tmp10 = tmp1 == tmp9
        tmp11 = tl.full([1], 16, tl.int32)
        tmp12 = tmp1 == tmp11
        tmp13 = tl.full([1], 17, tl.int32)
        tmp14 = tmp1 == tmp13
        tmp15 = tl.full([1], 18, tl.int32)
        tmp16 = tmp1 == tmp15
        tmp17 = tl.full([1], 19, tl.int32)
        tmp18 = tmp1 == tmp17
        tmp21 = 0.0
        tmp22 = tl.where(tmp18, tmp21, tmp20)
        tmp23 = tl.where(tmp16, tmp21, tmp22)
        tmp24 = tl.where(tmp14, tmp21, tmp23)
        tmp25 = tl.where(tmp12, tmp21, tmp24)
        tmp26 = tl.where(tmp10, tmp21, tmp25)
        tmp27 = tl.where(tmp8, tmp21, tmp26)
        tmp28 = tl.where(tmp6, tmp21, tmp27)
        tmp29 = tl.where(tmp4, tmp21, tmp28)
        tmp30 = 2.0
        tmp31 = tmp29 * tmp30
        tmp33 = tl.where(tmp2, tmp31, tmp32)
        tl.store(out_ptr0 + (x0), tmp33, xmask)


op60: SchedulerNode(ComputedBuffer)
op60.writes = [MemoryDep('buf60', c0, {c0: 100}, None)]
op60.unmet_dependencies = [MemoryDep('buf53', c0, {c0: 100}, None)]
op60.met_dependencies = []
op60.outputs = [
    buf60: ComputedBuffer
    buf60.layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
    buf60.users = [
        NodeUser(node=SchedulerNode(name='op62'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op63'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op64'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op65'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op66'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op67'), can_inplace=True, is_weak=False),
    ]
]
op60.group.device = cuda:0
op60.group.iteration = (100, 1)
op60.sizes = ([100], [])
buf53_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf60_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
class op60_loop_body:
    var_ranges = {z0: 100}
    index0 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        index_expr = ops.index_expr(get_index, torch.int32)
        constant = ops.constant(10, torch.int32)
        eq = ops.eq(index_expr, constant)
        get_index_1 = self.get_index('index0')
        index_expr_1 = ops.index_expr(get_index_1, torch.int32)
        constant_1 = ops.constant(11, torch.int32)
        eq_1 = ops.eq(index_expr_1, constant_1)
        get_index_2 = self.get_index('index0')
        index_expr_2 = ops.index_expr(get_index_2, torch.int32)
        constant_2 = ops.constant(12, torch.int32)
        eq_2 = ops.eq(index_expr_2, constant_2)
        get_index_3 = self.get_index('index0')
        index_expr_3 = ops.index_expr(get_index_3, torch.int32)
        constant_3 = ops.constant(13, torch.int32)
        eq_3 = ops.eq(index_expr_3, constant_3)
        get_index_4 = self.get_index('index0')
        index_expr_4 = ops.index_expr(get_index_4, torch.int32)
        constant_4 = ops.constant(14, torch.int32)
        eq_4 = ops.eq(index_expr_4, constant_4)
        get_index_5 = self.get_index('index0')
        index_expr_5 = ops.index_expr(get_index_5, torch.int32)
        constant_5 = ops.constant(15, torch.int32)
        eq_5 = ops.eq(index_expr_5, constant_5)
        get_index_6 = self.get_index('index0')
        index_expr_6 = ops.index_expr(get_index_6, torch.int32)
        constant_6 = ops.constant(16, torch.int32)
        eq_6 = ops.eq(index_expr_6, constant_6)
        get_index_7 = self.get_index('index0')
        index_expr_7 = ops.index_expr(get_index_7, torch.int32)
        constant_7 = ops.constant(17, torch.int32)
        eq_7 = ops.eq(index_expr_7, constant_7)
        get_index_8 = self.get_index('index0')
        index_expr_8 = ops.index_expr(get_index_8, torch.int32)
        constant_8 = ops.constant(18, torch.int32)
        eq_8 = ops.eq(index_expr_8, constant_8)
        get_index_9 = self.get_index('index0')
        index_expr_9 = ops.index_expr(get_index_9, torch.int32)
        constant_9 = ops.constant(19, torch.int32)
        eq_9 = ops.eq(index_expr_9, constant_9)
        get_index_10 = self.get_index('index0')
        load = ops.load('buf53', get_index_10)
        constant_10 = ops.constant(0.0, torch.float32)
        where = ops.where(eq_9, constant_10, load)
        constant_11 = ops.constant(0.0, torch.float32)
        where_1 = ops.where(eq_8, constant_11, where)
        constant_12 = ops.constant(0.0, torch.float32)
        where_2 = ops.where(eq_7, constant_12, where_1)
        constant_13 = ops.constant(0.0, torch.float32)
        where_3 = ops.where(eq_6, constant_13, where_2)
        constant_14 = ops.constant(0.0, torch.float32)
        where_4 = ops.where(eq_5, constant_14, where_3)
        constant_15 = ops.constant(0.0, torch.float32)
        where_5 = ops.where(eq_4, constant_15, where_4)
        constant_16 = ops.constant(0.0, torch.float32)
        where_6 = ops.where(eq_3, constant_16, where_5)
        constant_17 = ops.constant(0.0, torch.float32)
        where_7 = ops.where(eq_2, constant_17, where_6)
        constant_18 = ops.constant(0.0, torch.float32)
        where_8 = ops.where(eq_1, constant_18, where_7)
        constant_19 = ops.constant(0.0, torch.float32)
        where_9 = ops.where(eq, constant_19, where_8)
        get_index_11 = self.get_index('index0')
        store = ops.store('buf60', get_index_11, where_9, None)
        return store
op60 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[128], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, multi_processor_count=20), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '712B1D69F892A891D8FFA5075DCAB47CFF4E132D88BFC66744701CEAE226F127', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 100
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp21 = tl.load(in_ptr0 + (x0), xmask)
        tmp0 = x0
        tmp1 = tl.full([1], 10, tl.int32)
        tmp2 = tmp0 == tmp1
        tmp3 = tl.full([1], 11, tl.int32)
        tmp4 = tmp0 == tmp3
        tmp5 = tl.full([1], 12, tl.int32)
        tmp6 = tmp0 == tmp5
        tmp7 = tl.full([1], 13, tl.int32)
        tmp8 = tmp0 == tmp7
        tmp9 = tl.full([1], 14, tl.int32)
        tmp10 = tmp0 == tmp9
        tmp11 = tl.full([1], 15, tl.int32)
        tmp12 = tmp0 == tmp11
        tmp13 = tl.full([1], 16, tl.int32)
        tmp14 = tmp0 == tmp13
        tmp15 = tl.full([1], 17, tl.int32)
        tmp16 = tmp0 == tmp15
        tmp17 = tl.full([1], 18, tl.int32)
        tmp18 = tmp0 == tmp17
        tmp19 = tl.full([1], 19, tl.int32)
        tmp20 = tmp0 == tmp19
        tmp22 = 0.0
        tmp23 = tl.where(tmp20, tmp22, tmp21)
        tmp24 = tl.where(tmp18, tmp22, tmp23)
        tmp25 = tl.where(tmp16, tmp22, tmp24)
        tmp26 = tl.where(tmp14, tmp22, tmp25)
        tmp27 = tl.where(tmp12, tmp22, tmp26)
        tmp28 = tl.where(tmp10, tmp22, tmp27)
        tmp29 = tl.where(tmp8, tmp22, tmp28)
        tmp30 = tl.where(tmp6, tmp22, tmp29)
        tmp31 = tl.where(tmp4, tmp22, tmp30)
        tmp32 = tl.where(tmp2, tmp22, tmp31)
        tl.store(out_ptr0 + (x0), tmp32, xmask)


op61: SchedulerNode(ComputedBuffer)
op61.writes = [MemoryDep('buf61', 0, {}, None)]
op61.unmet_dependencies = [MemoryDep('buf53', 10, {}, None)]
op61.met_dependencies = []
op61.outputs = [
    buf61: ComputedBuffer
    buf61.layout = FixedLayout('cuda', torch.float32, size=[], stride=[])
    buf61.users = [NodeUser(node=SchedulerNode(name='op62'), can_inplace=False, is_weak=False)]
]
op61.group.device = cuda:0
op61.group.iteration = (1, 1)
op61.sizes = ([], [])
buf53_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf61_layout = FixedLayout('cuda', torch.float32, size=[], stride=[])
class op61_loop_body:
    var_ranges = {}
    index0 = 10
    index1 = 0
    def body(self, ops):
        constant = ops.constant(10, torch.int32)
        constant_1 = ops.constant(11, torch.int32)
        eq = ops.eq(constant, constant_1)
        constant_2 = ops.constant(10, torch.int32)
        constant_3 = ops.constant(12, torch.int32)
        eq_1 = ops.eq(constant_2, constant_3)
        constant_4 = ops.constant(10, torch.int32)
        constant_5 = ops.constant(13, torch.int32)
        eq_2 = ops.eq(constant_4, constant_5)
        constant_6 = ops.constant(10, torch.int32)
        constant_7 = ops.constant(14, torch.int32)
        eq_3 = ops.eq(constant_6, constant_7)
        constant_8 = ops.constant(10, torch.int32)
        constant_9 = ops.constant(15, torch.int32)
        eq_4 = ops.eq(constant_8, constant_9)
        constant_10 = ops.constant(10, torch.int32)
        constant_11 = ops.constant(16, torch.int32)
        eq_5 = ops.eq(constant_10, constant_11)
        constant_12 = ops.constant(10, torch.int32)
        constant_13 = ops.constant(17, torch.int32)
        eq_6 = ops.eq(constant_12, constant_13)
        constant_14 = ops.constant(10, torch.int32)
        constant_15 = ops.constant(18, torch.int32)
        eq_7 = ops.eq(constant_14, constant_15)
        constant_16 = ops.constant(10, torch.int32)
        constant_17 = ops.constant(19, torch.int32)
        eq_8 = ops.eq(constant_16, constant_17)
        get_index = self.get_index('index0')
        load = ops.load('buf53', get_index)
        constant_18 = ops.constant(0.0, torch.float32)
        where = ops.where(eq_8, constant_18, load)
        constant_19 = ops.constant(0.0, torch.float32)
        where_1 = ops.where(eq_7, constant_19, where)
        constant_20 = ops.constant(0.0, torch.float32)
        where_2 = ops.where(eq_6, constant_20, where_1)
        constant_21 = ops.constant(0.0, torch.float32)
        where_3 = ops.where(eq_5, constant_21, where_2)
        constant_22 = ops.constant(0.0, torch.float32)
        where_4 = ops.where(eq_4, constant_22, where_3)
        constant_23 = ops.constant(0.0, torch.float32)
        where_5 = ops.where(eq_3, constant_23, where_4)
        constant_24 = ops.constant(0.0, torch.float32)
        where_6 = ops.where(eq_2, constant_24, where_5)
        constant_25 = ops.constant(0.0, torch.float32)
        where_7 = ops.where(eq_1, constant_25, where_6)
        constant_26 = ops.constant(0.0, torch.float32)
        where_8 = ops.where(eq, constant_26, where_7)
        constant_27 = ops.constant(2.0, torch.float32)
        mul = ops.mul(where_8, constant_27)
        get_index_1 = self.get_index('index1')
        store = ops.store('buf61', get_index_1, mul, None)
        return store
op61 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[1], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, multi_processor_count=20), 'constants': {2: 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(2,))]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '712B1D69F892A891D8FFA5075DCAB47CFF4E132D88BFC66744701CEAE226F127', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 1
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = tl.full([XBLOCK], True, tl.int1)
        tmp19 = tl.load(in_ptr0 + (10))
        tmp20 = tl.broadcast_to(tmp19, [XBLOCK])
        tmp0 = tl.full([1], 10, tl.int32)
        tmp1 = tl.full([1], 11, tl.int32)
        tmp2 = tmp0 == tmp1
        tmp3 = tl.full([1], 12, tl.int32)
        tmp4 = tmp0 == tmp3
        tmp5 = tl.full([1], 13, tl.int32)
        tmp6 = tmp0 == tmp5
        tmp7 = tl.full([1], 14, tl.int32)
        tmp8 = tmp0 == tmp7
        tmp9 = tl.full([1], 15, tl.int32)
        tmp10 = tmp0 == tmp9
        tmp11 = tl.full([1], 16, tl.int32)
        tmp12 = tmp0 == tmp11
        tmp13 = tl.full([1], 17, tl.int32)
        tmp14 = tmp0 == tmp13
        tmp15 = tl.full([1], 18, tl.int32)
        tmp16 = tmp0 == tmp15
        tmp17 = tl.full([1], 19, tl.int32)
        tmp18 = tmp0 == tmp17
        tmp21 = 0.0
        tmp22 = tl.where(tmp18, tmp21, tmp20)
        tmp23 = tl.where(tmp16, tmp21, tmp22)
        tmp24 = tl.where(tmp14, tmp21, tmp23)
        tmp25 = tl.where(tmp12, tmp21, tmp24)
        tmp26 = tl.where(tmp10, tmp21, tmp25)
        tmp27 = tl.where(tmp8, tmp21, tmp26)
        tmp28 = tl.where(tmp6, tmp21, tmp27)
        tmp29 = tl.where(tmp4, tmp21, tmp28)
        tmp30 = tl.where(tmp2, tmp21, tmp29)
        tmp31 = 2.0
        tmp32 = tmp30 * tmp31
        tl.store(out_ptr0 + (tl.full([XBLOCK], 0, tl.int32)), tmp32, None)


op62: SchedulerNode(ComputedBuffer)
op62.writes = [MemoryDep('buf62', c0, {c0: 100}, None)]
op62.unmet_dependencies = 
    [   MemoryDep('buf58', c0, {c0: 100}, None),
        MemoryDep('buf59', c0, {c0: 100}, None),
        MemoryDep('buf60', 7, {}, None),
        MemoryDep('buf60', 8, {}, None),
        MemoryDep('buf60', 9, {}, None),
        MemoryDep('buf61', 0, {}, None)]
op62.met_dependencies = [MemoryDep('full_default', c0, {c0: 100}, None)]
op62.outputs = [
    buf62: ComputedBuffer
    buf62.layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
    buf62.users = [NodeUser(node=SchedulerNode(name='op63'), can_inplace=True, is_weak=False)]
]
op62.group.device = cuda:0
op62.group.iteration = (100, 1)
op62.sizes = ([100], [])
buf58_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf59_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf61_layout = FixedLayout('cuda', torch.float32, size=[], stride=[])
full_default_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf60_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf60_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf60_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf62_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
class op62_loop_body:
    var_ranges = {z0: 100}
    index0 = z0
    index1 = 0
    index2 = 9
    index3 = 8
    index4 = 7
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf58', get_index)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('buf59', get_index_1)
        add = ops.add(load, load_1)
        get_index_2 = self.get_index('index0')
        index_expr = ops.index_expr(get_index_2, torch.int32)
        constant = ops.constant(10, torch.int32)
        eq = ops.eq(index_expr, constant)
        get_index_3 = self.get_index('index1')
        load_2 = ops.load('buf61', get_index_3)
        get_index_4 = self.get_index('index0')
        load_3 = ops.load('full_default', get_index_4)
        where = ops.where(eq, load_2, load_3)
        add_1 = ops.add(add, where)
        get_index_5 = self.get_index('index0')
        index_expr_1 = ops.index_expr(get_index_5, torch.int32)
        constant_1 = ops.constant(9, torch.int32)
        eq_1 = ops.eq(index_expr_1, constant_1)
        get_index_6 = self.get_index('index2')
        load_4 = ops.load('buf60', get_index_6)
        constant_2 = ops.constant(2.0, torch.float32)
        mul = ops.mul(load_4, constant_2)
        get_index_7 = self.get_index('index0')
        load_5 = ops.load('full_default', get_index_7)
        where_1 = ops.where(eq_1, mul, load_5)
        add_2 = ops.add(add_1, where_1)
        get_index_8 = self.get_index('index0')
        index_expr_2 = ops.index_expr(get_index_8, torch.int32)
        constant_3 = ops.constant(8, torch.int32)
        eq_2 = ops.eq(index_expr_2, constant_3)
        constant_4 = ops.constant(8, torch.int32)
        constant_5 = ops.constant(9, torch.int32)
        eq_3 = ops.eq(constant_4, constant_5)
        get_index_9 = self.get_index('index3')
        load_6 = ops.load('buf60', get_index_9)
        constant_6 = ops.constant(0.0, torch.float32)
        where_2 = ops.where(eq_3, constant_6, load_6)
        constant_7 = ops.constant(2.0, torch.float32)
        mul_1 = ops.mul(where_2, constant_7)
        get_index_10 = self.get_index('index0')
        load_7 = ops.load('full_default', get_index_10)
        where_3 = ops.where(eq_2, mul_1, load_7)
        add_3 = ops.add(add_2, where_3)
        get_index_11 = self.get_index('index0')
        index_expr_3 = ops.index_expr(get_index_11, torch.int32)
        constant_8 = ops.constant(7, torch.int32)
        eq_4 = ops.eq(index_expr_3, constant_8)
        constant_9 = ops.constant(7, torch.int32)
        constant_10 = ops.constant(8, torch.int32)
        eq_5 = ops.eq(constant_9, constant_10)
        constant_11 = ops.constant(7, torch.int32)
        constant_12 = ops.constant(9, torch.int32)
        eq_6 = ops.eq(constant_11, constant_12)
        get_index_12 = self.get_index('index4')
        load_8 = ops.load('buf60', get_index_12)
        constant_13 = ops.constant(0.0, torch.float32)
        where_4 = ops.where(eq_6, constant_13, load_8)
        constant_14 = ops.constant(0.0, torch.float32)
        where_5 = ops.where(eq_5, constant_14, where_4)
        constant_15 = ops.constant(2.0, torch.float32)
        mul_2 = ops.mul(where_5, constant_15)
        get_index_13 = self.get_index('index0')
        load_9 = ops.load('full_default', get_index_13)
        where_6 = ops.where(eq_4, mul_2, load_9)
        add_4 = ops.add(add_3, where_6)
        get_index_14 = self.get_index('index0')
        store = ops.store('buf62', get_index_14, add_4, None)
        return store
op62 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[128], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, multi_processor_count=20), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_out_ptr0'], 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': '712B1D69F892A891D8FFA5075DCAB47CFF4E132D88BFC66744701CEAE226F127', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, xnumel, XBLOCK : tl.constexpr):
        xnumel = 100
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp0 = tl.load(in_out_ptr0 + (x0), xmask)
        tmp1 = tl.load(in_ptr0 + (x0), xmask)
        tmp6 = tl.load(in_ptr1 + (0))
        tmp7 = tl.broadcast_to(tmp6, [XBLOCK])
        tmp8 = tl.load(in_ptr2 + (x0), xmask)
        tmp13 = tl.load(in_ptr3 + (9))
        tmp14 = tl.broadcast_to(tmp13, [XBLOCK])
        tmp22 = tl.load(in_ptr3 + (8))
        tmp23 = tl.broadcast_to(tmp22, [XBLOCK])
        tmp33 = tl.load(in_ptr3 + (7))
        tmp34 = tl.broadcast_to(tmp33, [XBLOCK])
        tmp2 = tmp0 + tmp1
        tmp3 = x0
        tmp4 = tl.full([1], 10, tl.int32)
        tmp5 = tmp3 == tmp4
        tmp9 = tl.where(tmp5, tmp7, tmp8)
        tmp10 = tmp2 + tmp9
        tmp11 = tl.full([1], 9, tl.int32)
        tmp12 = tmp3 == tmp11
        tmp15 = 2.0
        tmp16 = tmp14 * tmp15
        tmp17 = tl.where(tmp12, tmp16, tmp8)
        tmp18 = tmp10 + tmp17
        tmp19 = tl.full([1], 8, tl.int32)
        tmp20 = tmp3 == tmp19
        tmp21 = tmp19 == tmp11
        tmp24 = 0.0
        tmp25 = tl.where(tmp21, tmp24, tmp23)
        tmp26 = tmp25 * tmp15
        tmp27 = tl.where(tmp20, tmp26, tmp8)
        tmp28 = tmp18 + tmp27
        tmp29 = tl.full([1], 7, tl.int32)
        tmp30 = tmp3 == tmp29
        tmp31 = tmp29 == tmp19
        tmp32 = tmp29 == tmp11
        tmp35 = tl.where(tmp32, tmp24, tmp34)
        tmp36 = tl.where(tmp31, tmp24, tmp35)
        tmp37 = tmp36 * tmp15
        tmp38 = tl.where(tmp30, tmp37, tmp8)
        tmp39 = tmp28 + tmp38
        tl.store(in_out_ptr0 + (x0), tmp39, xmask)


op63: SchedulerNode(ComputedBuffer)
op63.writes = [MemoryDep('buf63', c0, {c0: 100}, None)]
op63.unmet_dependencies = 
    [   MemoryDep('buf60', 5, {}, None),
        MemoryDep('buf60', 6, {}, None),
        MemoryDep('buf62', c0, {c0: 100}, None)]
op63.met_dependencies = [MemoryDep('full_default', c0, {c0: 100}, None)]
op63.outputs = [
    buf63: ComputedBuffer
    buf63.layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
    buf63.users = [NodeUser(node=SchedulerNode(name='op64'), can_inplace=True, is_weak=False)]
]
op63.group.device = cuda:0
op63.group.iteration = (100, 1)
op63.sizes = ([100], [])
buf62_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf60_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
full_default_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf60_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf63_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
class op63_loop_body:
    var_ranges = {z0: 100}
    index0 = z0
    index1 = 6
    index2 = 5
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf62', get_index)
        get_index_1 = self.get_index('index0')
        index_expr = ops.index_expr(get_index_1, torch.int32)
        constant = ops.constant(6, torch.int32)
        eq = ops.eq(index_expr, constant)
        constant_1 = ops.constant(6, torch.int32)
        constant_2 = ops.constant(7, torch.int32)
        eq_1 = ops.eq(constant_1, constant_2)
        constant_3 = ops.constant(6, torch.int32)
        constant_4 = ops.constant(8, torch.int32)
        eq_2 = ops.eq(constant_3, constant_4)
        constant_5 = ops.constant(6, torch.int32)
        constant_6 = ops.constant(9, torch.int32)
        eq_3 = ops.eq(constant_5, constant_6)
        get_index_2 = self.get_index('index1')
        load_1 = ops.load('buf60', get_index_2)
        constant_7 = ops.constant(0.0, torch.float32)
        where = ops.where(eq_3, constant_7, load_1)
        constant_8 = ops.constant(0.0, torch.float32)
        where_1 = ops.where(eq_2, constant_8, where)
        constant_9 = ops.constant(0.0, torch.float32)
        where_2 = ops.where(eq_1, constant_9, where_1)
        constant_10 = ops.constant(2.0, torch.float32)
        mul = ops.mul(where_2, constant_10)
        get_index_3 = self.get_index('index0')
        load_2 = ops.load('full_default', get_index_3)
        where_3 = ops.where(eq, mul, load_2)
        add = ops.add(load, where_3)
        get_index_4 = self.get_index('index0')
        index_expr_1 = ops.index_expr(get_index_4, torch.int32)
        constant_11 = ops.constant(5, torch.int32)
        eq_4 = ops.eq(index_expr_1, constant_11)
        constant_12 = ops.constant(5, torch.int32)
        constant_13 = ops.constant(6, torch.int32)
        eq_5 = ops.eq(constant_12, constant_13)
        constant_14 = ops.constant(5, torch.int32)
        constant_15 = ops.constant(7, torch.int32)
        eq_6 = ops.eq(constant_14, constant_15)
        constant_16 = ops.constant(5, torch.int32)
        constant_17 = ops.constant(8, torch.int32)
        eq_7 = ops.eq(constant_16, constant_17)
        constant_18 = ops.constant(5, torch.int32)
        constant_19 = ops.constant(9, torch.int32)
        eq_8 = ops.eq(constant_18, constant_19)
        get_index_5 = self.get_index('index2')
        load_3 = ops.load('buf60', get_index_5)
        constant_20 = ops.constant(0.0, torch.float32)
        where_4 = ops.where(eq_8, constant_20, load_3)
        constant_21 = ops.constant(0.0, torch.float32)
        where_5 = ops.where(eq_7, constant_21, where_4)
        constant_22 = ops.constant(0.0, torch.float32)
        where_6 = ops.where(eq_6, constant_22, where_5)
        constant_23 = ops.constant(0.0, torch.float32)
        where_7 = ops.where(eq_5, constant_23, where_6)
        constant_24 = ops.constant(2.0, torch.float32)
        mul_1 = ops.mul(where_7, constant_24)
        get_index_6 = self.get_index('index0')
        load_4 = ops.load('full_default', get_index_6)
        where_8 = ops.where(eq_4, mul_1, load_4)
        add_1 = ops.add(add, where_8)
        get_index_7 = self.get_index('index0')
        store = ops.store('buf63', get_index_7, add_1, None)
        return store
op63 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[128], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, multi_processor_count=20), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_out_ptr0'], 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': '712B1D69F892A891D8FFA5075DCAB47CFF4E132D88BFC66744701CEAE226F127', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_out_ptr0, in_ptr0, in_ptr1, xnumel, XBLOCK : tl.constexpr):
        xnumel = 100
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp0 = tl.load(in_out_ptr0 + (x0), xmask)
        tmp10 = tl.load(in_ptr0 + (6))
        tmp11 = tl.broadcast_to(tmp10, [XBLOCK])
        tmp18 = tl.load(in_ptr1 + (x0), xmask)
        tmp27 = tl.load(in_ptr0 + (5))
        tmp28 = tl.broadcast_to(tmp27, [XBLOCK])
        tmp1 = x0
        tmp2 = tl.full([1], 6, tl.int32)
        tmp3 = tmp1 == tmp2
        tmp4 = tl.full([1], 7, tl.int32)
        tmp5 = tmp2 == tmp4
        tmp6 = tl.full([1], 8, tl.int32)
        tmp7 = tmp2 == tmp6
        tmp8 = tl.full([1], 9, tl.int32)
        tmp9 = tmp2 == tmp8
        tmp12 = 0.0
        tmp13 = tl.where(tmp9, tmp12, tmp11)
        tmp14 = tl.where(tmp7, tmp12, tmp13)
        tmp15 = tl.where(tmp5, tmp12, tmp14)
        tmp16 = 2.0
        tmp17 = tmp15 * tmp16
        tmp19 = tl.where(tmp3, tmp17, tmp18)
        tmp20 = tmp0 + tmp19
        tmp21 = tl.full([1], 5, tl.int32)
        tmp22 = tmp1 == tmp21
        tmp23 = tmp21 == tmp2
        tmp24 = tmp21 == tmp4
        tmp25 = tmp21 == tmp6
        tmp26 = tmp21 == tmp8
        tmp29 = tl.where(tmp26, tmp12, tmp28)
        tmp30 = tl.where(tmp25, tmp12, tmp29)
        tmp31 = tl.where(tmp24, tmp12, tmp30)
        tmp32 = tl.where(tmp23, tmp12, tmp31)
        tmp33 = tmp32 * tmp16
        tmp34 = tl.where(tmp22, tmp33, tmp18)
        tmp35 = tmp20 + tmp34
        tl.store(in_out_ptr0 + (x0), tmp35, xmask)


op64: SchedulerNode(ComputedBuffer)
op64.writes = [MemoryDep('buf64', c0, {c0: 100}, None)]
op64.unmet_dependencies = 
    [   MemoryDep('buf60', 3, {}, None),
        MemoryDep('buf60', 4, {}, None),
        MemoryDep('buf63', c0, {c0: 100}, None)]
op64.met_dependencies = [MemoryDep('full_default', c0, {c0: 100}, None)]
op64.outputs = [
    buf64: ComputedBuffer
    buf64.layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
    buf64.users = [NodeUser(node=SchedulerNode(name='op65'), can_inplace=True, is_weak=False)]
]
op64.group.device = cuda:0
op64.group.iteration = (100, 1)
op64.sizes = ([100], [])
buf63_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf60_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
full_default_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf60_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf64_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
class op64_loop_body:
    var_ranges = {z0: 100}
    index0 = z0
    index1 = 4
    index2 = 3
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf63', get_index)
        get_index_1 = self.get_index('index0')
        index_expr = ops.index_expr(get_index_1, torch.int32)
        constant = ops.constant(4, torch.int32)
        eq = ops.eq(index_expr, constant)
        constant_1 = ops.constant(4, torch.int32)
        constant_2 = ops.constant(5, torch.int32)
        eq_1 = ops.eq(constant_1, constant_2)
        constant_3 = ops.constant(4, torch.int32)
        constant_4 = ops.constant(6, torch.int32)
        eq_2 = ops.eq(constant_3, constant_4)
        constant_5 = ops.constant(4, torch.int32)
        constant_6 = ops.constant(7, torch.int32)
        eq_3 = ops.eq(constant_5, constant_6)
        constant_7 = ops.constant(4, torch.int32)
        constant_8 = ops.constant(8, torch.int32)
        eq_4 = ops.eq(constant_7, constant_8)
        constant_9 = ops.constant(4, torch.int32)
        constant_10 = ops.constant(9, torch.int32)
        eq_5 = ops.eq(constant_9, constant_10)
        get_index_2 = self.get_index('index1')
        load_1 = ops.load('buf60', get_index_2)
        constant_11 = ops.constant(0.0, torch.float32)
        where = ops.where(eq_5, constant_11, load_1)
        constant_12 = ops.constant(0.0, torch.float32)
        where_1 = ops.where(eq_4, constant_12, where)
        constant_13 = ops.constant(0.0, torch.float32)
        where_2 = ops.where(eq_3, constant_13, where_1)
        constant_14 = ops.constant(0.0, torch.float32)
        where_3 = ops.where(eq_2, constant_14, where_2)
        constant_15 = ops.constant(0.0, torch.float32)
        where_4 = ops.where(eq_1, constant_15, where_3)
        constant_16 = ops.constant(2.0, torch.float32)
        mul = ops.mul(where_4, constant_16)
        get_index_3 = self.get_index('index0')
        load_2 = ops.load('full_default', get_index_3)
        where_5 = ops.where(eq, mul, load_2)
        add = ops.add(load, where_5)
        get_index_4 = self.get_index('index0')
        index_expr_1 = ops.index_expr(get_index_4, torch.int32)
        constant_17 = ops.constant(3, torch.int32)
        eq_6 = ops.eq(index_expr_1, constant_17)
        constant_18 = ops.constant(3, torch.int32)
        constant_19 = ops.constant(4, torch.int32)
        eq_7 = ops.eq(constant_18, constant_19)
        constant_20 = ops.constant(3, torch.int32)
        constant_21 = ops.constant(5, torch.int32)
        eq_8 = ops.eq(constant_20, constant_21)
        constant_22 = ops.constant(3, torch.int32)
        constant_23 = ops.constant(6, torch.int32)
        eq_9 = ops.eq(constant_22, constant_23)
        constant_24 = ops.constant(3, torch.int32)
        constant_25 = ops.constant(7, torch.int32)
        eq_10 = ops.eq(constant_24, constant_25)
        constant_26 = ops.constant(3, torch.int32)
        constant_27 = ops.constant(8, torch.int32)
        eq_11 = ops.eq(constant_26, constant_27)
        constant_28 = ops.constant(3, torch.int32)
        constant_29 = ops.constant(9, torch.int32)
        eq_12 = ops.eq(constant_28, constant_29)
        get_index_5 = self.get_index('index2')
        load_3 = ops.load('buf60', get_index_5)
        constant_30 = ops.constant(0.0, torch.float32)
        where_6 = ops.where(eq_12, constant_30, load_3)
        constant_31 = ops.constant(0.0, torch.float32)
        where_7 = ops.where(eq_11, constant_31, where_6)
        constant_32 = ops.constant(0.0, torch.float32)
        where_8 = ops.where(eq_10, constant_32, where_7)
        constant_33 = ops.constant(0.0, torch.float32)
        where_9 = ops.where(eq_9, constant_33, where_8)
        constant_34 = ops.constant(0.0, torch.float32)
        where_10 = ops.where(eq_8, constant_34, where_9)
        constant_35 = ops.constant(0.0, torch.float32)
        where_11 = ops.where(eq_7, constant_35, where_10)
        constant_36 = ops.constant(2.0, torch.float32)
        mul_1 = ops.mul(where_11, constant_36)
        get_index_6 = self.get_index('index0')
        load_4 = ops.load('full_default', get_index_6)
        where_12 = ops.where(eq_6, mul_1, load_4)
        add_1 = ops.add(add, where_12)
        get_index_7 = self.get_index('index0')
        store = ops.store('buf64', get_index_7, add_1, None)
        return store
op64 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[128], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, multi_processor_count=20), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_out_ptr0'], 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': '712B1D69F892A891D8FFA5075DCAB47CFF4E132D88BFC66744701CEAE226F127', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_out_ptr0, in_ptr0, in_ptr1, xnumel, XBLOCK : tl.constexpr):
        xnumel = 100
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp0 = tl.load(in_out_ptr0 + (x0), xmask)
        tmp14 = tl.load(in_ptr0 + (4))
        tmp15 = tl.broadcast_to(tmp14, [XBLOCK])
        tmp24 = tl.load(in_ptr1 + (x0), xmask)
        tmp35 = tl.load(in_ptr0 + (3))
        tmp36 = tl.broadcast_to(tmp35, [XBLOCK])
        tmp1 = x0
        tmp2 = tl.full([1], 4, tl.int32)
        tmp3 = tmp1 == tmp2
        tmp4 = tl.full([1], 5, tl.int32)
        tmp5 = tmp2 == tmp4
        tmp6 = tl.full([1], 6, tl.int32)
        tmp7 = tmp2 == tmp6
        tmp8 = tl.full([1], 7, tl.int32)
        tmp9 = tmp2 == tmp8
        tmp10 = tl.full([1], 8, tl.int32)
        tmp11 = tmp2 == tmp10
        tmp12 = tl.full([1], 9, tl.int32)
        tmp13 = tmp2 == tmp12
        tmp16 = 0.0
        tmp17 = tl.where(tmp13, tmp16, tmp15)
        tmp18 = tl.where(tmp11, tmp16, tmp17)
        tmp19 = tl.where(tmp9, tmp16, tmp18)
        tmp20 = tl.where(tmp7, tmp16, tmp19)
        tmp21 = tl.where(tmp5, tmp16, tmp20)
        tmp22 = 2.0
        tmp23 = tmp21 * tmp22
        tmp25 = tl.where(tmp3, tmp23, tmp24)
        tmp26 = tmp0 + tmp25
        tmp27 = tl.full([1], 3, tl.int32)
        tmp28 = tmp1 == tmp27
        tmp29 = tmp27 == tmp2
        tmp30 = tmp27 == tmp4
        tmp31 = tmp27 == tmp6
        tmp32 = tmp27 == tmp8
        tmp33 = tmp27 == tmp10
        tmp34 = tmp27 == tmp12
        tmp37 = tl.where(tmp34, tmp16, tmp36)
        tmp38 = tl.where(tmp33, tmp16, tmp37)
        tmp39 = tl.where(tmp32, tmp16, tmp38)
        tmp40 = tl.where(tmp31, tmp16, tmp39)
        tmp41 = tl.where(tmp30, tmp16, tmp40)
        tmp42 = tl.where(tmp29, tmp16, tmp41)
        tmp43 = tmp42 * tmp22
        tmp44 = tl.where(tmp28, tmp43, tmp24)
        tmp45 = tmp26 + tmp44
        tl.store(in_out_ptr0 + (x0), tmp45, xmask)


op65: SchedulerNode(ComputedBuffer)
op65.writes = [MemoryDep('buf65', c0, {c0: 100}, None)]
op65.unmet_dependencies = [MemoryDep('buf60', 2, {}, None), MemoryDep('buf64', c0, {c0: 100}, None)]
op65.met_dependencies = [MemoryDep('full_default', c0, {c0: 100}, None)]
op65.outputs = [
    buf65: ComputedBuffer
    buf65.layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
    buf65.users = [NodeUser(node=SchedulerNode(name='op68'), can_inplace=True, is_weak=False)]
]
op65.group.device = cuda:0
op65.group.iteration = (100, 1)
op65.sizes = ([100], [])
buf64_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf60_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
full_default_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf65_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
class op65_loop_body:
    var_ranges = {z0: 100}
    index0 = z0
    index1 = 2
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf64', get_index)
        get_index_1 = self.get_index('index0')
        index_expr = ops.index_expr(get_index_1, torch.int32)
        constant = ops.constant(2, torch.int32)
        eq = ops.eq(index_expr, constant)
        constant_1 = ops.constant(2, torch.int32)
        constant_2 = ops.constant(3, torch.int32)
        eq_1 = ops.eq(constant_1, constant_2)
        constant_3 = ops.constant(2, torch.int32)
        constant_4 = ops.constant(4, torch.int32)
        eq_2 = ops.eq(constant_3, constant_4)
        constant_5 = ops.constant(2, torch.int32)
        constant_6 = ops.constant(5, torch.int32)
        eq_3 = ops.eq(constant_5, constant_6)
        constant_7 = ops.constant(2, torch.int32)
        constant_8 = ops.constant(6, torch.int32)
        eq_4 = ops.eq(constant_7, constant_8)
        constant_9 = ops.constant(2, torch.int32)
        constant_10 = ops.constant(7, torch.int32)
        eq_5 = ops.eq(constant_9, constant_10)
        constant_11 = ops.constant(2, torch.int32)
        constant_12 = ops.constant(8, torch.int32)
        eq_6 = ops.eq(constant_11, constant_12)
        constant_13 = ops.constant(2, torch.int32)
        constant_14 = ops.constant(9, torch.int32)
        eq_7 = ops.eq(constant_13, constant_14)
        get_index_2 = self.get_index('index1')
        load_1 = ops.load('buf60', get_index_2)
        constant_15 = ops.constant(0.0, torch.float32)
        where = ops.where(eq_7, constant_15, load_1)
        constant_16 = ops.constant(0.0, torch.float32)
        where_1 = ops.where(eq_6, constant_16, where)
        constant_17 = ops.constant(0.0, torch.float32)
        where_2 = ops.where(eq_5, constant_17, where_1)
        constant_18 = ops.constant(0.0, torch.float32)
        where_3 = ops.where(eq_4, constant_18, where_2)
        constant_19 = ops.constant(0.0, torch.float32)
        where_4 = ops.where(eq_3, constant_19, where_3)
        constant_20 = ops.constant(0.0, torch.float32)
        where_5 = ops.where(eq_2, constant_20, where_4)
        constant_21 = ops.constant(0.0, torch.float32)
        where_6 = ops.where(eq_1, constant_21, where_5)
        constant_22 = ops.constant(2.0, torch.float32)
        mul = ops.mul(where_6, constant_22)
        get_index_3 = self.get_index('index0')
        load_2 = ops.load('full_default', get_index_3)
        where_7 = ops.where(eq, mul, load_2)
        add = ops.add(load, where_7)
        get_index_4 = self.get_index('index0')
        store = ops.store('buf65', get_index_4, add, None)
        return store
op65 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[128], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, multi_processor_count=20), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_out_ptr0'], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 0, 'backend_hash': '712B1D69F892A891D8FFA5075DCAB47CFF4E132D88BFC66744701CEAE226F127', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_out_ptr0, in_ptr0, in_ptr1, xnumel, XBLOCK : tl.constexpr):
        xnumel = 100
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp0 = tl.load(in_out_ptr0 + (x0), xmask)
        tmp18 = tl.load(in_ptr0 + (2))
        tmp19 = tl.broadcast_to(tmp18, [XBLOCK])
        tmp30 = tl.load(in_ptr1 + (x0), xmask)
        tmp1 = x0
        tmp2 = tl.full([1], 2, tl.int32)
        tmp3 = tmp1 == tmp2
        tmp4 = tl.full([1], 3, tl.int32)
        tmp5 = tmp2 == tmp4
        tmp6 = tl.full([1], 4, tl.int32)
        tmp7 = tmp2 == tmp6
        tmp8 = tl.full([1], 5, tl.int32)
        tmp9 = tmp2 == tmp8
        tmp10 = tl.full([1], 6, tl.int32)
        tmp11 = tmp2 == tmp10
        tmp12 = tl.full([1], 7, tl.int32)
        tmp13 = tmp2 == tmp12
        tmp14 = tl.full([1], 8, tl.int32)
        tmp15 = tmp2 == tmp14
        tmp16 = tl.full([1], 9, tl.int32)
        tmp17 = tmp2 == tmp16
        tmp20 = 0.0
        tmp21 = tl.where(tmp17, tmp20, tmp19)
        tmp22 = tl.where(tmp15, tmp20, tmp21)
        tmp23 = tl.where(tmp13, tmp20, tmp22)
        tmp24 = tl.where(tmp11, tmp20, tmp23)
        tmp25 = tl.where(tmp9, tmp20, tmp24)
        tmp26 = tl.where(tmp7, tmp20, tmp25)
        tmp27 = tl.where(tmp5, tmp20, tmp26)
        tmp28 = 2.0
        tmp29 = tmp27 * tmp28
        tmp31 = tl.where(tmp3, tmp29, tmp30)
        tmp32 = tmp0 + tmp31
        tl.store(in_out_ptr0 + (x0), tmp32, xmask)


op66: SchedulerNode(ComputedBuffer)
op66.writes = [MemoryDep('buf66', c0, {c0: 100}, None)]
op66.unmet_dependencies = [MemoryDep('buf60', 1, {}, None)]
op66.met_dependencies = [MemoryDep('full_default', c0, {c0: 100}, None)]
op66.outputs = [
    buf66: ComputedBuffer
    buf66.layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
    buf66.users = [NodeUser(node=SchedulerNode(name='op68'), can_inplace=True, is_weak=False)]
]
op66.group.device = cuda:0
op66.group.iteration = (100, 1)
op66.sizes = ([100], [])
buf60_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
full_default_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf66_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
class op66_loop_body:
    var_ranges = {z0: 100}
    index0 = z0
    index1 = 1
    def body(self, ops):
        get_index = self.get_index('index0')
        index_expr = ops.index_expr(get_index, torch.int32)
        constant = ops.constant(1, torch.int32)
        eq = ops.eq(index_expr, constant)
        constant_1 = ops.constant(1, torch.int32)
        constant_2 = ops.constant(2, torch.int32)
        eq_1 = ops.eq(constant_1, constant_2)
        constant_3 = ops.constant(1, torch.int32)
        constant_4 = ops.constant(3, torch.int32)
        eq_2 = ops.eq(constant_3, constant_4)
        constant_5 = ops.constant(1, torch.int32)
        constant_6 = ops.constant(4, torch.int32)
        eq_3 = ops.eq(constant_5, constant_6)
        constant_7 = ops.constant(1, torch.int32)
        constant_8 = ops.constant(5, torch.int32)
        eq_4 = ops.eq(constant_7, constant_8)
        constant_9 = ops.constant(1, torch.int32)
        constant_10 = ops.constant(6, torch.int32)
        eq_5 = ops.eq(constant_9, constant_10)
        constant_11 = ops.constant(1, torch.int32)
        constant_12 = ops.constant(7, torch.int32)
        eq_6 = ops.eq(constant_11, constant_12)
        constant_13 = ops.constant(1, torch.int32)
        constant_14 = ops.constant(8, torch.int32)
        eq_7 = ops.eq(constant_13, constant_14)
        constant_15 = ops.constant(1, torch.int32)
        constant_16 = ops.constant(9, torch.int32)
        eq_8 = ops.eq(constant_15, constant_16)
        get_index_1 = self.get_index('index1')
        load = ops.load('buf60', get_index_1)
        constant_17 = ops.constant(0.0, torch.float32)
        where = ops.where(eq_8, constant_17, load)
        constant_18 = ops.constant(0.0, torch.float32)
        where_1 = ops.where(eq_7, constant_18, where)
        constant_19 = ops.constant(0.0, torch.float32)
        where_2 = ops.where(eq_6, constant_19, where_1)
        constant_20 = ops.constant(0.0, torch.float32)
        where_3 = ops.where(eq_5, constant_20, where_2)
        constant_21 = ops.constant(0.0, torch.float32)
        where_4 = ops.where(eq_4, constant_21, where_3)
        constant_22 = ops.constant(0.0, torch.float32)
        where_5 = ops.where(eq_3, constant_22, where_4)
        constant_23 = ops.constant(0.0, torch.float32)
        where_6 = ops.where(eq_2, constant_23, where_5)
        constant_24 = ops.constant(0.0, torch.float32)
        where_7 = ops.where(eq_1, constant_24, where_6)
        constant_25 = ops.constant(2.0, torch.float32)
        mul = ops.mul(where_7, constant_25)
        get_index_2 = self.get_index('index0')
        load_1 = ops.load('full_default', get_index_2)
        where_8 = ops.where(eq, mul, load_1)
        get_index_3 = self.get_index('index0')
        store = ops.store('buf66', get_index_3, where_8, None)
        return store
op66 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[128], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, multi_processor_count=20), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '712B1D69F892A891D8FFA5075DCAB47CFF4E132D88BFC66744701CEAE226F127', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 100
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp19 = tl.load(in_ptr0 + (1))
        tmp20 = tl.broadcast_to(tmp19, [XBLOCK])
        tmp32 = tl.load(in_ptr1 + (x0), xmask)
        tmp0 = x0
        tmp1 = tl.full([1], 1, tl.int32)
        tmp2 = tmp0 == tmp1
        tmp3 = tl.full([1], 2, tl.int32)
        tmp4 = tmp1 == tmp3
        tmp5 = tl.full([1], 3, tl.int32)
        tmp6 = tmp1 == tmp5
        tmp7 = tl.full([1], 4, tl.int32)
        tmp8 = tmp1 == tmp7
        tmp9 = tl.full([1], 5, tl.int32)
        tmp10 = tmp1 == tmp9
        tmp11 = tl.full([1], 6, tl.int32)
        tmp12 = tmp1 == tmp11
        tmp13 = tl.full([1], 7, tl.int32)
        tmp14 = tmp1 == tmp13
        tmp15 = tl.full([1], 8, tl.int32)
        tmp16 = tmp1 == tmp15
        tmp17 = tl.full([1], 9, tl.int32)
        tmp18 = tmp1 == tmp17
        tmp21 = 0.0
        tmp22 = tl.where(tmp18, tmp21, tmp20)
        tmp23 = tl.where(tmp16, tmp21, tmp22)
        tmp24 = tl.where(tmp14, tmp21, tmp23)
        tmp25 = tl.where(tmp12, tmp21, tmp24)
        tmp26 = tl.where(tmp10, tmp21, tmp25)
        tmp27 = tl.where(tmp8, tmp21, tmp26)
        tmp28 = tl.where(tmp6, tmp21, tmp27)
        tmp29 = tl.where(tmp4, tmp21, tmp28)
        tmp30 = 2.0
        tmp31 = tmp29 * tmp30
        tmp33 = tl.where(tmp2, tmp31, tmp32)
        tl.store(out_ptr0 + (x0), tmp33, xmask)


op67: SchedulerNode(ComputedBuffer)
op67.writes = [MemoryDep('buf67', 0, {}, None)]
op67.unmet_dependencies = [MemoryDep('buf60', 0, {}, None)]
op67.met_dependencies = []
op67.outputs = [
    buf67: ComputedBuffer
    buf67.layout = FixedLayout('cuda', torch.float32, size=[], stride=[])
    buf67.users = [NodeUser(node=SchedulerNode(name='op68'), can_inplace=False, is_weak=False)]
]
op67.group.device = cuda:0
op67.group.iteration = (1, 1)
op67.sizes = ([], [])
buf60_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf67_layout = FixedLayout('cuda', torch.float32, size=[], stride=[])
class op67_loop_body:
    var_ranges = {}
    index0 = 0
    def body(self, ops):
        constant = ops.constant(0, torch.int32)
        constant_1 = ops.constant(1, torch.int32)
        eq = ops.eq(constant, constant_1)
        constant_2 = ops.constant(0, torch.int32)
        constant_3 = ops.constant(2, torch.int32)
        eq_1 = ops.eq(constant_2, constant_3)
        constant_4 = ops.constant(0, torch.int32)
        constant_5 = ops.constant(3, torch.int32)
        eq_2 = ops.eq(constant_4, constant_5)
        constant_6 = ops.constant(0, torch.int32)
        constant_7 = ops.constant(4, torch.int32)
        eq_3 = ops.eq(constant_6, constant_7)
        constant_8 = ops.constant(0, torch.int32)
        constant_9 = ops.constant(5, torch.int32)
        eq_4 = ops.eq(constant_8, constant_9)
        constant_10 = ops.constant(0, torch.int32)
        constant_11 = ops.constant(6, torch.int32)
        eq_5 = ops.eq(constant_10, constant_11)
        constant_12 = ops.constant(0, torch.int32)
        constant_13 = ops.constant(7, torch.int32)
        eq_6 = ops.eq(constant_12, constant_13)
        constant_14 = ops.constant(0, torch.int32)
        constant_15 = ops.constant(8, torch.int32)
        eq_7 = ops.eq(constant_14, constant_15)
        constant_16 = ops.constant(0, torch.int32)
        constant_17 = ops.constant(9, torch.int32)
        eq_8 = ops.eq(constant_16, constant_17)
        get_index = self.get_index('index0')
        load = ops.load('buf60', get_index)
        constant_18 = ops.constant(0.0, torch.float32)
        where = ops.where(eq_8, constant_18, load)
        constant_19 = ops.constant(0.0, torch.float32)
        where_1 = ops.where(eq_7, constant_19, where)
        constant_20 = ops.constant(0.0, torch.float32)
        where_2 = ops.where(eq_6, constant_20, where_1)
        constant_21 = ops.constant(0.0, torch.float32)
        where_3 = ops.where(eq_5, constant_21, where_2)
        constant_22 = ops.constant(0.0, torch.float32)
        where_4 = ops.where(eq_4, constant_22, where_3)
        constant_23 = ops.constant(0.0, torch.float32)
        where_5 = ops.where(eq_3, constant_23, where_4)
        constant_24 = ops.constant(0.0, torch.float32)
        where_6 = ops.where(eq_2, constant_24, where_5)
        constant_25 = ops.constant(0.0, torch.float32)
        where_7 = ops.where(eq_1, constant_25, where_6)
        constant_26 = ops.constant(0.0, torch.float32)
        where_8 = ops.where(eq, constant_26, where_7)
        constant_27 = ops.constant(2.0, torch.float32)
        mul = ops.mul(where_8, constant_27)
        get_index_1 = self.get_index('index0')
        store = ops.store('buf67', get_index_1, mul, None)
        return store
op67 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[1], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, multi_processor_count=20), 'constants': {2: 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(2,))]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '712B1D69F892A891D8FFA5075DCAB47CFF4E132D88BFC66744701CEAE226F127', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 1
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = tl.full([XBLOCK], True, tl.int1)
        tmp19 = tl.load(in_ptr0 + (0))
        tmp20 = tl.broadcast_to(tmp19, [XBLOCK])
        tmp0 = tl.full([1], 0, tl.int32)
        tmp1 = tl.full([1], 1, tl.int32)
        tmp2 = tmp0 == tmp1
        tmp3 = tl.full([1], 2, tl.int32)
        tmp4 = tmp0 == tmp3
        tmp5 = tl.full([1], 3, tl.int32)
        tmp6 = tmp0 == tmp5
        tmp7 = tl.full([1], 4, tl.int32)
        tmp8 = tmp0 == tmp7
        tmp9 = tl.full([1], 5, tl.int32)
        tmp10 = tmp0 == tmp9
        tmp11 = tl.full([1], 6, tl.int32)
        tmp12 = tmp0 == tmp11
        tmp13 = tl.full([1], 7, tl.int32)
        tmp14 = tmp0 == tmp13
        tmp15 = tl.full([1], 8, tl.int32)
        tmp16 = tmp0 == tmp15
        tmp17 = tl.full([1], 9, tl.int32)
        tmp18 = tmp0 == tmp17
        tmp21 = 0.0
        tmp22 = tl.where(tmp18, tmp21, tmp20)
        tmp23 = tl.where(tmp16, tmp21, tmp22)
        tmp24 = tl.where(tmp14, tmp21, tmp23)
        tmp25 = tl.where(tmp12, tmp21, tmp24)
        tmp26 = tl.where(tmp10, tmp21, tmp25)
        tmp27 = tl.where(tmp8, tmp21, tmp26)
        tmp28 = tl.where(tmp6, tmp21, tmp27)
        tmp29 = tl.where(tmp4, tmp21, tmp28)
        tmp30 = tl.where(tmp2, tmp21, tmp29)
        tmp31 = 2.0
        tmp32 = tmp30 * tmp31
        tl.store(out_ptr0 + (tl.full([XBLOCK], 0, tl.int32)), tmp32, None)


op68: SchedulerNode(ComputedBuffer)
op68.writes = [MemoryDep('buf68', c0, {c0: 100}, None)]
op68.unmet_dependencies = 
    [   MemoryDep('buf65', c0, {c0: 100}, None),
        MemoryDep('buf66', c0, {c0: 100}, None),
        MemoryDep('buf67', 0, {}, None)]
op68.met_dependencies = [MemoryDep('full_default', c0, {c0: 100}, None)]
op68.outputs = [
    buf68: ComputedBuffer
    buf68.layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
    buf68.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
]
op68.group.device = cuda:0
op68.group.iteration = (100, 1)
op68.sizes = ([100], [])
buf65_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf66_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf67_layout = FixedLayout('cuda', torch.float32, size=[], stride=[])
full_default_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
buf68_layout = FixedLayout('cuda', torch.float32, size=[100], stride=[1])
class op68_loop_body:
    var_ranges = {z0: 100}
    index0 = z0
    index1 = 0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf65', get_index)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('buf66', get_index_1)
        add = ops.add(load, load_1)
        get_index_2 = self.get_index('index0')
        index_expr = ops.index_expr(get_index_2, torch.int32)
        constant = ops.constant(0, torch.int32)
        eq = ops.eq(index_expr, constant)
        get_index_3 = self.get_index('index1')
        load_2 = ops.load('buf67', get_index_3)
        get_index_4 = self.get_index('index0')
        load_3 = ops.load('full_default', get_index_4)
        where = ops.where(eq, load_2, load_3)
        add_1 = ops.add(add, where)
        get_index_5 = self.get_index('index0')
        store = ops.store('buf68', get_index_5, add_1, None)
        return store
op68 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[128], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, multi_processor_count=20), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_out_ptr0'], 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': '712B1D69F892A891D8FFA5075DCAB47CFF4E132D88BFC66744701CEAE226F127', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, xnumel, XBLOCK : tl.constexpr):
        xnumel = 100
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = xindex < xnumel
        x0 = xindex
        tmp0 = tl.load(in_out_ptr0 + (x0), xmask)
        tmp1 = tl.load(in_ptr0 + (x0), xmask)
        tmp6 = tl.load(in_ptr1 + (0))
        tmp7 = tl.broadcast_to(tmp6, [XBLOCK])
        tmp8 = tl.load(in_ptr2 + (x0), xmask)
        tmp2 = tmp0 + tmp1
        tmp3 = x0
        tmp4 = tl.full([1], 0, tl.int32)
        tmp5 = tmp3 == tmp4
        tmp9 = tl.where(tmp5, tmp7, tmp8)
        tmp10 = tmp2 + tmp9
        tl.store(in_out_ptr0 + (x0), tmp10, xmask)


